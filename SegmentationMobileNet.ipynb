{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def resize_labels(labels, original_size, new_size):\n",
    "    scale_x = new_size[1] / original_size[1]\n",
    "    scale_y = new_size[0] / original_size[0]\n",
    "    resized_labels = []\n",
    "    for label in labels:\n",
    "        resized_label = {\n",
    "            'x': label['x'] * scale_x,\n",
    "            'y': label['y'] * scale_y,\n",
    "            'radius': label['radius'] * scale_x  # Assuming uniform scaling in x and y\n",
    "        }\n",
    "        resized_labels.append(resized_label)\n",
    "    return resized_labels\n",
    "\n",
    "def load_images_and_labels(image_paths, label_dir, new_size):\n",
    "    original_size = (1024, 1024)  # Original size of the images and labels\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Extract filename without extension to match with the label\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_file = os.path.join(label_dir, base_filename + '.json')\n",
    "\n",
    "        # Load and resize image\n",
    "        image = img_to_array(load_img(image_path, color_mode='rgb', target_size=new_size))\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load and resize corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        resized_json_data = resize_labels(json_data, original_size, new_size)\n",
    "        mask = create_mask_from_json(resized_json_data, shape=new_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, *new_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "def create_loocv_folds(image_files, augmented_image_dir):\n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "\n",
    "    for i in range(n):\n",
    "        test_image = image_files[i]\n",
    "        \n",
    "        # Ensure validation images are different from the test image and rotate them\n",
    "        val_indices = [(i + 1) % n, (i + 2) % n]\n",
    "        validation_images = [image_files[j] for j in val_indices]\n",
    "\n",
    "        # Remaining images for training, excluding the test and validation images\n",
    "        train_images = [img for idx, img in enumerate(image_files) if idx not in [i, val_indices[0], val_indices[1]]]\n",
    "\n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(20)]\n",
    "\n",
    "        folds.append((augmented_train_images, [test_image], validation_images))\n",
    "\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 256, 256, 32)         864       ['input_23[0][0]']            \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 256, 256, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 256, 256, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 256, 256, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 256, 256, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 256, 256, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 256, 256, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 256, 256, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 256, 256, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 256, 256, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 256, 256, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 257, 257, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 128, 128, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 128, 128, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 128, 128, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 128, 128, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 128, 128, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 128, 128, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 128, 128, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 128, 128, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 128, 128, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 129, 129, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 64, 64, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 64, 64, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 64, 64, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 64, 64, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 64, 64, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 64, 64, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 65, 65, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 32, 32, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 32, 32, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 32, 32, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 32, 32, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 32, 32, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 32, 32, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 32, 32, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 32, 32, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 32, 32, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 32, 32, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 32, 32, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 32, 32, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 32, 32, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 32, 32, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 32, 32, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 32, 32, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 32, 32, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 32, 32, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 32, 32, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 33, 33, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 16, 16, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 16, 16, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 16, 16, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 16, 16, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 16, 16, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 16, 16, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 16, 16, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 16, 16, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 16, 16, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 16, 16, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 16, 16, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 16, 16, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 16, 16, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 16, 16, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 16, 16, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 16, 16, 256)          1024      ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenat  (None, 16, 16, 1024)         0         ['conv2d_234[0][0]',          \n",
      " e)                                                                  'conv2d_235[0][0]',          \n",
      "                                                                     'conv2d_236[0][0]',          \n",
      "                                                                     'conv2d_237[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 16, 16, 256)          262400    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 16, 16, 256)          1024      ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_197[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_53 (UpSampli  (None, 32, 32, 256)          0         ['conv2d_239[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_54 (UpSampli  (None, 64, 64, 256)          0         ['up_sampling2d_53[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_55 (UpSampli  (None, 128, 128, 256)        0         ['up_sampling2d_54[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_56 (UpSampli  (None, 256, 256, 256)        0         ['up_sampling2d_55[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_57 (UpSampli  (None, 512, 512, 256)        0         ['up_sampling2d_56[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 512, 512, 1)          257       ['up_sampling2d_57[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4752449 (18.13 MB)\n",
      "Trainable params: 2493441 (9.51 MB)\n",
      "Non-trainable params: 2259008 (8.62 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "def create_deeplabv3_plus_binary_model(input_shape=(512, 512, 3), l2_lambda=0.01, fine_tune_at=200):\n",
    "    # Load MobileNetV2 pre-trained on ImageNet as the backbone\n",
    "    backbone = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Unfreeze the top layers of the model for fine-tuning\n",
    "    backbone.trainable = True\n",
    "    for layer in backbone.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Use features from the backbone network - feature extraction\n",
    "    x = backbone.output\n",
    "\n",
    "    # Apply atrous convolutions / spatial pyramid pooling\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling (ASPP)\n",
    "    b0 = layers.Conv2D(256, (1, 1), activation='relu', padding='same', dilation_rate=1, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=6, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=12, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=18, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "\n",
    "    # Concatenate the atrous and image-level features\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3])\n",
    "\n",
    "    # Add a convolutional layer on top of the concatenated features\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Decoder\n",
    "    # Start with a simple 1x1 convolution\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Perform upsampling in steps to reach the output size of 512x512.\n",
    "    # Each UpSampling2D layer doubles the size of the feature map\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 32x32\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 64x64\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 128x128\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 256x256\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 512x512\n",
    "\n",
    "    # Output layer for binary segmentation\n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = models.Model(inputs=backbone.input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_deeplabv3_plus_binary_model()\n",
    "\n",
    "# Compile the model (if you're about to train it)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary to verify the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3), num_filters=16, depth=2, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 512, 512, 16)         448       ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 512, 512, 16)         64        ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_190[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 512, 512, 16)         64        ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_38 (MaxPooli  (None, 256, 256, 16)         0         ['activation_191[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 256, 256, 16)         0         ['max_pooling2d_38[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 256, 256, 32)         4640      ['dropout_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 256, 256, 32)         128       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_192[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 256, 256, 32)         128       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_39 (MaxPooli  (None, 128, 128, 32)         0         ['activation_193[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 128, 128, 32)         0         ['max_pooling2d_39[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 128, 128, 64)         18496     ['dropout_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 128, 128, 64)         256       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 128, 128, 64)         36928     ['activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 128, 128, 64)         256       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_58 (UpSampli  (None, 256, 256, 64)         0         ['activation_195[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_58[0][0]',    \n",
      " e)                                                                  'activation_193[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 256, 256, 32)         27680     ['concatenate_42[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 256, 256, 32)         128       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 256, 256, 32)         128       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_59 (UpSampli  (None, 512, 512, 32)         0         ['activation_197[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenat  (None, 512, 512, 48)         0         ['up_sampling2d_59[0][0]',    \n",
      " e)                                                                  'activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 512, 512, 16)         6928      ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 512, 512, 16)         64        ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_198[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 512, 512, 16)         64        ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 512, 512, 1)          17        ['activation_199[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119553 (467.00 KB)\n",
      "Trainable params: 118913 (464.50 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = unet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a Learning Rate Schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 0:\n",
    "        return lr\n",
    "    elif epoch < 30 and epoch%2 == 0:\n",
    "        return lr * tf.math.exp(-0.5)\n",
    "    elif epoch > 30:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def train_unet(model, train_images, train_masks, val_images, val_masks, epochs=300, batch_size=32, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=1)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-4), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model with the given training and validation data\n",
    "    history = model.fit(\n",
    "        x=train_images, \n",
    "        y=train_masks, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(val_images, val_masks), \n",
    "        callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv  # Import the csv module\n",
    "\n",
    "original_image_dir = './TMA_WSI_Padded_PNGs'\n",
    "augmented_image_dir = './augmented_images'\n",
    "original_label_dir = './TMA_WSI_Labels_updated'\n",
    "augmented_label_dir = './augmented_labels'\n",
    "\n",
    "# Use list comprehension to create the list of file paths\n",
    "original_image_files = [os.path.join(original_image_dir, file) for file in sorted(\n",
    "    os.listdir(original_image_dir)) if file.endswith('.png')]\n",
    "\n",
    "folds = create_loocv_folds(original_image_files, augmented_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1334 - auc: 0.9899 - accuracy: 0.9487 - precision: 0.9153 - recall: 0.9282\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1503 - auc: 0.9857 - accuracy: 0.9400 - precision: 0.9299 - recall: 0.8824\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1538 - auc: 0.9854 - accuracy: 0.9426 - precision: 0.8813 - recall: 0.9294\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.2064 - auc: 0.9867 - accuracy: 0.9191 - precision: 0.7952 - recall: 0.9891\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2330 - auc: 0.9349 - accuracy: 0.9194 - precision: 0.8770 - recall: 0.7710\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1739 - auc: 0.9757 - accuracy: 0.9478 - precision: 0.9742 - recall: 0.7001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m test_images, test_masks \u001b[39m=\u001b[39m load_images_and_labels(test_image, original_label_dir, (\u001b[39m512\u001b[39m,\u001b[39m512\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m loss, auc, accuracy, precision, recall \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mevaluate(test_images, test_masks)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Write the evaluation metrics to the CSV file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m writer\u001b[39m.\u001b[39mwriterow([i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, loss, auc, accuracy, precision, recall])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2274\u001b[0m                     data_handler,\n\u001b[1;32m   2275\u001b[0m                     step,\n\u001b[1;32m   2276\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2277\u001b[0m                 )\n\u001b[1;32m   2279\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4080\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:887\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    885\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    886\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 887\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m    888\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    889\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    890\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    692\u001b[0m )\n\u001b[1;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[1;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    291\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:308\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m    304\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    305\u001b[0m       placeholder_context\n\u001b[1;32m    306\u001b[0m   )\n\u001b[0;32m--> 308\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    309\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    310\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[1;32m    311\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[1;32m    312\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[1;32m    313\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    314\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    315\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[1;32m    316\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    321\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39;49mconverter\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/yg/982c10113957_2gb06y92y35sx509h/T/__autograph_generated_filec46oyzrn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:2025\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   2020\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   2021\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     )\n\u001b[1;32m   2024\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 2025\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   2026\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   2027\u001b[0m     outputs,\n\u001b[1;32m   2028\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   2029\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   2030\u001b[0m )\n\u001b[1;32m   2031\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1679\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1675\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1678\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1679\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3269\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3267\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3268\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3269\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4067\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4065\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4066\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4067\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:2013\u001b[0m, in \u001b[0;36mModel.make_test_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 2013\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtest_step(data)\n\u001b[1;32m   2014\u001b[0m     \u001b[39m# Ensure counter is updated only if `test_step` succeeds.\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1893\u001b[0m, in \u001b[0;36mModel.test_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1869\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The logic for one evaluation step.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \n\u001b[1;32m   1871\u001b[0m \u001b[39mThis method can be overridden to support custom evaluation logic.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[39m  values of the `Model`'s metrics are returned.\u001b[39;00m\n\u001b[1;32m   1890\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m x, y, sample_weight \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[0;32m-> 1893\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1894\u001b[0m \u001b[39m# Updates stateful loss metrics.\u001b[39;00m\n\u001b[1;32m   1895\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:589\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    587\u001b[0m     layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[0;32m--> 589\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \n\u001b[1;32m    500\u001b[0m \u001b[39m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 672\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    674\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m    676\u001b[0m     node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[1;32m    677\u001b[0m ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/reshaping/up_sampling2d.py:132\u001b[0m, in \u001b[0;36mUpSampling2D.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mresize_images(\n\u001b[1;32m    133\u001b[0m         inputs,\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    136\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[1;32m    137\u001b[0m         interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation,\n\u001b[1;32m    138\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py:3703\u001b[0m, in \u001b[0;36mresize_images\u001b[0;34m(x, height_factor, width_factor, data_format, interpolation)\u001b[0m\n\u001b[1;32m   3701\u001b[0m interploations_list \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(interpolations\u001b[39m.\u001b[39mkeys()) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   3702\u001b[0m \u001b[39mif\u001b[39;00m interpolation \u001b[39min\u001b[39;00m interpolations:\n\u001b[0;32m-> 3703\u001b[0m     x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresize(x, new_shape, method\u001b[39m=\u001b[39;49minterpolations[interpolation])\n\u001b[1;32m   3704\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3705\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3706\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`interpolation` argument should be one of: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3707\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minterploations_list\u001b[39m}\u001b[39;00m\u001b[39m. Received: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minterpolation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   3708\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/image_ops_impl.py:1781\u001b[0m, in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1778\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1779\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mResize method is not implemented: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(method))\n\u001b[0;32m-> 1781\u001b[0m \u001b[39mreturn\u001b[39;00m _resize_images_common(\n\u001b[1;32m   1782\u001b[0m     images,\n\u001b[1;32m   1783\u001b[0m     resize_fn,\n\u001b[1;32m   1784\u001b[0m     size,\n\u001b[1;32m   1785\u001b[0m     preserve_aspect_ratio\u001b[39m=\u001b[39;49mpreserve_aspect_ratio,\n\u001b[1;32m   1786\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1787\u001b[0m     skip_resize_if_same\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/image_ops_impl.py:1514\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1511\u001b[0m     images \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39msqueeze(images, axis\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[1;32m   1512\u001b[0m   \u001b[39mreturn\u001b[39;00m images\n\u001b[0;32m-> 1514\u001b[0m images \u001b[39m=\u001b[39m resizer_fn(images, size)\n\u001b[1;32m   1516\u001b[0m \u001b[39m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39m# the packed values in `new_size`, so set the shape here.\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m images\u001b[39m.\u001b[39mset_shape([\u001b[39mNone\u001b[39;00m, new_height_const, new_width_const, \u001b[39mNone\u001b[39;00m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/image_ops_impl.py:1766\u001b[0m, in \u001b[0;36mresize_images_v2.<locals>.resize_fn\u001b[0;34m(images_t, new_size)\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_image_ops\u001b[39m.\u001b[39mresize_bilinear(\n\u001b[1;32m   1764\u001b[0m         images_t, new_size, half_pixel_centers\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1765\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m ResizeMethod\u001b[39m.\u001b[39mNEAREST_NEIGHBOR:\n\u001b[0;32m-> 1766\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_image_ops\u001b[39m.\u001b[39;49mresize_nearest_neighbor(\n\u001b[1;32m   1767\u001b[0m       images_t, new_size, half_pixel_centers\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1768\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m ResizeMethod\u001b[39m.\u001b[39mBICUBIC:\n\u001b[1;32m   1769\u001b[0m   \u001b[39mif\u001b[39;00m antialias:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/ops/gen_image_ops.py:3931\u001b[0m, in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3929\u001b[0m   half_pixel_centers \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   3930\u001b[0m half_pixel_centers \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_bool(half_pixel_centers, \u001b[39m\"\u001b[39m\u001b[39mhalf_pixel_centers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 3931\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m   3932\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mResizeNearestNeighbor\u001b[39;49m\u001b[39m\"\u001b[39;49m, images\u001b[39m=\u001b[39;49mimages, size\u001b[39m=\u001b[39;49msize,\n\u001b[1;32m   3933\u001b[0m                                align_corners\u001b[39m=\u001b[39;49malign_corners,\n\u001b[1;32m   3934\u001b[0m                                half_pixel_centers\u001b[39m=\u001b[39;49mhalf_pixel_centers,\n\u001b[1;32m   3935\u001b[0m                                name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   3936\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m   3937\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    797\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:2657\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   2655\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   2656\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 2657\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[1;32m   2658\u001b[0m       node_def,\n\u001b[1;32m   2659\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2660\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   2661\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   2662\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   2663\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   2664\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   2665\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[1;32m   2666\u001b[0m   )\n\u001b[1;32m   2667\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   2668\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1161\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   1160\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 1161\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   1162\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[1;32m   1163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1018\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1014\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[1;32m   1015\u001b[0m                                          serialized)\n\u001b[1;32m   1017\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1018\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[1;32m   1019\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1020\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'model_evaluation_results.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for i, fold in enumerate(folds):\n",
    "        # Load the checkpointed model for the fold\n",
    "        model_path = f\"pixel_core_fold_{i+1}.hdf5\"\n",
    "        loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "        # Unpack the fold\n",
    "        train_image, test_image, val_images = fold\n",
    "\n",
    "        # Load the test images and masks\n",
    "        test_images, test_masks = load_images_and_labels(test_image, original_label_dir, (512,512))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = loaded_model.evaluate(test_images, test_masks)\n",
    "\n",
    "        # Write the evaluation metrics to the CSV file\n",
    "        writer.writerow([i+1, loss, auc, accuracy, precision, recall])\n",
    "    \n",
    "\n",
    "        # Flush the changes to the CSV file\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint: pixel_core_fold_9.hdf5\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1876 - auc: 0.9802 - accuracy: 0.9517 - precision: 0.8841 - recall: 0.8777 \n",
      "Epoch 1: val_loss improved from inf to 0.51470, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 114s 11s/step - loss: 0.1876 - auc: 0.9802 - accuracy: 0.9517 - precision: 0.8841 - recall: 0.8777 - val_loss: 0.5147 - val_auc: 0.8123 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1842 - auc: 0.9794 - accuracy: 0.9525 - precision: 0.9006 - recall: 0.8620 \n",
      "Epoch 2: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1842 - auc: 0.9794 - accuracy: 0.9525 - precision: 0.9006 - recall: 0.8620 - val_loss: 0.5319 - val_auc: 0.8430 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1819 - auc: 0.9810 - accuracy: 0.9520 - precision: 0.8831 - recall: 0.8806 \n",
      "Epoch 3: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1819 - auc: 0.9810 - accuracy: 0.9520 - precision: 0.8831 - recall: 0.8806 - val_loss: 0.5409 - val_auc: 0.7162 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1811 - auc: 0.9802 - accuracy: 0.9521 - precision: 0.8958 - recall: 0.8655 \n",
      "Epoch 4: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1811 - auc: 0.9802 - accuracy: 0.9521 - precision: 0.8958 - recall: 0.8655 - val_loss: 0.5452 - val_auc: 0.7853 - val_accuracy: 0.8052 - val_precision: 1.0000 - val_recall: 7.6319e-04 - lr: 1.8394e-04\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1800 - auc: 0.9805 - accuracy: 0.9521 - precision: 0.8897 - recall: 0.8727 \n",
      "Epoch 5: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 121s 12s/step - loss: 0.1800 - auc: 0.9805 - accuracy: 0.9521 - precision: 0.8897 - recall: 0.8727 - val_loss: 0.5480 - val_auc: 0.8420 - val_accuracy: 0.8055 - val_precision: 1.0000 - val_recall: 0.0022 - lr: 1.1157e-04\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1774 - auc: 0.9810 - accuracy: 0.9529 - precision: 0.8931 - recall: 0.8730 \n",
      "Epoch 6: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 115s 11s/step - loss: 0.1774 - auc: 0.9810 - accuracy: 0.9529 - precision: 0.8931 - recall: 0.8730 - val_loss: 0.5448 - val_auc: 0.7766 - val_accuracy: 0.8059 - val_precision: 1.0000 - val_recall: 0.0043 - lr: 1.1157e-04\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1757 - auc: 0.9814 - accuracy: 0.9534 - precision: 0.8950 - recall: 0.8738 \n",
      "Epoch 7: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1757 - auc: 0.9814 - accuracy: 0.9534 - precision: 0.8950 - recall: 0.8738 - val_loss: 0.5448 - val_auc: 0.7965 - val_accuracy: 0.8062 - val_precision: 1.0000 - val_recall: 0.0057 - lr: 6.7668e-05\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1767 - auc: 0.9811 - accuracy: 0.9526 - precision: 0.8910 - recall: 0.8743 \n",
      "Epoch 8: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 118s 11s/step - loss: 0.1767 - auc: 0.9811 - accuracy: 0.9526 - precision: 0.8910 - recall: 0.8743 - val_loss: 0.5416 - val_auc: 0.7884 - val_accuracy: 0.8066 - val_precision: 1.0000 - val_recall: 0.0077 - lr: 6.7668e-05\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1758 - auc: 0.9812 - accuracy: 0.9530 - precision: 0.8943 - recall: 0.8724 \n",
      "Epoch 9: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1758 - auc: 0.9812 - accuracy: 0.9530 - precision: 0.8943 - recall: 0.8724 - val_loss: 0.5362 - val_auc: 0.8119 - val_accuracy: 0.8072 - val_precision: 1.0000 - val_recall: 0.0109 - lr: 4.1043e-05\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1750 - auc: 0.9811 - accuracy: 0.9531 - precision: 0.8958 - recall: 0.8712 \n",
      "Epoch 10: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1750 - auc: 0.9811 - accuracy: 0.9531 - precision: 0.8958 - recall: 0.8712 - val_loss: 0.5274 - val_auc: 0.8443 - val_accuracy: 0.8085 - val_precision: 0.9995 - val_recall: 0.0179 - lr: 4.1043e-05\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1743 - auc: 0.9815 - accuracy: 0.9534 - precision: 0.8958 - recall: 0.8727 \n",
      "Epoch 11: val_loss did not improve from 0.51470\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1743 - auc: 0.9815 - accuracy: 0.9534 - precision: 0.8958 - recall: 0.8727 - val_loss: 0.5178 - val_auc: 0.8730 - val_accuracy: 0.8111 - val_precision: 0.9959 - val_recall: 0.0310 - lr: 2.4894e-05\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1745 - auc: 0.9812 - accuracy: 0.9533 - precision: 0.8951 - recall: 0.8732 \n",
      "Epoch 12: val_loss improved from 0.51470 to 0.50342, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1745 - auc: 0.9812 - accuracy: 0.9533 - precision: 0.8951 - recall: 0.8732 - val_loss: 0.5034 - val_auc: 0.8936 - val_accuracy: 0.8142 - val_precision: 0.9856 - val_recall: 0.0477 - lr: 2.4894e-05\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1746 - auc: 0.9816 - accuracy: 0.9530 - precision: 0.8929 - recall: 0.8742 \n",
      "Epoch 13: val_loss improved from 0.50342 to 0.48444, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1746 - auc: 0.9816 - accuracy: 0.9530 - precision: 0.8929 - recall: 0.8742 - val_loss: 0.4844 - val_auc: 0.8933 - val_accuracy: 0.8194 - val_precision: 0.9827 - val_recall: 0.0746 - lr: 1.5099e-05\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1753 - auc: 0.9812 - accuracy: 0.9525 - precision: 0.8915 - recall: 0.8732 \n",
      "Epoch 14: val_loss improved from 0.48444 to 0.46100, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1753 - auc: 0.9812 - accuracy: 0.9525 - precision: 0.8915 - recall: 0.8732 - val_loss: 0.4610 - val_auc: 0.8986 - val_accuracy: 0.8263 - val_precision: 0.9811 - val_recall: 0.1110 - lr: 1.5099e-05\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1735 - auc: 0.9817 - accuracy: 0.9536 - precision: 0.8961 - recall: 0.8733 \n",
      "Epoch 15: val_loss improved from 0.46100 to 0.43342, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1735 - auc: 0.9817 - accuracy: 0.9536 - precision: 0.8961 - recall: 0.8733 - val_loss: 0.4334 - val_auc: 0.9009 - val_accuracy: 0.8356 - val_precision: 0.9810 - val_recall: 0.1600 - lr: 9.1578e-06\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - auc: 0.9817 - accuracy: 0.9536 - precision: 0.8960 - recall: 0.8737 \n",
      "Epoch 16: val_loss improved from 0.43342 to 0.40336, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1733 - auc: 0.9817 - accuracy: 0.9536 - precision: 0.8960 - recall: 0.8737 - val_loss: 0.4034 - val_auc: 0.9044 - val_accuracy: 0.8466 - val_precision: 0.9816 - val_recall: 0.2169 - lr: 9.1578e-06\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1745 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8931 - recall: 0.8731\n",
      "Epoch 17: val_loss improved from 0.40336 to 0.37309, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1745 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8931 - recall: 0.8731 - val_loss: 0.3731 - val_auc: 0.9086 - val_accuracy: 0.8593 - val_precision: 0.9804 - val_recall: 0.2839 - lr: 5.5545e-06\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9821 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8743 \n",
      "Epoch 18: val_loss improved from 0.37309 to 0.34384, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1730 - auc: 0.9821 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8743 - val_loss: 0.3438 - val_auc: 0.9145 - val_accuracy: 0.8727 - val_precision: 0.9777 - val_recall: 0.3551 - lr: 5.5545e-06\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1732 - auc: 0.9820 - accuracy: 0.9535 - precision: 0.8953 - recall: 0.8738 \n",
      "Epoch 19: val_loss improved from 0.34384 to 0.31756, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1732 - auc: 0.9820 - accuracy: 0.9535 - precision: 0.8953 - recall: 0.8738 - val_loss: 0.3176 - val_auc: 0.9208 - val_accuracy: 0.8852 - val_precision: 0.9720 - val_recall: 0.4234 - lr: 3.3690e-06\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1740 - auc: 0.9815 - accuracy: 0.9532 - precision: 0.8941 - recall: 0.8736 \n",
      "Epoch 20: val_loss improved from 0.31756 to 0.29365, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1740 - auc: 0.9815 - accuracy: 0.9532 - precision: 0.8941 - recall: 0.8736 - val_loss: 0.2936 - val_auc: 0.9281 - val_accuracy: 0.8953 - val_precision: 0.9568 - val_recall: 0.4850 - lr: 3.3690e-06\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1736 - auc: 0.9816 - accuracy: 0.9533 - precision: 0.8945 - recall: 0.8739 \n",
      "Epoch 21: val_loss improved from 0.29365 to 0.27342, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1736 - auc: 0.9816 - accuracy: 0.9533 - precision: 0.8945 - recall: 0.8739 - val_loss: 0.2734 - val_auc: 0.9343 - val_accuracy: 0.9051 - val_precision: 0.9519 - val_recall: 0.5404 - lr: 2.0434e-06\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1735 - auc: 0.9817 - accuracy: 0.9534 - precision: 0.8946 - recall: 0.8742 \n",
      "Epoch 22: val_loss improved from 0.27342 to 0.25588, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1735 - auc: 0.9817 - accuracy: 0.9534 - precision: 0.8946 - recall: 0.8742 - val_loss: 0.2559 - val_auc: 0.9400 - val_accuracy: 0.9136 - val_precision: 0.9479 - val_recall: 0.5893 - lr: 2.0434e-06\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - auc: 0.9818 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8737 \n",
      "Epoch 23: val_loss improved from 0.25588 to 0.24102, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1733 - auc: 0.9818 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8737 - val_loss: 0.2410 - val_auc: 0.9455 - val_accuracy: 0.9213 - val_precision: 0.9429 - val_recall: 0.6349 - lr: 1.2394e-06\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1729 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8956 - recall: 0.8741 \n",
      "Epoch 24: val_loss improved from 0.24102 to 0.22845, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1729 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8956 - recall: 0.8741 - val_loss: 0.2284 - val_auc: 0.9506 - val_accuracy: 0.9279 - val_precision: 0.9383 - val_recall: 0.6746 - lr: 1.2394e-06\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1729 - auc: 0.9819 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8740 \n",
      "Epoch 25: val_loss improved from 0.22845 to 0.21842, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1729 - auc: 0.9819 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8740 - val_loss: 0.2184 - val_auc: 0.9551 - val_accuracy: 0.9336 - val_precision: 0.9330 - val_recall: 0.7104 - lr: 7.5172e-07\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1743 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8930 - recall: 0.8733 \n",
      "Epoch 26: val_loss improved from 0.21842 to 0.21049, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1743 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8930 - recall: 0.8733 - val_loss: 0.2105 - val_auc: 0.9589 - val_accuracy: 0.9381 - val_precision: 0.9268 - val_recall: 0.7412 - lr: 7.5172e-07\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1734 - auc: 0.9815 - accuracy: 0.9535 - precision: 0.8953 - recall: 0.8735 \n",
      "Epoch 27: val_loss improved from 0.21049 to 0.20416, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 115s 11s/step - loss: 0.1734 - auc: 0.9815 - accuracy: 0.9535 - precision: 0.8953 - recall: 0.8735 - val_loss: 0.2042 - val_auc: 0.9622 - val_accuracy: 0.9415 - val_precision: 0.9208 - val_recall: 0.7656 - lr: 4.5594e-07\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1732 - auc: 0.9818 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8742 \n",
      "Epoch 28: val_loss improved from 0.20416 to 0.19924, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1732 - auc: 0.9818 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8742 - val_loss: 0.1992 - val_auc: 0.9651 - val_accuracy: 0.9443 - val_precision: 0.9152 - val_recall: 0.7870 - lr: 4.5594e-07\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1731 - auc: 0.9817 - accuracy: 0.9537 - precision: 0.8962 - recall: 0.8737 \n",
      "Epoch 29: val_loss improved from 0.19924 to 0.19561, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1731 - auc: 0.9817 - accuracy: 0.9537 - precision: 0.8962 - recall: 0.8737 - val_loss: 0.1956 - val_auc: 0.9674 - val_accuracy: 0.9467 - val_precision: 0.9097 - val_recall: 0.8066 - lr: 2.7654e-07\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1727 - auc: 0.9821 - accuracy: 0.9538 - precision: 0.8962 - recall: 0.8743 \n",
      "Epoch 30: val_loss improved from 0.19561 to 0.19293, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1727 - auc: 0.9821 - accuracy: 0.9538 - precision: 0.8962 - recall: 0.8743 - val_loss: 0.1929 - val_auc: 0.9693 - val_accuracy: 0.9483 - val_precision: 0.9041 - val_recall: 0.8222 - lr: 2.7654e-07\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1744 - auc: 0.9811 - accuracy: 0.9530 - precision: 0.8932 - recall: 0.8737 \n",
      "Epoch 31: val_loss improved from 0.19293 to 0.19089, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 120s 12s/step - loss: 0.1744 - auc: 0.9811 - accuracy: 0.9530 - precision: 0.8932 - recall: 0.8737 - val_loss: 0.1909 - val_auc: 0.9708 - val_accuracy: 0.9495 - val_precision: 0.8990 - val_recall: 0.8348 - lr: 2.7654e-07\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8953 - recall: 0.8744 \n",
      "Epoch 32: val_loss improved from 0.19089 to 0.18945, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 123s 12s/step - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8953 - recall: 0.8744 - val_loss: 0.1894 - val_auc: 0.9723 - val_accuracy: 0.9505 - val_precision: 0.8940 - val_recall: 0.8462 - lr: 2.7654e-08\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - auc: 0.9819 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8740 \n",
      "Epoch 33: val_loss improved from 0.18945 to 0.18848, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1733 - auc: 0.9819 - accuracy: 0.9535 - precision: 0.8952 - recall: 0.8740 - val_loss: 0.1885 - val_auc: 0.9734 - val_accuracy: 0.9511 - val_precision: 0.8890 - val_recall: 0.8559 - lr: 2.7654e-09\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9537 - precision: 0.8958 - recall: 0.8742 \n",
      "Epoch 34: val_loss improved from 0.18848 to 0.18788, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 116s 12s/step - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9537 - precision: 0.8958 - recall: 0.8742 - val_loss: 0.1879 - val_auc: 0.9744 - val_accuracy: 0.9515 - val_precision: 0.8845 - val_recall: 0.8641 - lr: 2.7654e-10\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - auc: 0.9817 - accuracy: 0.9535 - precision: 0.8956 - recall: 0.8737 \n",
      "Epoch 35: val_loss improved from 0.18788 to 0.18752, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1733 - auc: 0.9817 - accuracy: 0.9535 - precision: 0.8956 - recall: 0.8737 - val_loss: 0.1875 - val_auc: 0.9752 - val_accuracy: 0.9518 - val_precision: 0.8801 - val_recall: 0.8713 - lr: 2.7654e-11\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1740 - auc: 0.9815 - accuracy: 0.9532 - precision: 0.8942 - recall: 0.8734 \n",
      "Epoch 36: val_loss improved from 0.18752 to 0.18735, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1740 - auc: 0.9815 - accuracy: 0.9532 - precision: 0.8942 - recall: 0.8734 - val_loss: 0.1874 - val_auc: 0.9759 - val_accuracy: 0.9519 - val_precision: 0.8760 - val_recall: 0.8774 - lr: 2.7654e-12\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1742 - auc: 0.9814 - accuracy: 0.9530 - precision: 0.8938 - recall: 0.8731 \n",
      "Epoch 37: val_loss improved from 0.18735 to 0.18731, saving model to pixel_core_fold_9.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1742 - auc: 0.9814 - accuracy: 0.9530 - precision: 0.8938 - recall: 0.8731 - val_loss: 0.1873 - val_auc: 0.9766 - val_accuracy: 0.9520 - val_precision: 0.8721 - val_recall: 0.8832 - lr: 2.7654e-13\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1728 - auc: 0.9820 - accuracy: 0.9538 - precision: 0.8962 - recall: 0.8741 \n",
      "Epoch 38: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1728 - auc: 0.9820 - accuracy: 0.9538 - precision: 0.8962 - recall: 0.8741 - val_loss: 0.1875 - val_auc: 0.9771 - val_accuracy: 0.9518 - val_precision: 0.8679 - val_recall: 0.8880 - lr: 2.7654e-14\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1731 - auc: 0.9820 - accuracy: 0.9535 - precision: 0.8954 - recall: 0.8739 \n",
      "Epoch 39: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1731 - auc: 0.9820 - accuracy: 0.9535 - precision: 0.8954 - recall: 0.8739 - val_loss: 0.1876 - val_auc: 0.9776 - val_accuracy: 0.9517 - val_precision: 0.8644 - val_recall: 0.8920 - lr: 2.7654e-15\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1741 - auc: 0.9815 - accuracy: 0.9531 - precision: 0.8941 - recall: 0.8729 \n",
      "Epoch 40: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1741 - auc: 0.9815 - accuracy: 0.9531 - precision: 0.8941 - recall: 0.8729 - val_loss: 0.1878 - val_auc: 0.9780 - val_accuracy: 0.9515 - val_precision: 0.8613 - val_recall: 0.8954 - lr: 2.7654e-16\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1731 - auc: 0.9819 - accuracy: 0.9536 - precision: 0.8956 - recall: 0.8742 \n",
      "Epoch 41: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1731 - auc: 0.9819 - accuracy: 0.9536 - precision: 0.8956 - recall: 0.8742 - val_loss: 0.1880 - val_auc: 0.9783 - val_accuracy: 0.9513 - val_precision: 0.8581 - val_recall: 0.8986 - lr: 2.7654e-17\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1736 - auc: 0.9814 - accuracy: 0.9533 - precision: 0.8953 - recall: 0.8728 \n",
      "Epoch 42: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1736 - auc: 0.9814 - accuracy: 0.9533 - precision: 0.8953 - recall: 0.8728 - val_loss: 0.1883 - val_auc: 0.9786 - val_accuracy: 0.9511 - val_precision: 0.8555 - val_recall: 0.9013 - lr: 2.7654e-18\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1737 - auc: 0.9816 - accuracy: 0.9533 - precision: 0.8949 - recall: 0.8731 \n",
      "Epoch 43: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 114s 12s/step - loss: 0.1737 - auc: 0.9816 - accuracy: 0.9533 - precision: 0.8949 - recall: 0.8731 - val_loss: 0.1885 - val_auc: 0.9789 - val_accuracy: 0.9508 - val_precision: 0.8530 - val_recall: 0.9035 - lr: 2.7654e-19\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1737 - auc: 0.9817 - accuracy: 0.9533 - precision: 0.8952 - recall: 0.8728 \n",
      "Epoch 44: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1737 - auc: 0.9817 - accuracy: 0.9533 - precision: 0.8952 - recall: 0.8728 - val_loss: 0.1888 - val_auc: 0.9792 - val_accuracy: 0.9506 - val_precision: 0.8508 - val_recall: 0.9056 - lr: 2.7654e-20\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1737 - auc: 0.9816 - accuracy: 0.9532 - precision: 0.8944 - recall: 0.8735 \n",
      "Epoch 45: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1737 - auc: 0.9816 - accuracy: 0.9532 - precision: 0.8944 - recall: 0.8735 - val_loss: 0.1891 - val_auc: 0.9794 - val_accuracy: 0.9504 - val_precision: 0.8487 - val_recall: 0.9073 - lr: 2.7654e-21\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8954 - recall: 0.8741 \n",
      "Epoch 46: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1730 - auc: 0.9820 - accuracy: 0.9536 - precision: 0.8954 - recall: 0.8741 - val_loss: 0.1895 - val_auc: 0.9795 - val_accuracy: 0.9501 - val_precision: 0.8466 - val_recall: 0.9089 - lr: 2.7654e-22\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1734 - auc: 0.9817 - accuracy: 0.9534 - precision: 0.8947 - recall: 0.8740 \n",
      "Epoch 47: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1734 - auc: 0.9817 - accuracy: 0.9534 - precision: 0.8947 - recall: 0.8740 - val_loss: 0.1897 - val_auc: 0.9797 - val_accuracy: 0.9499 - val_precision: 0.8447 - val_recall: 0.9101 - lr: 2.7654e-23\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1735 - auc: 0.9819 - accuracy: 0.9533 - precision: 0.8948 - recall: 0.8735 \n",
      "Epoch 48: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1735 - auc: 0.9819 - accuracy: 0.9533 - precision: 0.8948 - recall: 0.8735 - val_loss: 0.1900 - val_auc: 0.9798 - val_accuracy: 0.9497 - val_precision: 0.8433 - val_recall: 0.9114 - lr: 2.7654e-24\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9818 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8740 \n",
      "Epoch 49: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1730 - auc: 0.9818 - accuracy: 0.9537 - precision: 0.8959 - recall: 0.8740 - val_loss: 0.1903 - val_auc: 0.9800 - val_accuracy: 0.9496 - val_precision: 0.8421 - val_recall: 0.9127 - lr: 2.7654e-25\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1728 - auc: 0.9820 - accuracy: 0.9537 - precision: 0.8961 - recall: 0.8742 \n",
      "Epoch 50: val_loss did not improve from 0.18731\n",
      "10/10 [==============================] - 115s 11s/step - loss: 0.1728 - auc: 0.9820 - accuracy: 0.9537 - precision: 0.8961 - recall: 0.8742 - val_loss: 0.1906 - val_auc: 0.9801 - val_accuracy: 0.9494 - val_precision: 0.8406 - val_recall: 0.9138 - lr: 2.7654e-26\n",
      "Epoch 51/150\n",
      " 1/10 [==>...........................] - ETA: 1:39 - loss: 0.1705 - auc: 0.9825 - accuracy: 0.9568 - precision: 0.9024 - recall: 0.8710"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m model \u001b[39m=\u001b[39m unet()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m trained_model \u001b[39m=\u001b[39m train_unet(model, train_images, train_masks, val_images, val_masks, \u001b[39m150\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpixel_core_fold_\u001b[39;49m\u001b[39m{i}\u001b[39;49;00m\u001b[39m.hdf5\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i\u001b[39m=\u001b[39;49mi))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m loss, auc, accuracy, precision, recall \u001b[39m=\u001b[39m trained_model\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     test_images, test_masks)\n",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# Fit the model with the given training and validation data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     x\u001b[39m=\u001b[39;49mtrain_images, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     y\u001b[39m=\u001b[39;49mtrain_masks, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(val_images, val_masks), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X10sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation metrics initialization\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "new_size = (512, 512)\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('model_evaluation_results.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    # Check if the file is empty by seeking to the end and getting the position\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    if file.tell() == 0:\n",
    "        # File is empty, write the header\n",
    "        writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    file.flush() \n",
    "    indices = [14,16,19]\n",
    "    # Iterate over each fold\n",
    "    i = 0\n",
    "    for i, fold in enumerate([folds[index - 1] for index in indices], start=1):\n",
    "        augmented_train_images, test_image, validation_images = fold\n",
    "        i = indices[i-1]\n",
    "        # Load and preprocess images and labels\n",
    "        train_images, train_masks = load_images_and_labels(\n",
    "            augmented_train_images, augmented_label_dir, new_size)\n",
    "        test_images, test_masks = load_images_and_labels(\n",
    "            test_image, original_label_dir, new_size)\n",
    "        val_images, val_masks = load_images_and_labels(\n",
    "            validation_images, original_label_dir, new_size)\n",
    "\n",
    "        # Create a new instance of the model\n",
    "        model = unet()\n",
    "\n",
    "        # Train the model\n",
    "        trained_model = train_unet(model, train_images, train_masks, val_images, val_masks, 150, 32, \"pixel_core_fold_{i}.hdf5\".format(i=i))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = trained_model.evaluate(\n",
    "            test_images, test_masks)\n",
    "\n",
    "        # Store the evaluation metrics\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Write the fold results to the CSV file\n",
    "        writer.writerow([i, loss, auc, accuracy, precision, recall])\n",
    "        file.flush() \n",
    "\n",
    "# Calculate average and standard deviation of metrics\n",
    "avg_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "avg_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Average AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron\\Documents\\GitHub\\RizzGPT\\Microarray-Dearraying\\UNetDetection.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m plot_training_predictions(model, images, masks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_predictions(model, training_images, training_masks, num_samples=3):\n",
    "    # Make sure there is enough data for the number of samples requested\n",
    "    if num_samples > len(training_images):\n",
    "        num_samples = len(training_images)\n",
    "        print(f\"Number of available samples is less than requested. Setting num_samples to {num_samples}.\")\n",
    "\n",
    "    # Randomly select some samples from the training images and masks\n",
    "    indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    sample_images = np.array([training_images[i] for i in indices])\n",
    "    sample_masks = np.array([training_masks[i] for i in indices])\n",
    "\n",
    "    # Generate predictions for the sample_images\n",
    "    predicted_masks = model.predict(sample_images)\n",
    "\n",
    "    # Convert predicted masks to binary\n",
    "    binary_predicted_masks = (predicted_masks > 0.114).astype(np.uint8)\n",
    "\n",
    "    # Set up the matplotlib figure and axes, based on the number of samples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)  # If only one sample, make sure axes are iterable\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(np.squeeze(sample_images[i]), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Display true mask for the image\n",
    "        axes[i, 1].imshow(np.squeeze(sample_masks[i]), cmap='gray')\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Display predicted mask for the image\n",
    "        axes[i, 2].imshow(np.squeeze(binary_predicted_masks[i]), cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_predictions(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Call the function after loading your images and masks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m verify_masks(images, masks, num_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mask_alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def verify_masks(images, masks, num_samples=3, mask_alpha=0.3):\n",
    "    \"\"\"\n",
    "    This function overlays the mask onto the image to verify position and size.\n",
    "    Parameters:\n",
    "    - images: numpy array of images.\n",
    "    - masks: numpy array of masks.\n",
    "    - num_samples: number of samples to display for verification.\n",
    "    - mask_alpha: transparency level of the mask overlay.\n",
    "    \"\"\"\n",
    "    # Set the number of images to display\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    # Create figure to display images and masks\n",
    "    plt.figure(figsize=(20, num_samples * 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.imshow(masks[i].squeeze(), cmap='jet', alpha=mask_alpha)  # 'jet' colormap for the mask\n",
    "        plt.title(f'Image {i} with Mask Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after loading your images and masks\n",
    "verify_masks(images, masks, num_samples=2, mask_alpha=0.3)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
