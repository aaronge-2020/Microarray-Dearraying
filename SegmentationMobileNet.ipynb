{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def resize_labels(labels, original_size, new_size):\n",
    "    scale_x = new_size[1] / original_size[1]\n",
    "    scale_y = new_size[0] / original_size[0]\n",
    "    resized_labels = []\n",
    "    for label in labels:\n",
    "        resized_label = {\n",
    "            'x': label['x'] * scale_x,\n",
    "            'y': label['y'] * scale_y,\n",
    "            'radius': label['radius'] * scale_x  # Assuming uniform scaling in x and y\n",
    "        }\n",
    "        resized_labels.append(resized_label)\n",
    "    return resized_labels\n",
    "\n",
    "def load_images_and_labels(image_paths, label_dir, new_size):\n",
    "    original_size = (1024, 1024)  # Original size of the images and labels\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Extract filename without extension to match with the label\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_file = os.path.join(label_dir, base_filename + '.json')\n",
    "\n",
    "        # Load and resize image\n",
    "        image = img_to_array(load_img(image_path, color_mode='rgb', target_size=new_size))\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load and resize corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        resized_json_data = resize_labels(json_data, original_size, new_size)\n",
    "        mask = create_mask_from_json(resized_json_data, shape=new_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, *new_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "def create_loocv_folds(image_files, augmented_image_dir):\n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "\n",
    "    for i in range(n):\n",
    "        test_image = image_files[i]\n",
    "        \n",
    "        # Ensure validation images are different from the test image and rotate them\n",
    "        val_indices = [(i + 1) % n, (i + 2) % n]\n",
    "        validation_images = [image_files[j] for j in val_indices]\n",
    "\n",
    "        # Remaining images for training, excluding the test and validation images\n",
    "        train_images = [img for idx, img in enumerate(image_files) if idx not in [i, val_indices[0], val_indices[1]]]\n",
    "\n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(20)]\n",
    "\n",
    "        folds.append((augmented_train_images, [test_image], validation_images))\n",
    "\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 256, 256, 32)         864       ['input_12[0][0]']            \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 256, 256, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 256, 256, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 256, 256, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 256, 256, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 256, 256, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 256, 256, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 256, 256, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 256, 256, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 256, 256, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 256, 256, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 257, 257, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 128, 128, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 128, 128, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 128, 128, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 128, 128, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 128, 128, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 128, 128, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 128, 128, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 128, 128, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 128, 128, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 129, 129, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 64, 64, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 64, 64, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 64, 64, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 64, 64, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 64, 64, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 64, 64, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 65, 65, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 32, 32, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 32, 32, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 32, 32, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 32, 32, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 32, 32, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 32, 32, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 32, 32, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 32, 32, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 32, 32, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 32, 32, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 32, 32, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 32, 32, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 32, 32, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 32, 32, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 32, 32, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 32, 32, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 32, 32, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 32, 32, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 32, 32, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 33, 33, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 16, 16, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 16, 16, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 16, 16, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 16, 16, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 16, 16, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 16, 16, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 16, 16, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 16, 16, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 16, 16, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 16, 16, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 16, 16, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 16, 16, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 16, 16, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 16, 16, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)         (None, 16, 16, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_86 (Ba  (None, 16, 16, 256)          1024      ['conv2d_112[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_86[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenat  (None, 16, 16, 1024)         0         ['conv2d_113[0][0]',          \n",
      " e)                                                                  'conv2d_114[0][0]',          \n",
      "                                                                     'conv2d_115[0][0]',          \n",
      "                                                                     'conv2d_116[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)         (None, 16, 16, 256)          262400    ['concatenate_19[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_87 (Ba  (None, 16, 16, 256)          1024      ['conv2d_117[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_87[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_31 (UpSampli  (None, 32, 32, 256)          0         ['conv2d_118[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_32 (UpSampli  (None, 64, 64, 256)          0         ['up_sampling2d_31[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_33 (UpSampli  (None, 128, 128, 256)        0         ['up_sampling2d_32[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_34 (UpSampli  (None, 256, 256, 256)        0         ['up_sampling2d_33[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_35 (UpSampli  (None, 512, 512, 256)        0         ['up_sampling2d_34[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)         (None, 512, 512, 1)          257       ['up_sampling2d_35[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4752449 (18.13 MB)\n",
      "Trainable params: 2493441 (9.51 MB)\n",
      "Non-trainable params: 2259008 (8.62 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "def create_deeplabv3_plus_binary_model(input_shape=(512, 512, 3), l2_lambda=0.01, fine_tune_at=200):\n",
    "    # Load MobileNetV2 pre-trained on ImageNet as the backbone\n",
    "    backbone = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Unfreeze the top layers of the model for fine-tuning\n",
    "    backbone.trainable = True\n",
    "    for layer in backbone.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Use features from the backbone network - feature extraction\n",
    "    x = backbone.output\n",
    "\n",
    "    # Apply atrous convolutions / spatial pyramid pooling\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling (ASPP)\n",
    "    b0 = layers.Conv2D(256, (1, 1), activation='relu', padding='same', dilation_rate=1, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=6, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=12, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=18, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "\n",
    "    # Concatenate the atrous and image-level features\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3])\n",
    "\n",
    "    # Add a convolutional layer on top of the concatenated features\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Decoder\n",
    "    # Start with a simple 1x1 convolution\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Perform upsampling in steps to reach the output size of 512x512.\n",
    "    # Each UpSampling2D layer doubles the size of the feature map\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 32x32\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 64x64\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 128x128\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 256x256\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 512x512\n",
    "\n",
    "    # Output layer for binary segmentation\n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = models.Model(inputs=backbone.input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_deeplabv3_plus_binary_model()\n",
    "\n",
    "# Compile the model (if you're about to train it)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary to verify the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3), num_filters=16, depth=2, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)         (None, 512, 512, 16)         448       ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_88 (Ba  (None, 512, 512, 16)         64        ['conv2d_120[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_80 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_88[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_80[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_89 (Ba  (None, 512, 512, 16)         64        ['conv2d_121[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_81 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_89[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooli  (None, 256, 256, 16)         0         ['activation_81[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 256, 256, 16)         0         ['max_pooling2d_16[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_122 (Conv2D)         (None, 256, 256, 32)         4640      ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (Ba  (None, 256, 256, 32)         128       ['conv2d_122[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_82 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_90[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_82[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_91 (Ba  (None, 256, 256, 32)         128       ['conv2d_123[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_83 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_91[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooli  (None, 128, 128, 32)         0         ['activation_83[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 128, 128, 32)         0         ['max_pooling2d_17[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)         (None, 128, 128, 64)         18496     ['dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 128, 128, 64)         256       ['conv2d_124[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_84 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)         (None, 128, 128, 64)         36928     ['activation_84[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 128, 128, 64)         256       ['conv2d_125[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_85 (Activation)  (None, 128, 128, 64)         0         ['batch_normalization_93[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_36 (UpSampli  (None, 256, 256, 64)         0         ['activation_85[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_36[0][0]',    \n",
      " e)                                                                  'activation_83[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)         (None, 256, 256, 32)         27680     ['concatenate_20[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 256, 256, 32)         128       ['conv2d_126[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_86 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_94[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_86[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 256, 256, 32)         128       ['conv2d_127[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_87 (Activation)  (None, 256, 256, 32)         0         ['batch_normalization_95[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " up_sampling2d_37 (UpSampli  (None, 512, 512, 32)         0         ['activation_87[0][0]']       \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenat  (None, 512, 512, 48)         0         ['up_sampling2d_37[0][0]',    \n",
      " e)                                                                  'activation_81[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)         (None, 512, 512, 16)         6928      ['concatenate_21[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, 512, 512, 16)         64        ['conv2d_128[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_88 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_96[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_88[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, 512, 512, 16)         64        ['conv2d_129[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_89 (Activation)  (None, 512, 512, 16)         0         ['batch_normalization_97[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)         (None, 512, 512, 1)          17        ['activation_89[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119553 (467.00 KB)\n",
      "Trainable params: 118913 (464.50 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = unet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a Learning Rate Schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 15:\n",
    "        return lr\n",
    "    elif epoch%2 == 0:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def train_unet(model, train_images, train_masks, val_images, val_masks, epochs=300, batch_size=32, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=1)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model with the given training and validation data\n",
    "    history = model.fit(\n",
    "        x=train_images, \n",
    "        y=train_masks, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(val_images, val_masks), \n",
    "        callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5258 - auc: 0.8568 - accuracy: 0.7838 - precision: 0.4831 - recall: 0.7817 \n",
      "Epoch 1: val_loss improved from inf to 0.65653, saving model to pixel_core_fold_6.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 137s 13s/step - loss: 0.5258 - auc: 0.8568 - accuracy: 0.7838 - precision: 0.4831 - recall: 0.7817 - val_loss: 0.6565 - val_auc: 0.4782 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3033 - auc: 0.9677 - accuracy: 0.9191 - precision: 0.7534 - recall: 0.9003 \n",
      "Epoch 2: val_loss did not improve from 0.65653\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.3033 - auc: 0.9677 - accuracy: 0.9191 - precision: 0.7534 - recall: 0.9003 - val_loss: 1.0309 - val_auc: 0.3383 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2351 - auc: 0.9760 - accuracy: 0.9454 - precision: 0.8565 - recall: 0.8815 \n",
      "Epoch 3: val_loss did not improve from 0.65653\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.2351 - auc: 0.9760 - accuracy: 0.9454 - precision: 0.8565 - recall: 0.8815 - val_loss: 0.9950 - val_auc: 0.4059 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2103 - auc: 0.9782 - accuracy: 0.9498 - precision: 0.8835 - recall: 0.8701 \n",
      "Epoch 4: val_loss did not improve from 0.65653\n",
      "10/10 [==============================] - 125s 12s/step - loss: 0.2103 - auc: 0.9782 - accuracy: 0.9498 - precision: 0.8835 - recall: 0.8701 - val_loss: 0.6747 - val_auc: 0.4258 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1956 - auc: 0.9795 - accuracy: 0.9510 - precision: 0.8965 - recall: 0.8600 \n",
      "Epoch 5: val_loss improved from 0.65653 to 0.54515, saving model to pixel_core_fold_6.hdf5\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1956 - auc: 0.9795 - accuracy: 0.9510 - precision: 0.8965 - recall: 0.8600 - val_loss: 0.5452 - val_auc: 0.4138 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1848 - auc: 0.9789 - accuracy: 0.9516 - precision: 0.9024 - recall: 0.8567 \n",
      "Epoch 6: val_loss improved from 0.54515 to 0.49490, saving model to pixel_core_fold_6.hdf5\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.1848 - auc: 0.9789 - accuracy: 0.9516 - precision: 0.9024 - recall: 0.8567 - val_loss: 0.4949 - val_auc: 0.6114 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1761 - auc: 0.9805 - accuracy: 0.9512 - precision: 0.8834 - recall: 0.8779 \n",
      "Epoch 7: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1761 - auc: 0.9805 - accuracy: 0.9512 - precision: 0.8834 - recall: 0.8779 - val_loss: 0.5199 - val_auc: 0.6392 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1696 - auc: 0.9809 - accuracy: 0.9508 - precision: 0.8851 - recall: 0.8734 \n",
      "Epoch 8: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 124s 12s/step - loss: 0.1696 - auc: 0.9809 - accuracy: 0.9508 - precision: 0.8851 - recall: 0.8734 - val_loss: 0.5757 - val_auc: 0.6473 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1625 - auc: 0.9812 - accuracy: 0.9524 - precision: 0.9055 - recall: 0.8570 \n",
      "Epoch 9: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 126s 13s/step - loss: 0.1625 - auc: 0.9812 - accuracy: 0.9524 - precision: 0.9055 - recall: 0.8570 - val_loss: 0.6410 - val_auc: 0.6463 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1560 - auc: 0.9836 - accuracy: 0.9528 - precision: 0.8869 - recall: 0.8823 \n",
      "Epoch 10: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 130s 13s/step - loss: 0.1560 - auc: 0.9836 - accuracy: 0.9528 - precision: 0.8869 - recall: 0.8823 - val_loss: 0.6810 - val_auc: 0.5976 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1536 - auc: 0.9825 - accuracy: 0.9524 - precision: 0.8940 - recall: 0.8708 \n",
      "Epoch 11: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 122s 12s/step - loss: 0.1536 - auc: 0.9825 - accuracy: 0.9524 - precision: 0.8940 - recall: 0.8708 - val_loss: 0.7141 - val_auc: 0.5481 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1482 - auc: 0.9834 - accuracy: 0.9536 - precision: 0.9060 - recall: 0.8633 \n",
      "Epoch 12: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1482 - auc: 0.9834 - accuracy: 0.9536 - precision: 0.9060 - recall: 0.8633 - val_loss: 0.7144 - val_auc: 0.5278 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1445 - auc: 0.9840 - accuracy: 0.9536 - precision: 0.8909 - recall: 0.8819 \n",
      "Epoch 13: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1445 - auc: 0.9840 - accuracy: 0.9536 - precision: 0.8909 - recall: 0.8819 - val_loss: 0.7462 - val_auc: 0.5163 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1408 - auc: 0.9847 - accuracy: 0.9545 - precision: 0.9002 - recall: 0.8750 \n",
      "Epoch 14: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1408 - auc: 0.9847 - accuracy: 0.9545 - precision: 0.9002 - recall: 0.8750 - val_loss: 0.7656 - val_auc: 0.4643 - val_accuracy: 0.8051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1395 - auc: 0.9844 - accuracy: 0.9540 - precision: 0.8999 - recall: 0.8729 \n",
      "Epoch 15: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 121s 12s/step - loss: 0.1395 - auc: 0.9844 - accuracy: 0.9540 - precision: 0.8999 - recall: 0.8729 - val_loss: 0.7679 - val_auc: 0.4374 - val_accuracy: 0.8053 - val_precision: 1.0000 - val_recall: 0.0010 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1382 - auc: 0.9841 - accuracy: 0.9538 - precision: 0.8941 - recall: 0.8787 \n",
      "Epoch 16: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.1382 - auc: 0.9841 - accuracy: 0.9538 - precision: 0.8941 - recall: 0.8787 - val_loss: 0.7867 - val_auc: 0.5082 - val_accuracy: 0.8064 - val_precision: 1.0000 - val_recall: 0.0070 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1364 - auc: 0.9845 - accuracy: 0.9540 - precision: 0.8980 - recall: 0.8749 \n",
      "Epoch 17: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 125s 12s/step - loss: 0.1364 - auc: 0.9845 - accuracy: 0.9540 - precision: 0.8980 - recall: 0.8749 - val_loss: 0.7786 - val_auc: 0.5134 - val_accuracy: 0.8077 - val_precision: 0.9986 - val_recall: 0.0138 - lr: 9.0484e-04\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1328 - auc: 0.9853 - accuracy: 0.9552 - precision: 0.9096 - recall: 0.8676 \n",
      "Epoch 18: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 122s 12s/step - loss: 0.1328 - auc: 0.9853 - accuracy: 0.9552 - precision: 0.9096 - recall: 0.8676 - val_loss: 0.7750 - val_auc: 0.5159 - val_accuracy: 0.8097 - val_precision: 0.9915 - val_recall: 0.0239 - lr: 9.0484e-04\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1314 - auc: 0.9853 - accuracy: 0.9550 - precision: 0.8968 - recall: 0.8822 \n",
      "Epoch 19: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 126s 12s/step - loss: 0.1314 - auc: 0.9853 - accuracy: 0.9550 - precision: 0.8968 - recall: 0.8822 - val_loss: 0.7703 - val_auc: 0.4834 - val_accuracy: 0.8130 - val_precision: 0.9879 - val_recall: 0.0414 - lr: 8.1873e-04\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1294 - auc: 0.9859 - accuracy: 0.9555 - precision: 0.8983 - recall: 0.8830 \n",
      "Epoch 20: val_loss did not improve from 0.49490\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.1294 - auc: 0.9859 - accuracy: 0.9555 - precision: 0.8983 - recall: 0.8830 - val_loss: 0.7648 - val_auc: 0.5142 - val_accuracy: 0.8158 - val_precision: 0.9816 - val_recall: 0.0563 - lr: 8.1873e-04\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1282 - auc: 0.9859 - accuracy: 0.9559 - precision: 0.9046 - recall: 0.8773 \n",
      "Epoch 21: val_loss did not improve from 0.49490\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.1282 - auc: 0.9859 - accuracy: 0.9559 - precision: 0.9046 - recall: 0.8773 - val_loss: 0.7440 - val_auc: 0.5959 - val_accuracy: 0.8202 - val_precision: 0.9769 - val_recall: 0.0794 - lr: 7.4082e-04\n",
      "Epoch 21: early stopping\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4422 - auc: 0.6544 - accuracy: 0.8360 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4745 - auc: 0.8800 - accuracy: 0.8442 - precision: 0.6043 - recall: 0.6778 \n",
      "Epoch 1: val_loss improved from inf to 0.59847, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.4745 - auc: 0.8800 - accuracy: 0.8442 - precision: 0.6043 - recall: 0.6778 - val_loss: 0.5985 - val_auc: 0.6770 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2910 - auc: 0.9695 - accuracy: 0.9370 - precision: 0.8170 - recall: 0.8895 \n",
      "Epoch 2: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.2910 - auc: 0.9695 - accuracy: 0.9370 - precision: 0.8170 - recall: 0.8895 - val_loss: 0.9679 - val_auc: 0.5131 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2445 - auc: 0.9714 - accuracy: 0.9472 - precision: 0.8661 - recall: 0.8758 \n",
      "Epoch 3: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.2445 - auc: 0.9714 - accuracy: 0.9472 - precision: 0.8661 - recall: 0.8758 - val_loss: 1.5325 - val_auc: 0.4891 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2259 - auc: 0.9768 - accuracy: 0.9492 - precision: 0.8656 - recall: 0.8885 \n",
      "Epoch 4: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.2259 - auc: 0.9768 - accuracy: 0.9492 - precision: 0.8656 - recall: 0.8885 - val_loss: 1.6675 - val_auc: 0.4904 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2137 - auc: 0.9760 - accuracy: 0.9510 - precision: 0.8877 - recall: 0.8691 \n",
      "Epoch 5: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 125s 12s/step - loss: 0.2137 - auc: 0.9760 - accuracy: 0.9510 - precision: 0.8877 - recall: 0.8691 - val_loss: 2.0042 - val_auc: 0.4926 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2025 - auc: 0.9783 - accuracy: 0.9502 - precision: 0.8694 - recall: 0.8884 \n",
      "Epoch 6: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.2025 - auc: 0.9783 - accuracy: 0.9502 - precision: 0.8694 - recall: 0.8884 - val_loss: 1.5266 - val_auc: 0.4885 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1928 - auc: 0.9789 - accuracy: 0.9521 - precision: 0.8941 - recall: 0.8670 \n",
      "Epoch 7: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.1928 - auc: 0.9789 - accuracy: 0.9521 - precision: 0.8941 - recall: 0.8670 - val_loss: 1.2971 - val_auc: 0.4914 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1845 - auc: 0.9807 - accuracy: 0.9518 - precision: 0.8829 - recall: 0.8795 \n",
      "Epoch 8: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 125s 13s/step - loss: 0.1845 - auc: 0.9807 - accuracy: 0.9518 - precision: 0.8829 - recall: 0.8795 - val_loss: 0.7224 - val_auc: 0.8539 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1776 - auc: 0.9813 - accuracy: 0.9522 - precision: 0.8883 - recall: 0.8753 \n",
      "Epoch 9: val_loss did not improve from 0.59847\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.1776 - auc: 0.9813 - accuracy: 0.9522 - precision: 0.8883 - recall: 0.8753 - val_loss: 0.6341 - val_auc: 0.8822 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1720 - auc: 0.9812 - accuracy: 0.9527 - precision: 0.8956 - recall: 0.8690 \n",
      "Epoch 10: val_loss improved from 0.59847 to 0.54344, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1720 - auc: 0.9812 - accuracy: 0.9527 - precision: 0.8956 - recall: 0.8690 - val_loss: 0.5434 - val_auc: 0.9104 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1654 - auc: 0.9810 - accuracy: 0.9538 - precision: 0.9051 - recall: 0.8635 \n",
      "Epoch 11: val_loss improved from 0.54344 to 0.53514, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.1654 - auc: 0.9810 - accuracy: 0.9538 - precision: 0.9051 - recall: 0.8635 - val_loss: 0.5351 - val_auc: 0.9311 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1601 - auc: 0.9829 - accuracy: 0.9536 - precision: 0.8877 - recall: 0.8838 \n",
      "Epoch 12: val_loss improved from 0.53514 to 0.50912, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.1601 - auc: 0.9829 - accuracy: 0.9536 - precision: 0.8877 - recall: 0.8838 - val_loss: 0.5091 - val_auc: 0.9161 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1570 - auc: 0.9830 - accuracy: 0.9530 - precision: 0.8973 - recall: 0.8683 \n",
      "Epoch 13: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1570 - auc: 0.9830 - accuracy: 0.9530 - precision: 0.8973 - recall: 0.8683 - val_loss: 0.5374 - val_auc: 0.8626 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1519 - auc: 0.9824 - accuracy: 0.9544 - precision: 0.9067 - recall: 0.8646 \n",
      "Epoch 14: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 136s 13s/step - loss: 0.1519 - auc: 0.9824 - accuracy: 0.9544 - precision: 0.9067 - recall: 0.8646 - val_loss: 0.6323 - val_auc: 0.6762 - val_accuracy: 0.7986 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1482 - auc: 0.9846 - accuracy: 0.9544 - precision: 0.8898 - recall: 0.8855 \n",
      "Epoch 15: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 145s 14s/step - loss: 0.1482 - auc: 0.9846 - accuracy: 0.9544 - precision: 0.8898 - recall: 0.8855 - val_loss: 0.6169 - val_auc: 0.7598 - val_accuracy: 0.7987 - val_precision: 1.0000 - val_recall: 5.6811e-04 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1458 - auc: 0.9830 - accuracy: 0.9543 - precision: 0.9061 - recall: 0.8650 \n",
      "Epoch 16: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1458 - auc: 0.9830 - accuracy: 0.9543 - precision: 0.9061 - recall: 0.8650 - val_loss: 0.6390 - val_auc: 0.8568 - val_accuracy: 0.7987 - val_precision: 1.0000 - val_recall: 9.0897e-04 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1426 - auc: 0.9842 - accuracy: 0.9547 - precision: 0.8974 - recall: 0.8776 \n",
      "Epoch 17: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1426 - auc: 0.9842 - accuracy: 0.9547 - precision: 0.8974 - recall: 0.8776 - val_loss: 0.6155 - val_auc: 0.8962 - val_accuracy: 0.7988 - val_precision: 1.0000 - val_recall: 0.0013 - lr: 9.0484e-04\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1410 - auc: 0.9836 - accuracy: 0.9547 - precision: 0.9104 - recall: 0.8624 \n",
      "Epoch 18: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 131s 13s/step - loss: 0.1410 - auc: 0.9836 - accuracy: 0.9547 - precision: 0.9104 - recall: 0.8624 - val_loss: 0.6352 - val_auc: 0.9051 - val_accuracy: 0.7989 - val_precision: 1.0000 - val_recall: 0.0018 - lr: 9.0484e-04\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1384 - auc: 0.9847 - accuracy: 0.9549 - precision: 0.8890 - recall: 0.8893 \n",
      "Epoch 19: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 136s 13s/step - loss: 0.1384 - auc: 0.9847 - accuracy: 0.9549 - precision: 0.8890 - recall: 0.8893 - val_loss: 0.6095 - val_auc: 0.9082 - val_accuracy: 0.7995 - val_precision: 1.0000 - val_recall: 0.0049 - lr: 8.1873e-04\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1371 - auc: 0.9846 - accuracy: 0.9547 - precision: 0.9083 - recall: 0.8645 \n",
      "Epoch 20: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.1371 - auc: 0.9846 - accuracy: 0.9547 - precision: 0.9083 - recall: 0.8645 - val_loss: 0.5979 - val_auc: 0.8983 - val_accuracy: 0.8006 - val_precision: 1.0000 - val_recall: 0.0099 - lr: 8.1873e-04\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1352 - auc: 0.9844 - accuracy: 0.9550 - precision: 0.9040 - recall: 0.8713 \n",
      "Epoch 21: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1352 - auc: 0.9844 - accuracy: 0.9550 - precision: 0.9040 - recall: 0.8713 - val_loss: 0.6241 - val_auc: 0.8777 - val_accuracy: 0.8015 - val_precision: 1.0000 - val_recall: 0.0146 - lr: 7.4082e-04\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1331 - auc: 0.9854 - accuracy: 0.9554 - precision: 0.8972 - recall: 0.8816 \n",
      "Epoch 22: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1331 - auc: 0.9854 - accuracy: 0.9554 - precision: 0.8972 - recall: 0.8816 - val_loss: 0.6248 - val_auc: 0.8909 - val_accuracy: 0.8027 - val_precision: 1.0000 - val_recall: 0.0208 - lr: 7.4082e-04\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1308 - auc: 0.9853 - accuracy: 0.9561 - precision: 0.9128 - recall: 0.8668 \n",
      "Epoch 23: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.1308 - auc: 0.9853 - accuracy: 0.9561 - precision: 0.9128 - recall: 0.8668 - val_loss: 0.6055 - val_auc: 0.8773 - val_accuracy: 0.8051 - val_precision: 1.0000 - val_recall: 0.0324 - lr: 6.7032e-04\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1305 - auc: 0.9856 - accuracy: 0.9558 - precision: 0.8969 - recall: 0.8842 \n",
      "Epoch 24: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1305 - auc: 0.9856 - accuracy: 0.9558 - precision: 0.8969 - recall: 0.8842 - val_loss: 0.5893 - val_auc: 0.8010 - val_accuracy: 0.8088 - val_precision: 0.9991 - val_recall: 0.0508 - lr: 6.7032e-04\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1286 - auc: 0.9858 - accuracy: 0.9562 - precision: 0.9106 - recall: 0.8700 \n",
      "Epoch 25: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1286 - auc: 0.9858 - accuracy: 0.9562 - precision: 0.9106 - recall: 0.8700 - val_loss: 0.5826 - val_auc: 0.7801 - val_accuracy: 0.8131 - val_precision: 0.9987 - val_recall: 0.0722 - lr: 6.0653e-04\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1288 - auc: 0.9857 - accuracy: 0.9558 - precision: 0.9023 - recall: 0.8778 \n",
      "Epoch 26: val_loss did not improve from 0.50912\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.1288 - auc: 0.9857 - accuracy: 0.9558 - precision: 0.9023 - recall: 0.8778 - val_loss: 0.5532 - val_auc: 0.8180 - val_accuracy: 0.8179 - val_precision: 0.9975 - val_recall: 0.0964 - lr: 6.0653e-04\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1270 - auc: 0.9858 - accuracy: 0.9564 - precision: 0.9030 - recall: 0.8800 \n",
      "Epoch 27: val_loss improved from 0.50912 to 0.47669, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 131s 13s/step - loss: 0.1270 - auc: 0.9858 - accuracy: 0.9564 - precision: 0.9030 - recall: 0.8800 - val_loss: 0.4767 - val_auc: 0.8225 - val_accuracy: 0.8334 - val_precision: 0.9953 - val_recall: 0.1737 - lr: 5.4881e-04\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1260 - auc: 0.9861 - accuracy: 0.9564 - precision: 0.9140 - recall: 0.8671 \n",
      "Epoch 28: val_loss improved from 0.47669 to 0.42112, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.1260 - auc: 0.9861 - accuracy: 0.9564 - precision: 0.9140 - recall: 0.8671 - val_loss: 0.4211 - val_auc: 0.8938 - val_accuracy: 0.8453 - val_precision: 0.9934 - val_recall: 0.2338 - lr: 5.4881e-04\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1243 - auc: 0.9870 - accuracy: 0.9567 - precision: 0.8952 - recall: 0.8917 \n",
      "Epoch 29: val_loss improved from 0.42112 to 0.33128, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 144s 15s/step - loss: 0.1243 - auc: 0.9870 - accuracy: 0.9567 - precision: 0.8952 - recall: 0.8917 - val_loss: 0.3313 - val_auc: 0.9270 - val_accuracy: 0.8662 - val_precision: 0.9886 - val_recall: 0.3398 - lr: 4.9659e-04\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1257 - auc: 0.9858 - accuracy: 0.9562 - precision: 0.9081 - recall: 0.8730 \n",
      "Epoch 30: val_loss improved from 0.33128 to 0.26976, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1257 - auc: 0.9858 - accuracy: 0.9562 - precision: 0.9081 - recall: 0.8730 - val_loss: 0.2698 - val_auc: 0.9414 - val_accuracy: 0.8887 - val_precision: 0.9829 - val_recall: 0.4552 - lr: 4.9659e-04\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1229 - auc: 0.9865 - accuracy: 0.9571 - precision: 0.9136 - recall: 0.8714 \n",
      "Epoch 31: val_loss improved from 0.26976 to 0.22488, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 120s 12s/step - loss: 0.1229 - auc: 0.9865 - accuracy: 0.9571 - precision: 0.9136 - recall: 0.8714 - val_loss: 0.2249 - val_auc: 0.9538 - val_accuracy: 0.9089 - val_precision: 0.9742 - val_recall: 0.5628 - lr: 4.4933e-04\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1234 - auc: 0.9865 - accuracy: 0.9567 - precision: 0.9046 - recall: 0.8799 \n",
      "Epoch 32: val_loss improved from 0.22488 to 0.20195, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 136s 13s/step - loss: 0.1234 - auc: 0.9865 - accuracy: 0.9567 - precision: 0.9046 - recall: 0.8799 - val_loss: 0.2020 - val_auc: 0.9634 - val_accuracy: 0.9212 - val_precision: 0.9691 - val_recall: 0.6290 - lr: 4.4933e-04\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1222 - auc: 0.9869 - accuracy: 0.9569 - precision: 0.9077 - recall: 0.8772 \n",
      "Epoch 33: val_loss improved from 0.20195 to 0.18031, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 127s 13s/step - loss: 0.1222 - auc: 0.9869 - accuracy: 0.9569 - precision: 0.9077 - recall: 0.8772 - val_loss: 0.1803 - val_auc: 0.9693 - val_accuracy: 0.9368 - val_precision: 0.9532 - val_recall: 0.7219 - lr: 4.0657e-04\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1214 - auc: 0.9866 - accuracy: 0.9571 - precision: 0.9109 - recall: 0.8746 \n",
      "Epoch 34: val_loss improved from 0.18031 to 0.17332, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.1214 - auc: 0.9866 - accuracy: 0.9571 - precision: 0.9109 - recall: 0.8746 - val_loss: 0.1733 - val_auc: 0.9718 - val_accuracy: 0.9425 - val_precision: 0.9468 - val_recall: 0.7569 - lr: 4.0657e-04\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1201 - auc: 0.9870 - accuracy: 0.9577 - precision: 0.9050 - recall: 0.8848 \n",
      "Epoch 35: val_loss improved from 0.17332 to 0.16668, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1201 - auc: 0.9870 - accuracy: 0.9577 - precision: 0.9050 - recall: 0.8848 - val_loss: 0.1667 - val_auc: 0.9737 - val_accuracy: 0.9478 - val_precision: 0.9328 - val_recall: 0.7985 - lr: 3.6788e-04\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1209 - auc: 0.9870 - accuracy: 0.9571 - precision: 0.9052 - recall: 0.8814 \n",
      "Epoch 36: val_loss did not improve from 0.16668\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.1209 - auc: 0.9870 - accuracy: 0.9571 - precision: 0.9052 - recall: 0.8814 - val_loss: 0.1706 - val_auc: 0.9747 - val_accuracy: 0.9494 - val_precision: 0.9279 - val_recall: 0.8121 - lr: 3.6788e-04\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1192 - auc: 0.9875 - accuracy: 0.9576 - precision: 0.9094 - recall: 0.8790 \n",
      "Epoch 37: val_loss improved from 0.16668 to 0.16617, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.1192 - auc: 0.9875 - accuracy: 0.9576 - precision: 0.9094 - recall: 0.8790 - val_loss: 0.1662 - val_auc: 0.9770 - val_accuracy: 0.9522 - val_precision: 0.9116 - val_recall: 0.8445 - lr: 3.3287e-04\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1189 - auc: 0.9873 - accuracy: 0.9576 - precision: 0.9082 - recall: 0.8807 \n",
      "Epoch 38: val_loss improved from 0.16617 to 0.16105, saving model to pixel_core_fold_7.hdf5\n",
      "10/10 [==============================] - 126s 13s/step - loss: 0.1189 - auc: 0.9873 - accuracy: 0.9576 - precision: 0.9082 - recall: 0.8807 - val_loss: 0.1610 - val_auc: 0.9775 - val_accuracy: 0.9531 - val_precision: 0.9032 - val_recall: 0.8595 - lr: 3.3287e-04\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1182 - auc: 0.9873 - accuracy: 0.9579 - precision: 0.9087 - recall: 0.8819 \n",
      "Epoch 39: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1182 - auc: 0.9873 - accuracy: 0.9579 - precision: 0.9087 - recall: 0.8819 - val_loss: 0.1677 - val_auc: 0.9792 - val_accuracy: 0.9527 - val_precision: 0.8882 - val_recall: 0.8754 - lr: 3.0119e-04\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1171 - auc: 0.9878 - accuracy: 0.9582 - precision: 0.9110 - recall: 0.8803 \n",
      "Epoch 40: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.1171 - auc: 0.9878 - accuracy: 0.9582 - precision: 0.9110 - recall: 0.8803 - val_loss: 0.1674 - val_auc: 0.9804 - val_accuracy: 0.9517 - val_precision: 0.8713 - val_recall: 0.8922 - lr: 3.0119e-04\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1181 - auc: 0.9874 - accuracy: 0.9576 - precision: 0.9102 - recall: 0.8782 \n",
      "Epoch 41: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 125s 13s/step - loss: 0.1181 - auc: 0.9874 - accuracy: 0.9576 - precision: 0.9102 - recall: 0.8782 - val_loss: 0.1630 - val_auc: 0.9811 - val_accuracy: 0.9511 - val_precision: 0.8610 - val_recall: 0.9032 - lr: 2.7253e-04\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1177 - auc: 0.9875 - accuracy: 0.9578 - precision: 0.9035 - recall: 0.8874 \n",
      "Epoch 42: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1177 - auc: 0.9875 - accuracy: 0.9578 - precision: 0.9035 - recall: 0.8874 - val_loss: 0.2002 - val_auc: 0.9825 - val_accuracy: 0.9368 - val_precision: 0.7935 - val_recall: 0.9276 - lr: 2.7253e-04\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1172 - auc: 0.9877 - accuracy: 0.9577 - precision: 0.9183 - recall: 0.8695 \n",
      "Epoch 43: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 144s 14s/step - loss: 0.1172 - auc: 0.9877 - accuracy: 0.9577 - precision: 0.9183 - recall: 0.8695 - val_loss: 0.1995 - val_auc: 0.9805 - val_accuracy: 0.9408 - val_precision: 0.8121 - val_recall: 0.9185 - lr: 2.4660e-04\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1169 - auc: 0.9877 - accuracy: 0.9579 - precision: 0.9006 - recall: 0.8916 \n",
      "Epoch 44: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1169 - auc: 0.9877 - accuracy: 0.9579 - precision: 0.9006 - recall: 0.8916 - val_loss: 0.2095 - val_auc: 0.9830 - val_accuracy: 0.9296 - val_precision: 0.7657 - val_recall: 0.9376 - lr: 2.4660e-04\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9879 - accuracy: 0.9580 - precision: 0.9159 - recall: 0.8739 \n",
      "Epoch 45: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.1160 - auc: 0.9879 - accuracy: 0.9580 - precision: 0.9159 - recall: 0.8739 - val_loss: 0.1887 - val_auc: 0.9848 - val_accuracy: 0.9357 - val_precision: 0.7830 - val_recall: 0.9419 - lr: 2.2313e-04\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1164 - auc: 0.9876 - accuracy: 0.9580 - precision: 0.9067 - recall: 0.8844 \n",
      "Epoch 46: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 131s 13s/step - loss: 0.1164 - auc: 0.9876 - accuracy: 0.9580 - precision: 0.9067 - recall: 0.8844 - val_loss: 0.2632 - val_auc: 0.9863 - val_accuracy: 0.9010 - val_precision: 0.6787 - val_recall: 0.9656 - lr: 2.2313e-04\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1153 - auc: 0.9881 - accuracy: 0.9584 - precision: 0.9098 - recall: 0.8828 \n",
      "Epoch 47: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.1153 - auc: 0.9881 - accuracy: 0.9584 - precision: 0.9098 - recall: 0.8828 - val_loss: 0.2420 - val_auc: 0.9870 - val_accuracy: 0.9131 - val_precision: 0.7094 - val_recall: 0.9633 - lr: 2.0190e-04\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1155 - auc: 0.9878 - accuracy: 0.9582 - precision: 0.9101 - recall: 0.8816 \n",
      "Epoch 48: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1155 - auc: 0.9878 - accuracy: 0.9582 - precision: 0.9101 - recall: 0.8816 - val_loss: 0.2551 - val_auc: 0.9874 - val_accuracy: 0.9044 - val_precision: 0.6857 - val_recall: 0.9699 - lr: 2.0190e-04\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1148 - auc: 0.9880 - accuracy: 0.9584 - precision: 0.9124 - recall: 0.8799 \n",
      "Epoch 49: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 128s 13s/step - loss: 0.1148 - auc: 0.9880 - accuracy: 0.9584 - precision: 0.9124 - recall: 0.8799 - val_loss: 0.2272 - val_auc: 0.9877 - val_accuracy: 0.9140 - val_precision: 0.7106 - val_recall: 0.9669 - lr: 1.8268e-04\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1148 - auc: 0.9882 - accuracy: 0.9583 - precision: 0.9080 - recall: 0.8847 \n",
      "Epoch 50: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 126s 13s/step - loss: 0.1148 - auc: 0.9882 - accuracy: 0.9583 - precision: 0.9080 - recall: 0.8847 - val_loss: 0.2037 - val_auc: 0.9878 - val_accuracy: 0.9225 - val_precision: 0.7345 - val_recall: 0.9633 - lr: 1.8268e-04\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1135 - auc: 0.9885 - accuracy: 0.9588 - precision: 0.9123 - recall: 0.8820 \n",
      "Epoch 51: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1135 - auc: 0.9885 - accuracy: 0.9588 - precision: 0.9123 - recall: 0.8820 - val_loss: 0.2257 - val_auc: 0.9881 - val_accuracy: 0.9133 - val_precision: 0.7078 - val_recall: 0.9699 - lr: 1.6530e-04\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1136 - auc: 0.9882 - accuracy: 0.9587 - precision: 0.9116 - recall: 0.8826 \n",
      "Epoch 52: val_loss did not improve from 0.16105\n",
      "10/10 [==============================] - 125s 12s/step - loss: 0.1136 - auc: 0.9882 - accuracy: 0.9587 - precision: 0.9116 - recall: 0.8826 - val_loss: 0.2434 - val_auc: 0.9884 - val_accuracy: 0.9043 - val_precision: 0.6843 - val_recall: 0.9743 - lr: 1.6530e-04\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1137 - auc: 0.9882 - accuracy: 0.9587 - precision: 0.9102 - recall: 0.8840 \n",
      "Epoch 53: val_loss did not improve from 0.16105\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1137 - auc: 0.9882 - accuracy: 0.9587 - precision: 0.9102 - recall: 0.8840 - val_loss: 0.3011 - val_auc: 0.9883 - val_accuracy: 0.8783 - val_precision: 0.6263 - val_recall: 0.9813 - lr: 1.4957e-04\n",
      "Epoch 53: early stopping\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2001 - auc: 0.9928 - accuracy: 0.9353 - precision: 0.7342 - recall: 0.9853\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5217 - auc: 0.8608 - accuracy: 0.7838 - precision: 0.4800 - recall: 0.7713 \n",
      "Epoch 1: val_loss improved from inf to 0.47889, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.5217 - auc: 0.8608 - accuracy: 0.7838 - precision: 0.4800 - recall: 0.7713 - val_loss: 0.4789 - val_auc: 0.7462 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3171 - auc: 0.9647 - accuracy: 0.9066 - precision: 0.7111 - recall: 0.9094 \n",
      "Epoch 2: val_loss did not improve from 0.47889\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.3171 - auc: 0.9647 - accuracy: 0.9066 - precision: 0.7111 - recall: 0.9094 - val_loss: 0.7819 - val_auc: 0.7371 - val_accuracy: 0.8151 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2580 - auc: 0.9746 - accuracy: 0.9426 - precision: 0.8446 - recall: 0.8794 \n",
      "Epoch 3: val_loss did not improve from 0.47889\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.2580 - auc: 0.9746 - accuracy: 0.9426 - precision: 0.8446 - recall: 0.8794 - val_loss: 0.6454 - val_auc: 0.7381 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2340 - auc: 0.9730 - accuracy: 0.9470 - precision: 0.8742 - recall: 0.8631 \n",
      "Epoch 4: val_loss improved from 0.47889 to 0.47593, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.2340 - auc: 0.9730 - accuracy: 0.9470 - precision: 0.8742 - recall: 0.8631 - val_loss: 0.4759 - val_auc: 0.9201 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2188 - auc: 0.9769 - accuracy: 0.9475 - precision: 0.8695 - recall: 0.8728 \n",
      "Epoch 5: val_loss improved from 0.47593 to 0.44519, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.2188 - auc: 0.9769 - accuracy: 0.9475 - precision: 0.8695 - recall: 0.8728 - val_loss: 0.4452 - val_auc: 0.9318 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2071 - auc: 0.9767 - accuracy: 0.9494 - precision: 0.8853 - recall: 0.8627 \n",
      "Epoch 6: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.2071 - auc: 0.9767 - accuracy: 0.9494 - precision: 0.8853 - recall: 0.8627 - val_loss: 0.8373 - val_auc: 0.7593 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1973 - auc: 0.9781 - accuracy: 0.9502 - precision: 0.8834 - recall: 0.8697 \n",
      "Epoch 7: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 146s 15s/step - loss: 0.1973 - auc: 0.9781 - accuracy: 0.9502 - precision: 0.8834 - recall: 0.8697 - val_loss: 0.8894 - val_auc: 0.6444 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1894 - auc: 0.9788 - accuracy: 0.9502 - precision: 0.8839 - recall: 0.8690 \n",
      "Epoch 8: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.1894 - auc: 0.9788 - accuracy: 0.9502 - precision: 0.8839 - recall: 0.8690 - val_loss: 0.9126 - val_auc: 0.8897 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1818 - auc: 0.9798 - accuracy: 0.9512 - precision: 0.8886 - recall: 0.8688 \n",
      "Epoch 9: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 133s 13s/step - loss: 0.1818 - auc: 0.9798 - accuracy: 0.9512 - precision: 0.8886 - recall: 0.8688 - val_loss: 0.8712 - val_auc: 0.6855 - val_accuracy: 0.8152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1754 - auc: 0.9808 - accuracy: 0.9516 - precision: 0.8866 - recall: 0.8737 \n",
      "Epoch 10: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1754 - auc: 0.9808 - accuracy: 0.9516 - precision: 0.8866 - recall: 0.8737 - val_loss: 0.7772 - val_auc: 0.9056 - val_accuracy: 0.8153 - val_precision: 1.0000 - val_recall: 4.6437e-04 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1719 - auc: 0.9803 - accuracy: 0.9511 - precision: 0.8878 - recall: 0.8692 \n",
      "Epoch 11: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 129s 13s/step - loss: 0.1719 - auc: 0.9803 - accuracy: 0.9511 - precision: 0.8878 - recall: 0.8692 - val_loss: 0.6971 - val_auc: 0.8539 - val_accuracy: 0.8155 - val_precision: 1.0000 - val_recall: 0.0017 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1646 - auc: 0.9815 - accuracy: 0.9528 - precision: 0.8958 - recall: 0.8686 \n",
      "Epoch 12: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 131s 13s/step - loss: 0.1646 - auc: 0.9815 - accuracy: 0.9528 - precision: 0.8958 - recall: 0.8686 - val_loss: 0.6349 - val_auc: 0.8991 - val_accuracy: 0.8159 - val_precision: 1.0000 - val_recall: 0.0038 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1638 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8882 - recall: 0.8684 \n",
      "Epoch 13: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.1638 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8882 - recall: 0.8684 - val_loss: 0.5823 - val_auc: 0.9420 - val_accuracy: 0.8167 - val_precision: 1.0000 - val_recall: 0.0081 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1568 - auc: 0.9823 - accuracy: 0.9530 - precision: 0.8925 - recall: 0.8740 \n",
      "Epoch 14: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1568 - auc: 0.9823 - accuracy: 0.9530 - precision: 0.8925 - recall: 0.8740 - val_loss: 0.5670 - val_auc: 0.9468 - val_accuracy: 0.8178 - val_precision: 1.0000 - val_recall: 0.0143 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1564 - auc: 0.9811 - accuracy: 0.9514 - precision: 0.8910 - recall: 0.8670 \n",
      "Epoch 15: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 136s 14s/step - loss: 0.1564 - auc: 0.9811 - accuracy: 0.9514 - precision: 0.8910 - recall: 0.8670 - val_loss: 0.5577 - val_auc: 0.9512 - val_accuracy: 0.8195 - val_precision: 0.9996 - val_recall: 0.0233 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1502 - auc: 0.9838 - accuracy: 0.9532 - precision: 0.8827 - recall: 0.8875 \n",
      "Epoch 16: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1502 - auc: 0.9838 - accuracy: 0.9532 - precision: 0.8827 - recall: 0.8875 - val_loss: 0.5508 - val_auc: 0.9486 - val_accuracy: 0.8225 - val_precision: 0.9997 - val_recall: 0.0395 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1478 - auc: 0.9828 - accuracy: 0.9535 - precision: 0.8964 - recall: 0.8721 \n",
      "Epoch 17: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 137s 13s/step - loss: 0.1478 - auc: 0.9828 - accuracy: 0.9535 - precision: 0.8964 - recall: 0.8721 - val_loss: 0.4807 - val_auc: 0.9510 - val_accuracy: 0.8289 - val_precision: 0.9926 - val_recall: 0.0749 - lr: 9.0484e-04\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1478 - auc: 0.9826 - accuracy: 0.9526 - precision: 0.8981 - recall: 0.8648 \n",
      "Epoch 18: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1478 - auc: 0.9826 - accuracy: 0.9526 - precision: 0.8981 - recall: 0.8648 - val_loss: 0.4645 - val_auc: 0.9526 - val_accuracy: 0.8360 - val_precision: 0.9908 - val_recall: 0.1135 - lr: 9.0484e-04\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1430 - auc: 0.9839 - accuracy: 0.9536 - precision: 0.8868 - recall: 0.8846 \n",
      "Epoch 19: val_loss did not improve from 0.44519\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1430 - auc: 0.9839 - accuracy: 0.9536 - precision: 0.8868 - recall: 0.8846 - val_loss: 0.4476 - val_auc: 0.9550 - val_accuracy: 0.8379 - val_precision: 0.9921 - val_recall: 0.1242 - lr: 8.1873e-04\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1413 - auc: 0.9829 - accuracy: 0.9541 - precision: 0.9045 - recall: 0.8656 \n",
      "Epoch 20: val_loss improved from 0.44519 to 0.41061, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1413 - auc: 0.9829 - accuracy: 0.9541 - precision: 0.9045 - recall: 0.8656 - val_loss: 0.4106 - val_auc: 0.9047 - val_accuracy: 0.8552 - val_precision: 0.9850 - val_recall: 0.2198 - lr: 8.1873e-04\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1383 - auc: 0.9847 - accuracy: 0.9546 - precision: 0.8946 - recall: 0.8801 \n",
      "Epoch 21: val_loss improved from 0.41061 to 0.35180, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 138s 14s/step - loss: 0.1383 - auc: 0.9847 - accuracy: 0.9546 - precision: 0.8946 - recall: 0.8801 - val_loss: 0.3518 - val_auc: 0.7403 - val_accuracy: 0.8741 - val_precision: 0.9771 - val_recall: 0.3266 - lr: 7.4082e-04\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1376 - auc: 0.9838 - accuracy: 0.9544 - precision: 0.8982 - recall: 0.8745 \n",
      "Epoch 22: val_loss improved from 0.35180 to 0.29839, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 136s 13s/step - loss: 0.1376 - auc: 0.9838 - accuracy: 0.9544 - precision: 0.8982 - recall: 0.8745 - val_loss: 0.2984 - val_auc: 0.8517 - val_accuracy: 0.8895 - val_precision: 0.9689 - val_recall: 0.4155 - lr: 7.4082e-04\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1369 - auc: 0.9843 - accuracy: 0.9542 - precision: 0.9031 - recall: 0.8675 \n",
      "Epoch 23: val_loss did not improve from 0.29839\n",
      "10/10 [==============================] - 149s 15s/step - loss: 0.1369 - auc: 0.9843 - accuracy: 0.9542 - precision: 0.9031 - recall: 0.8675 - val_loss: 0.3021 - val_auc: 0.8265 - val_accuracy: 0.8916 - val_precision: 0.9745 - val_recall: 0.4245 - lr: 6.7032e-04\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1338 - auc: 0.9850 - accuracy: 0.9550 - precision: 0.8952 - recall: 0.8815 \n",
      "Epoch 24: val_loss improved from 0.29839 to 0.29700, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1338 - auc: 0.9850 - accuracy: 0.9550 - precision: 0.8952 - recall: 0.8815 - val_loss: 0.2970 - val_auc: 0.8318 - val_accuracy: 0.8952 - val_precision: 0.9806 - val_recall: 0.4415 - lr: 6.7032e-04\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1333 - auc: 0.9849 - accuracy: 0.9549 - precision: 0.9037 - recall: 0.8708 \n",
      "Epoch 25: val_loss improved from 0.29700 to 0.21722, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.1333 - auc: 0.9849 - accuracy: 0.9549 - precision: 0.9037 - recall: 0.8708 - val_loss: 0.2172 - val_auc: 0.9518 - val_accuracy: 0.9257 - val_precision: 0.9607 - val_recall: 0.6235 - lr: 6.0653e-04\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1306 - auc: 0.9858 - accuracy: 0.9555 - precision: 0.8987 - recall: 0.8804 \n",
      "Epoch 26: val_loss did not improve from 0.21722\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1306 - auc: 0.9858 - accuracy: 0.9555 - precision: 0.8987 - recall: 0.8804 - val_loss: 0.2523 - val_auc: 0.8930 - val_accuracy: 0.9125 - val_precision: 0.9779 - val_recall: 0.5387 - lr: 6.0653e-04\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1300 - auc: 0.9854 - accuracy: 0.9555 - precision: 0.8996 - recall: 0.8793 \n",
      "Epoch 27: val_loss did not improve from 0.21722\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1300 - auc: 0.9854 - accuracy: 0.9555 - precision: 0.8996 - recall: 0.8793 - val_loss: 0.2378 - val_auc: 0.9222 - val_accuracy: 0.9161 - val_precision: 0.9804 - val_recall: 0.5574 - lr: 5.4881e-04\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1300 - auc: 0.9856 - accuracy: 0.9553 - precision: 0.9032 - recall: 0.8736 \n",
      "Epoch 28: val_loss improved from 0.21722 to 0.17974, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 137s 13s/step - loss: 0.1300 - auc: 0.9856 - accuracy: 0.9553 - precision: 0.9032 - recall: 0.8736 - val_loss: 0.1797 - val_auc: 0.9707 - val_accuracy: 0.9443 - val_precision: 0.9467 - val_recall: 0.7401 - lr: 5.4881e-04\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1280 - auc: 0.9859 - accuracy: 0.9558 - precision: 0.8980 - recall: 0.8825 \n",
      "Epoch 29: val_loss did not improve from 0.17974\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1280 - auc: 0.9859 - accuracy: 0.9558 - precision: 0.8980 - recall: 0.8825 - val_loss: 0.2019 - val_auc: 0.9596 - val_accuracy: 0.9290 - val_precision: 0.9740 - val_recall: 0.6330 - lr: 4.9659e-04\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1276 - auc: 0.9855 - accuracy: 0.9558 - precision: 0.9098 - recall: 0.8684 \n",
      "Epoch 30: val_loss improved from 0.17974 to 0.17227, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1276 - auc: 0.9855 - accuracy: 0.9558 - precision: 0.9098 - recall: 0.8684 - val_loss: 0.1723 - val_auc: 0.9676 - val_accuracy: 0.9477 - val_precision: 0.9267 - val_recall: 0.7787 - lr: 4.9659e-04\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1273 - auc: 0.9859 - accuracy: 0.9556 - precision: 0.8993 - recall: 0.8799 \n",
      "Epoch 31: val_loss improved from 0.17227 to 0.16937, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1273 - auc: 0.9859 - accuracy: 0.9556 - precision: 0.8993 - recall: 0.8799 - val_loss: 0.1694 - val_auc: 0.9707 - val_accuracy: 0.9472 - val_precision: 0.9532 - val_recall: 0.7509 - lr: 4.4933e-04\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1266 - auc: 0.9858 - accuracy: 0.9556 - precision: 0.9011 - recall: 0.8776 \n",
      "Epoch 32: val_loss did not improve from 0.16937\n",
      "10/10 [==============================] - 137s 13s/step - loss: 0.1266 - auc: 0.9858 - accuracy: 0.9556 - precision: 0.9011 - recall: 0.8776 - val_loss: 0.1839 - val_auc: 0.9573 - val_accuracy: 0.9408 - val_precision: 0.9667 - val_recall: 0.7041 - lr: 4.4933e-04\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1270 - auc: 0.9855 - accuracy: 0.9553 - precision: 0.9059 - recall: 0.8703 \n",
      "Epoch 33: val_loss improved from 0.16937 to 0.16413, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 136s 14s/step - loss: 0.1270 - auc: 0.9855 - accuracy: 0.9553 - precision: 0.9059 - recall: 0.8703 - val_loss: 0.1641 - val_auc: 0.9713 - val_accuracy: 0.9471 - val_precision: 0.9617 - val_recall: 0.7433 - lr: 4.0657e-04\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1245 - auc: 0.9867 - accuracy: 0.9562 - precision: 0.8983 - recall: 0.8847 \n",
      "Epoch 34: val_loss improved from 0.16413 to 0.15818, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.1245 - auc: 0.9867 - accuracy: 0.9562 - precision: 0.8983 - recall: 0.8847 - val_loss: 0.1582 - val_auc: 0.9850 - val_accuracy: 0.9578 - val_precision: 0.8828 - val_recall: 0.8898 - lr: 4.0657e-04\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1235 - auc: 0.9868 - accuracy: 0.9564 - precision: 0.9011 - recall: 0.8820 \n",
      "Epoch 35: val_loss improved from 0.15818 to 0.14190, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 127s 13s/step - loss: 0.1235 - auc: 0.9868 - accuracy: 0.9564 - precision: 0.9011 - recall: 0.8820 - val_loss: 0.1419 - val_auc: 0.9854 - val_accuracy: 0.9617 - val_precision: 0.9279 - val_recall: 0.8597 - lr: 3.6788e-04\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1233 - auc: 0.9865 - accuracy: 0.9564 - precision: 0.9082 - recall: 0.8736 \n",
      "Epoch 36: val_loss did not improve from 0.14190\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1233 - auc: 0.9865 - accuracy: 0.9564 - precision: 0.9082 - recall: 0.8736 - val_loss: 0.1432 - val_auc: 0.9791 - val_accuracy: 0.9525 - val_precision: 0.9693 - val_recall: 0.7673 - lr: 3.6788e-04\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1227 - auc: 0.9868 - accuracy: 0.9564 - precision: 0.9012 - recall: 0.8823 \n",
      "Epoch 37: val_loss improved from 0.14190 to 0.13370, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 126s 13s/step - loss: 0.1227 - auc: 0.9868 - accuracy: 0.9564 - precision: 0.9012 - recall: 0.8823 - val_loss: 0.1337 - val_auc: 0.9830 - val_accuracy: 0.9564 - val_precision: 0.9585 - val_recall: 0.7988 - lr: 3.3287e-04\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1228 - auc: 0.9862 - accuracy: 0.9564 - precision: 0.9104 - recall: 0.8714 \n",
      "Epoch 38: val_loss improved from 0.13370 to 0.12719, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.1228 - auc: 0.9862 - accuracy: 0.9564 - precision: 0.9104 - recall: 0.8714 - val_loss: 0.1272 - val_auc: 0.9861 - val_accuracy: 0.9620 - val_precision: 0.9381 - val_recall: 0.8507 - lr: 3.3287e-04\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1216 - auc: 0.9871 - accuracy: 0.9566 - precision: 0.9011 - recall: 0.8835 \n",
      "Epoch 39: val_loss did not improve from 0.12719\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.1216 - auc: 0.9871 - accuracy: 0.9566 - precision: 0.9011 - recall: 0.8835 - val_loss: 0.1284 - val_auc: 0.9882 - val_accuracy: 0.9647 - val_precision: 0.9226 - val_recall: 0.8834 - lr: 3.0119e-04\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1227 - auc: 0.9865 - accuracy: 0.9561 - precision: 0.9009 - recall: 0.8810 \n",
      "Epoch 40: val_loss did not improve from 0.12719\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.1227 - auc: 0.9865 - accuracy: 0.9561 - precision: 0.9009 - recall: 0.8810 - val_loss: 0.1325 - val_auc: 0.9899 - val_accuracy: 0.9647 - val_precision: 0.9030 - val_recall: 0.9061 - lr: 3.0119e-04\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1205 - auc: 0.9870 - accuracy: 0.9569 - precision: 0.9105 - recall: 0.8735 \n",
      "Epoch 41: val_loss did not improve from 0.12719\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.1205 - auc: 0.9870 - accuracy: 0.9569 - precision: 0.9105 - recall: 0.8735 - val_loss: 0.1374 - val_auc: 0.9903 - val_accuracy: 0.9621 - val_precision: 0.8782 - val_recall: 0.9231 - lr: 2.7253e-04\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1211 - auc: 0.9868 - accuracy: 0.9566 - precision: 0.9043 - recall: 0.8791 \n",
      "Epoch 42: val_loss did not improve from 0.12719\n",
      "10/10 [==============================] - 133s 14s/step - loss: 0.1211 - auc: 0.9868 - accuracy: 0.9566 - precision: 0.9043 - recall: 0.8791 - val_loss: 0.1351 - val_auc: 0.9905 - val_accuracy: 0.9641 - val_precision: 0.8931 - val_recall: 0.9151 - lr: 2.7253e-04\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1222 - auc: 0.9866 - accuracy: 0.9558 - precision: 0.8963 - recall: 0.8847 \n",
      "Epoch 43: val_loss improved from 0.12719 to 0.12188, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1222 - auc: 0.9866 - accuracy: 0.9558 - precision: 0.8963 - recall: 0.8847 - val_loss: 0.1219 - val_auc: 0.9888 - val_accuracy: 0.9645 - val_precision: 0.9421 - val_recall: 0.8610 - lr: 2.4660e-04\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1212 - auc: 0.9866 - accuracy: 0.9563 - precision: 0.9169 - recall: 0.8634 \n",
      "Epoch 44: val_loss improved from 0.12188 to 0.12122, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 144s 14s/step - loss: 0.1212 - auc: 0.9866 - accuracy: 0.9563 - precision: 0.9169 - recall: 0.8634 - val_loss: 0.1212 - val_auc: 0.9896 - val_accuracy: 0.9647 - val_precision: 0.9014 - val_recall: 0.9084 - lr: 2.4660e-04\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1198 - auc: 0.9871 - accuracy: 0.9567 - precision: 0.8976 - recall: 0.8883 \n",
      "Epoch 45: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.1198 - auc: 0.9871 - accuracy: 0.9567 - precision: 0.8976 - recall: 0.8883 - val_loss: 0.1503 - val_auc: 0.9915 - val_accuracy: 0.9583 - val_precision: 0.8467 - val_recall: 0.9457 - lr: 2.2313e-04\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1186 - auc: 0.9878 - accuracy: 0.9571 - precision: 0.9031 - recall: 0.8836 \n",
      "Epoch 46: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1186 - auc: 0.9878 - accuracy: 0.9571 - precision: 0.9031 - recall: 0.8836 - val_loss: 0.1305 - val_auc: 0.9907 - val_accuracy: 0.9608 - val_precision: 0.8676 - val_recall: 0.9300 - lr: 2.2313e-04\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1191 - auc: 0.9872 - accuracy: 0.9569 - precision: 0.9115 - recall: 0.8726 \n",
      "Epoch 47: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 145s 15s/step - loss: 0.1191 - auc: 0.9872 - accuracy: 0.9569 - precision: 0.9115 - recall: 0.8726 - val_loss: 0.1426 - val_auc: 0.9911 - val_accuracy: 0.9569 - val_precision: 0.8415 - val_recall: 0.9445 - lr: 2.0190e-04\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1194 - auc: 0.9870 - accuracy: 0.9567 - precision: 0.8997 - recall: 0.8855 \n",
      "Epoch 48: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1194 - auc: 0.9870 - accuracy: 0.9567 - precision: 0.8997 - recall: 0.8855 - val_loss: 0.3055 - val_auc: 0.9926 - val_accuracy: 0.8985 - val_precision: 0.6476 - val_recall: 0.9894 - lr: 2.0190e-04\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1177 - auc: 0.9879 - accuracy: 0.9573 - precision: 0.9086 - recall: 0.8783 \n",
      "Epoch 49: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.1177 - auc: 0.9879 - accuracy: 0.9573 - precision: 0.9086 - recall: 0.8783 - val_loss: 0.1535 - val_auc: 0.9915 - val_accuracy: 0.9513 - val_precision: 0.8131 - val_recall: 0.9561 - lr: 1.8268e-04\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1186 - auc: 0.9874 - accuracy: 0.9568 - precision: 0.8997 - recall: 0.8860 \n",
      "Epoch 50: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.1186 - auc: 0.9874 - accuracy: 0.9568 - precision: 0.8997 - recall: 0.8860 - val_loss: 0.1480 - val_auc: 0.9915 - val_accuracy: 0.9558 - val_precision: 0.8337 - val_recall: 0.9503 - lr: 1.8268e-04\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1173 - auc: 0.9878 - accuracy: 0.9573 - precision: 0.9134 - recall: 0.8726 \n",
      "Epoch 51: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1173 - auc: 0.9878 - accuracy: 0.9573 - precision: 0.9134 - recall: 0.8726 - val_loss: 0.1640 - val_auc: 0.9914 - val_accuracy: 0.9447 - val_precision: 0.7862 - val_recall: 0.9626 - lr: 1.6530e-04\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1181 - auc: 0.9875 - accuracy: 0.9569 - precision: 0.9014 - recall: 0.8845 \n",
      "Epoch 52: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 136s 14s/step - loss: 0.1181 - auc: 0.9875 - accuracy: 0.9569 - precision: 0.9014 - recall: 0.8845 - val_loss: 0.3578 - val_auc: 0.9926 - val_accuracy: 0.8759 - val_precision: 0.5991 - val_recall: 0.9933 - lr: 1.6530e-04\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1170 - auc: 0.9879 - accuracy: 0.9574 - precision: 0.9066 - recall: 0.8812 \n",
      "Epoch 53: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1170 - auc: 0.9879 - accuracy: 0.9574 - precision: 0.9066 - recall: 0.8812 - val_loss: 0.1799 - val_auc: 0.9916 - val_accuracy: 0.9406 - val_precision: 0.7701 - val_recall: 0.9672 - lr: 1.4957e-04\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1171 - auc: 0.9876 - accuracy: 0.9572 - precision: 0.9056 - recall: 0.8814 \n",
      "Epoch 54: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 144s 15s/step - loss: 0.1171 - auc: 0.9876 - accuracy: 0.9572 - precision: 0.9056 - recall: 0.8814 - val_loss: 0.1813 - val_auc: 0.9917 - val_accuracy: 0.9388 - val_precision: 0.7636 - val_recall: 0.9690 - lr: 1.4957e-04\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1174 - auc: 0.9875 - accuracy: 0.9572 - precision: 0.9058 - recall: 0.8808 \n",
      "Epoch 55: val_loss did not improve from 0.12122\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.1174 - auc: 0.9875 - accuracy: 0.9572 - precision: 0.9058 - recall: 0.8808 - val_loss: 0.1752 - val_auc: 0.9920 - val_accuracy: 0.9437 - val_precision: 0.7801 - val_recall: 0.9680 - lr: 1.3534e-04\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1168 - auc: 0.9877 - accuracy: 0.9574 - precision: 0.9071 - recall: 0.8803 \n",
      "Epoch 56: val_loss improved from 0.12122 to 0.12113, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1168 - auc: 0.9877 - accuracy: 0.9574 - precision: 0.9071 - recall: 0.8803 - val_loss: 0.1211 - val_auc: 0.9910 - val_accuracy: 0.9621 - val_precision: 0.8726 - val_recall: 0.9312 - lr: 1.3534e-04\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1170 - auc: 0.9877 - accuracy: 0.9572 - precision: 0.9045 - recall: 0.8823 \n",
      "Epoch 57: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 134s 14s/step - loss: 0.1170 - auc: 0.9877 - accuracy: 0.9572 - precision: 0.9045 - recall: 0.8823 - val_loss: 0.1593 - val_auc: 0.9918 - val_accuracy: 0.9480 - val_precision: 0.7973 - val_recall: 0.9635 - lr: 1.2246e-04\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1162 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9068 - recall: 0.8815 \n",
      "Epoch 58: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1162 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9068 - recall: 0.8815 - val_loss: 0.1861 - val_auc: 0.9922 - val_accuracy: 0.9388 - val_precision: 0.7619 - val_recall: 0.9730 - lr: 1.2246e-04\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1158 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9087 - recall: 0.8793 \n",
      "Epoch 59: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 144s 14s/step - loss: 0.1158 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9087 - recall: 0.8793 - val_loss: 0.1486 - val_auc: 0.9920 - val_accuracy: 0.9503 - val_precision: 0.8061 - val_recall: 0.9629 - lr: 1.1080e-04\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9880 - accuracy: 0.9575 - precision: 0.9039 - recall: 0.8848 \n",
      "Epoch 60: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1160 - auc: 0.9880 - accuracy: 0.9575 - precision: 0.9039 - recall: 0.8848 - val_loss: 0.1292 - val_auc: 0.9919 - val_accuracy: 0.9580 - val_precision: 0.8422 - val_recall: 0.9510 - lr: 1.1080e-04\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1166 - auc: 0.9876 - accuracy: 0.9573 - precision: 0.9058 - recall: 0.8815 \n",
      "Epoch 61: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 140s 14s/step - loss: 0.1166 - auc: 0.9876 - accuracy: 0.9573 - precision: 0.9058 - recall: 0.8815 - val_loss: 0.1483 - val_auc: 0.9920 - val_accuracy: 0.9515 - val_precision: 0.8111 - val_recall: 0.9616 - lr: 1.0026e-04\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9879 - accuracy: 0.9573 - precision: 0.9093 - recall: 0.8774 \n",
      "Epoch 62: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 145s 14s/step - loss: 0.1160 - auc: 0.9879 - accuracy: 0.9573 - precision: 0.9093 - recall: 0.8774 - val_loss: 0.1243 - val_auc: 0.9913 - val_accuracy: 0.9587 - val_precision: 0.8483 - val_recall: 0.9453 - lr: 1.0026e-04\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9875 - accuracy: 0.9575 - precision: 0.9072 - recall: 0.8809 \n",
      "Epoch 63: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.1160 - auc: 0.9875 - accuracy: 0.9575 - precision: 0.9072 - recall: 0.8809 - val_loss: 0.1213 - val_auc: 0.9911 - val_accuracy: 0.9591 - val_precision: 0.8517 - val_recall: 0.9431 - lr: 9.0718e-05\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1152 - auc: 0.9881 - accuracy: 0.9577 - precision: 0.9037 - recall: 0.8863 \n",
      "Epoch 64: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1152 - auc: 0.9881 - accuracy: 0.9577 - precision: 0.9037 - recall: 0.8863 - val_loss: 0.1962 - val_auc: 0.9922 - val_accuracy: 0.9331 - val_precision: 0.7422 - val_recall: 0.9775 - lr: 9.0718e-05\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1145 - auc: 0.9884 - accuracy: 0.9578 - precision: 0.9054 - recall: 0.8848 \n",
      "Epoch 65: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 131s 13s/step - loss: 0.1145 - auc: 0.9884 - accuracy: 0.9578 - precision: 0.9054 - recall: 0.8848 - val_loss: 0.1976 - val_auc: 0.9923 - val_accuracy: 0.9343 - val_precision: 0.7460 - val_recall: 0.9776 - lr: 8.2085e-05\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1146 - auc: 0.9882 - accuracy: 0.9578 - precision: 0.9124 - recall: 0.8764 \n",
      "Epoch 66: val_loss did not improve from 0.12113\n",
      "10/10 [==============================] - 145s 15s/step - loss: 0.1146 - auc: 0.9882 - accuracy: 0.9578 - precision: 0.9124 - recall: 0.8764 - val_loss: 0.1404 - val_auc: 0.9920 - val_accuracy: 0.9526 - val_precision: 0.8157 - val_recall: 0.9608 - lr: 8.2085e-05\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1146 - auc: 0.9881 - accuracy: 0.9578 - precision: 0.9051 - recall: 0.8848 \n",
      "Epoch 67: val_loss improved from 0.12113 to 0.10512, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 137s 13s/step - loss: 0.1146 - auc: 0.9881 - accuracy: 0.9578 - precision: 0.9051 - recall: 0.8848 - val_loss: 0.1051 - val_auc: 0.9907 - val_accuracy: 0.9642 - val_precision: 0.8872 - val_recall: 0.9237 - lr: 7.4274e-05\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1157 - auc: 0.9877 - accuracy: 0.9575 - precision: 0.9018 - recall: 0.8872 \n",
      "Epoch 68: val_loss did not improve from 0.10512\n",
      "10/10 [==============================] - 149s 15s/step - loss: 0.1157 - auc: 0.9877 - accuracy: 0.9575 - precision: 0.9018 - recall: 0.8872 - val_loss: 0.1073 - val_auc: 0.9908 - val_accuracy: 0.9638 - val_precision: 0.8845 - val_recall: 0.9247 - lr: 7.4274e-05\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1151 - auc: 0.9881 - accuracy: 0.9576 - precision: 0.9097 - recall: 0.8783 \n",
      "Epoch 69: val_loss did not improve from 0.10512\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1151 - auc: 0.9881 - accuracy: 0.9576 - precision: 0.9097 - recall: 0.8783 - val_loss: 0.1058 - val_auc: 0.9908 - val_accuracy: 0.9640 - val_precision: 0.8857 - val_recall: 0.9246 - lr: 6.7206e-05\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1149 - auc: 0.9880 - accuracy: 0.9576 - precision: 0.9085 - recall: 0.8799 \n",
      "Epoch 70: val_loss improved from 0.10512 to 0.10301, saving model to pixel_core_fold_8.hdf5\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.1149 - auc: 0.9880 - accuracy: 0.9576 - precision: 0.9085 - recall: 0.8799 - val_loss: 0.1030 - val_auc: 0.9912 - val_accuracy: 0.9653 - val_precision: 0.8921 - val_recall: 0.9238 - lr: 6.7206e-05\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1142 - auc: 0.9883 - accuracy: 0.9580 - precision: 0.9067 - recall: 0.8841 \n",
      "Epoch 71: val_loss did not improve from 0.10301\n",
      "10/10 [==============================] - 139s 14s/step - loss: 0.1142 - auc: 0.9883 - accuracy: 0.9580 - precision: 0.9067 - recall: 0.8841 - val_loss: 0.1051 - val_auc: 0.9914 - val_accuracy: 0.9645 - val_precision: 0.8839 - val_recall: 0.9299 - lr: 6.0810e-05\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1138 - auc: 0.9883 - accuracy: 0.9580 - precision: 0.9075 - recall: 0.8835 \n",
      "Epoch 72: val_loss did not improve from 0.10301\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.1138 - auc: 0.9883 - accuracy: 0.9580 - precision: 0.9075 - recall: 0.8835 - val_loss: 0.1148 - val_auc: 0.9913 - val_accuracy: 0.9605 - val_precision: 0.8582 - val_recall: 0.9420 - lr: 6.0810e-05\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1146 - auc: 0.9882 - accuracy: 0.9578 - precision: 0.9072 - recall: 0.8823 \n",
      "Epoch 73: val_loss did not improve from 0.10301\n",
      "10/10 [==============================] - 130s 13s/step - loss: 0.1146 - auc: 0.9882 - accuracy: 0.9578 - precision: 0.9072 - recall: 0.8823 - val_loss: 0.1330 - val_auc: 0.9917 - val_accuracy: 0.9536 - val_precision: 0.8213 - val_recall: 0.9570 - lr: 5.5023e-05\n",
      "Epoch 74/200\n",
      " 5/10 [==============>...............] - ETA: 1:20 - loss: 0.1171 - auc: 0.9878 - accuracy: 0.9562 - precision: 0.9100 - recall: 0.8774"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv  # Import the csv module\n",
    "\n",
    "original_image_dir = './TMA_WSI_Padded_PNGs'\n",
    "augmented_image_dir = './augmented_images'\n",
    "original_label_dir = './TMA_WSI_Labels_updated'\n",
    "augmented_label_dir = './augmented_labels'\n",
    "\n",
    "# Use list comprehension to create the list of file paths\n",
    "original_image_files = [os.path.join(original_image_dir, file) for file in sorted(\n",
    "    os.listdir(original_image_dir)) if file.endswith('.png')]\n",
    "\n",
    "folds = create_loocv_folds(original_image_files, augmented_image_dir)\n",
    "\n",
    "# Evaluation metrics initialization\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "new_size = (512, 512)\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('model_segmentation_evaluation_results.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    # Check if the file is empty by seeking to the end and getting the position\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    if file.tell() == 0:\n",
    "        # File is empty, write the header\n",
    "        writer.writerow(['Fold', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    file.flush() \n",
    "    i = 5\n",
    "    # Iterate over each fold\n",
    "    for fold in folds[i:]:\n",
    "        i += 1\n",
    "        augmented_train_images, test_image, validation_images = fold\n",
    "\n",
    "        # Load and preprocess images and labels\n",
    "        train_images, train_masks = load_images_and_labels(\n",
    "            augmented_train_images, augmented_label_dir, new_size)\n",
    "        test_images, test_masks = load_images_and_labels(\n",
    "            test_image, original_label_dir, new_size)\n",
    "        val_images, val_masks = load_images_and_labels(\n",
    "            validation_images, original_label_dir, new_size)\n",
    "\n",
    "        # Create a new instance of the model\n",
    "        model = unet()\n",
    "\n",
    "        # Train the model\n",
    "        trained_model = train_unet(model, train_images, train_masks, val_images, val_masks, 200, 32, \"pixel_core_fold_{i}.hdf5\".format(i=i))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        _, auc, accuracy, precision, recall = trained_model.evaluate(\n",
    "            test_images, test_masks)\n",
    "\n",
    "        # Store the evaluation metrics\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Write the fold results to the CSV file\n",
    "        writer.writerow([i, auc, accuracy, precision, recall])\n",
    "        file.flush() \n",
    "\n",
    "# Calculate average and standard deviation of metrics\n",
    "avg_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "avg_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Average AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1672 - auc: 0.9732 - accuracy: 0.9380 - precision: 0.9011 - recall: 0.8317\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.2127 - auc: 0.9524 - accuracy: 0.9258 - precision: 0.9302 - recall: 0.7454\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.2032 - auc: 0.9536 - accuracy: 0.9280 - precision: 0.9190 - recall: 0.7660\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1947 - auc: 0.9618 - accuracy: 0.9272 - precision: 0.8635 - recall: 0.8259\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.2330 - auc: 0.9349 - accuracy: 0.9194 - precision: 0.8770 - recall: 0.7710\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at pixel_core_fold_6.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, fold \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(folds):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Load the checkpointed model for the fold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     model_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpixel_core_fold_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(model_path, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m: weighted_binary_crossentropy(zero_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, one_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Load the test images and masks\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     test_images, test_masks \u001b[39m=\u001b[39m load_images_and_labels(test_image, original_label_dir, new_size)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at pixel_core_fold_6.hdf5"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'model_evaluation_results.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Fold', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for i, fold in enumerate(folds):\n",
    "        # Load the checkpointed model for the fold\n",
    "        model_path = f\"pixel_core_fold_{i+1}.hdf5\"\n",
    "        loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "        # Load the test images and masks\n",
    "        test_images, test_masks = load_images_and_labels(test_image, original_label_dir, new_size)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = loaded_model.evaluate(test_images, test_masks)\n",
    "\n",
    "        # Write the evaluation metrics to the CSV file\n",
    "        writer.writerow([i+1, loss, auc, accuracy, precision, recall])\n",
    "    \n",
    "\n",
    "        # Flush the changes to the CSV file\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron\\Documents\\GitHub\\RizzGPT\\Microarray-Dearraying\\UNetDetection.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m plot_training_predictions(model, images, masks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_predictions(model, training_images, training_masks, num_samples=3):\n",
    "    # Make sure there is enough data for the number of samples requested\n",
    "    if num_samples > len(training_images):\n",
    "        num_samples = len(training_images)\n",
    "        print(f\"Number of available samples is less than requested. Setting num_samples to {num_samples}.\")\n",
    "\n",
    "    # Randomly select some samples from the training images and masks\n",
    "    indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    sample_images = np.array([training_images[i] for i in indices])\n",
    "    sample_masks = np.array([training_masks[i] for i in indices])\n",
    "\n",
    "    # Generate predictions for the sample_images\n",
    "    predicted_masks = model.predict(sample_images)\n",
    "\n",
    "    # Convert predicted masks to binary\n",
    "    binary_predicted_masks = (predicted_masks > 0.114).astype(np.uint8)\n",
    "\n",
    "    # Set up the matplotlib figure and axes, based on the number of samples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)  # If only one sample, make sure axes are iterable\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(np.squeeze(sample_images[i]), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Display true mask for the image\n",
    "        axes[i, 1].imshow(np.squeeze(sample_masks[i]), cmap='gray')\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Display predicted mask for the image\n",
    "        axes[i, 2].imshow(np.squeeze(binary_predicted_masks[i]), cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_predictions(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Call the function after loading your images and masks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m verify_masks(images, masks, num_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mask_alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def verify_masks(images, masks, num_samples=3, mask_alpha=0.3):\n",
    "    \"\"\"\n",
    "    This function overlays the mask onto the image to verify position and size.\n",
    "    Parameters:\n",
    "    - images: numpy array of images.\n",
    "    - masks: numpy array of masks.\n",
    "    - num_samples: number of samples to display for verification.\n",
    "    - mask_alpha: transparency level of the mask overlay.\n",
    "    \"\"\"\n",
    "    # Set the number of images to display\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    # Create figure to display images and masks\n",
    "    plt.figure(figsize=(20, num_samples * 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.imshow(masks[i].squeeze(), cmap='jet', alpha=mask_alpha)  # 'jet' colormap for the mask\n",
    "        plt.title(f'Image {i} with Mask Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after loading your images and masks\n",
    "verify_masks(images, masks, num_samples=2, mask_alpha=0.3)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
