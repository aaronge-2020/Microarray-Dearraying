{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def resize_labels(labels, original_size, new_size):\n",
    "    scale_x = new_size[1] / original_size[1]\n",
    "    scale_y = new_size[0] / original_size[0]\n",
    "    resized_labels = []\n",
    "    for label in labels:\n",
    "        resized_label = {\n",
    "            'x': label['x'] * scale_x,\n",
    "            'y': label['y'] * scale_y,\n",
    "            'radius': label['radius'] * scale_x  # Assuming uniform scaling in x and y\n",
    "        }\n",
    "        resized_labels.append(resized_label)\n",
    "    return resized_labels\n",
    "\n",
    "def load_images_and_labels(image_paths, label_dir, new_size):\n",
    "    original_size = (1024, 1024)  # Original size of the images and labels\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Extract filename without extension to match with the label\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_file = os.path.join(label_dir, base_filename + '.json')\n",
    "\n",
    "        # Load and resize image\n",
    "        image = img_to_array(load_img(image_path, color_mode='rgb', target_size=new_size))\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load and resize corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        resized_json_data = resize_labels(json_data, original_size, new_size)\n",
    "        mask = create_mask_from_json(resized_json_data, shape=new_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, *new_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "def create_loocv_folds(image_files, augmented_image_dir):\n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "\n",
    "    for i in range(n):\n",
    "        test_image = image_files[i]\n",
    "        \n",
    "        # Ensure validation images are different from the test image and rotate them\n",
    "        val_indices = [(i + 1) % n, (i + 2) % n]\n",
    "        validation_images = [image_files[j] for j in val_indices]\n",
    "\n",
    "        # Remaining images for training, excluding the test and validation images\n",
    "        train_images = [img for idx, img in enumerate(image_files) if idx not in [i, val_indices[0], val_indices[1]]]\n",
    "\n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(20)]\n",
    "\n",
    "        folds.append((augmented_train_images, [test_image], validation_images))\n",
    "\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 256, 256, 32)         864       ['input_23[0][0]']            \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 256, 256, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 256, 256, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 256, 256, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 256, 256, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 256, 256, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 256, 256, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 256, 256, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 256, 256, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 256, 256, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 256, 256, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 257, 257, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 128, 128, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 128, 128, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 128, 128, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 128, 128, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 128, 128, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 128, 128, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 128, 128, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 128, 128, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 128, 128, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 129, 129, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 64, 64, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 64, 64, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 64, 64, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 64, 64, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 64, 64, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 64, 64, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 65, 65, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 32, 32, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 32, 32, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 32, 32, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 32, 32, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 32, 32, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 32, 32, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 32, 32, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 32, 32, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 32, 32, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 32, 32, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 32, 32, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 32, 32, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 32, 32, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 32, 32, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 32, 32, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 32, 32, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 32, 32, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 32, 32, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 32, 32, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 33, 33, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 16, 16, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 16, 16, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 16, 16, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 16, 16, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 16, 16, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 16, 16, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 16, 16, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 16, 16, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 16, 16, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 16, 16, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 16, 16, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 16, 16, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 16, 16, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 16, 16, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 16, 16, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_196 (B  (None, 16, 16, 256)          1024      ['conv2d_233[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 16, 16, 256)          590080    ['batch_normalization_196[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenat  (None, 16, 16, 1024)         0         ['conv2d_234[0][0]',          \n",
      " e)                                                                  'conv2d_235[0][0]',          \n",
      "                                                                     'conv2d_236[0][0]',          \n",
      "                                                                     'conv2d_237[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)         (None, 16, 16, 256)          262400    ['concatenate_41[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_197 (B  (None, 16, 16, 256)          1024      ['conv2d_238[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 16, 16, 256)          65792     ['batch_normalization_197[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_53 (UpSampli  (None, 32, 32, 256)          0         ['conv2d_239[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_54 (UpSampli  (None, 64, 64, 256)          0         ['up_sampling2d_53[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_55 (UpSampli  (None, 128, 128, 256)        0         ['up_sampling2d_54[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_56 (UpSampli  (None, 256, 256, 256)        0         ['up_sampling2d_55[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " up_sampling2d_57 (UpSampli  (None, 512, 512, 256)        0         ['up_sampling2d_56[0][0]']    \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 512, 512, 1)          257       ['up_sampling2d_57[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4752449 (18.13 MB)\n",
      "Trainable params: 2493441 (9.51 MB)\n",
      "Non-trainable params: 2259008 (8.62 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "def create_deeplabv3_plus_binary_model(input_shape=(512, 512, 3), l2_lambda=0.01, fine_tune_at=200):\n",
    "    # Load MobileNetV2 pre-trained on ImageNet as the backbone\n",
    "    backbone = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Unfreeze the top layers of the model for fine-tuning\n",
    "    backbone.trainable = True\n",
    "    for layer in backbone.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Use features from the backbone network - feature extraction\n",
    "    x = backbone.output\n",
    "\n",
    "    # Apply atrous convolutions / spatial pyramid pooling\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling (ASPP)\n",
    "    b0 = layers.Conv2D(256, (1, 1), activation='relu', padding='same', dilation_rate=1, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=6, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=12, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=18, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "\n",
    "    # Concatenate the atrous and image-level features\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3])\n",
    "\n",
    "    # Add a convolutional layer on top of the concatenated features\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Decoder\n",
    "    # Start with a simple 1x1 convolution\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Perform upsampling in steps to reach the output size of 512x512.\n",
    "    # Each UpSampling2D layer doubles the size of the feature map\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 32x32\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 64x64\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 128x128\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 256x256\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 512x512\n",
    "\n",
    "    # Output layer for binary segmentation\n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = models.Model(inputs=backbone.input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_deeplabv3_plus_binary_model()\n",
    "\n",
    "# Compile the model (if you're about to train it)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary to verify the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3), num_filters=16, depth=2, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)       [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 512, 512, 16)         448       ['input_24[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_198 (B  (None, 512, 512, 16)         64        ['conv2d_241[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_190 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_198[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_190[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_199 (B  (None, 512, 512, 16)         64        ['conv2d_242[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_191 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_199[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_38 (MaxPooli  (None, 256, 256, 16)         0         ['activation_191[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 256, 256, 16)         0         ['max_pooling2d_38[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 256, 256, 32)         4640      ['dropout_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_200 (B  (None, 256, 256, 32)         128       ['conv2d_243[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_192 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_200[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_192[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_201 (B  (None, 256, 256, 32)         128       ['conv2d_244[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_193 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_201[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_39 (MaxPooli  (None, 128, 128, 32)         0         ['activation_193[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 128, 128, 32)         0         ['max_pooling2d_39[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)         (None, 128, 128, 64)         18496     ['dropout_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_202 (B  (None, 128, 128, 64)         256       ['conv2d_245[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_194 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_202[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 128, 128, 64)         36928     ['activation_194[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_203 (B  (None, 128, 128, 64)         256       ['conv2d_246[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_195 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_203[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_58 (UpSampli  (None, 256, 256, 64)         0         ['activation_195[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_58[0][0]',    \n",
      " e)                                                                  'activation_193[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 256, 256, 32)         27680     ['concatenate_42[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_204 (B  (None, 256, 256, 32)         128       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_196 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_204[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_196[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_205 (B  (None, 256, 256, 32)         128       ['conv2d_248[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_197 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_205[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " up_sampling2d_59 (UpSampli  (None, 512, 512, 32)         0         ['activation_197[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenat  (None, 512, 512, 48)         0         ['up_sampling2d_59[0][0]',    \n",
      " e)                                                                  'activation_191[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 512, 512, 16)         6928      ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_206 (B  (None, 512, 512, 16)         64        ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_198 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_206[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 512, 512, 16)         2320      ['activation_198[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_207 (B  (None, 512, 512, 16)         64        ['conv2d_250[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_199 (Activation  (None, 512, 512, 16)         0         ['batch_normalization_207[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 512, 512, 1)          17        ['activation_199[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119553 (467.00 KB)\n",
      "Trainable params: 118913 (464.50 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = unet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a Learning Rate Schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 0:\n",
    "        return lr\n",
    "    elif epoch < 30 and epoch%2 == 0:\n",
    "        return lr * tf.math.exp(-0.5)\n",
    "    elif epoch > 30:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def train_unet(model, train_images, train_masks, val_images, val_masks, epochs=300, batch_size=32, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=1)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=5e-4), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model with the given training and validation data\n",
    "    history = model.fit(\n",
    "        x=train_images, \n",
    "        y=train_masks, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(val_images, val_masks), \n",
    "        callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv  # Import the csv module\n",
    "\n",
    "original_image_dir = './TMA_WSI_Padded_PNGs'\n",
    "augmented_image_dir = './augmented_images'\n",
    "original_label_dir = './TMA_WSI_Labels_updated'\n",
    "augmented_label_dir = './augmented_labels'\n",
    "\n",
    "# Use list comprehension to create the list of file paths\n",
    "original_image_files = [os.path.join(original_image_dir, file) for file in sorted(\n",
    "    os.listdir(original_image_dir)) if file.endswith('.png')]\n",
    "\n",
    "folds = create_loocv_folds(original_image_files, augmented_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 343ms/step - loss: 0.1334 - auc: 0.9899 - accuracy: 0.9487 - precision: 0.9153 - recall: 0.9282\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.1503 - auc: 0.9857 - accuracy: 0.9400 - precision: 0.9299 - recall: 0.8824\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.1538 - auc: 0.9854 - accuracy: 0.9426 - precision: 0.8813 - recall: 0.9294\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2064 - auc: 0.9867 - accuracy: 0.9191 - precision: 0.7952 - recall: 0.9891\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.2330 - auc: 0.9349 - accuracy: 0.9194 - precision: 0.8770 - recall: 0.7710\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1739 - auc: 0.9757 - accuracy: 0.9478 - precision: 0.9742 - recall: 0.7001\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.2001 - auc: 0.9928 - accuracy: 0.9353 - precision: 0.7342 - recall: 0.9853\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1296 - auc: 0.9816 - accuracy: 0.9556 - precision: 0.8792 - recall: 0.9208\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1786 - auc: 0.9796 - accuracy: 0.9554 - precision: 0.8821 - recall: 0.8787\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1365 - auc: 0.9886 - accuracy: 0.9579 - precision: 0.8526 - recall: 0.9307\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.1385 - auc: 0.9901 - accuracy: 0.9502 - precision: 0.8280 - recall: 0.9590\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.2684 - auc: 0.9805 - accuracy: 0.8911 - precision: 0.9749 - recall: 0.6684\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0890 - auc: 0.9897 - accuracy: 0.9697 - precision: 0.9076 - recall: 0.9038\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.2002 - auc: 0.9631 - accuracy: 0.9594 - precision: 0.8068 - recall: 0.8242\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.2336 - auc: 0.9453 - accuracy: 0.9235 - precision: 0.7750 - recall: 0.7823\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3065 - auc: 0.9743 - accuracy: 0.9275 - precision: 0.7038 - recall: 0.9229\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.1407 - auc: 0.9923 - accuracy: 0.9484 - precision: 0.7644 - recall: 0.9667\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.1203 - auc: 0.9881 - accuracy: 0.9691 - precision: 0.9801 - recall: 0.8223\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1044 - auc: 0.9940 - accuracy: 0.9804 - precision: 0.8230 - recall: 0.9236\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'model_evaluation_results.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for i, fold in enumerate(folds):\n",
    "        # Load the checkpointed model for the fold\n",
    "        model_path = f\"pixel_core_fold_{i+1}.hdf5\"\n",
    "        loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "        # Unpack the fold\n",
    "        train_image, test_image, val_images = fold\n",
    "\n",
    "        # Load the test images and masks\n",
    "        test_images, test_masks = load_images_and_labels(test_image, original_label_dir, (512,512))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = loaded_model.evaluate(test_images, test_masks)\n",
    "\n",
    "        # Write the evaluation metrics to the CSV file\n",
    "        writer.writerow([i+1, loss, auc, accuracy, precision, recall])\n",
    "    \n",
    "\n",
    "        # Flush the changes to the CSV file\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint: pixel_core_fold_14.hdf5\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2560 - auc: 0.9751 - accuracy: 0.9449 - precision: 0.8600 - recall: 0.8846 \n",
      "Epoch 1: val_loss improved from inf to 0.55685, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 115s 11s/step - loss: 0.2560 - auc: 0.9751 - accuracy: 0.9449 - precision: 0.8600 - recall: 0.8846 - val_loss: 0.5568 - val_auc: 0.7613 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2361 - auc: 0.9745 - accuracy: 0.9473 - precision: 0.8766 - recall: 0.8750 \n",
      "Epoch 2: val_loss improved from 0.55685 to 0.51113, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.2361 - auc: 0.9745 - accuracy: 0.9473 - precision: 0.8766 - recall: 0.8750 - val_loss: 0.5111 - val_auc: 0.4037 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2250 - auc: 0.9775 - accuracy: 0.9471 - precision: 0.8671 - recall: 0.8865 \n",
      "Epoch 3: val_loss improved from 0.51113 to 0.48583, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2250 - auc: 0.9775 - accuracy: 0.9471 - precision: 0.8671 - recall: 0.8865 - val_loss: 0.4858 - val_auc: 0.4224 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2187 - auc: 0.9765 - accuracy: 0.9489 - precision: 0.8845 - recall: 0.8731 \n",
      "Epoch 4: val_loss improved from 0.48583 to 0.46712, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2187 - auc: 0.9765 - accuracy: 0.9489 - precision: 0.8845 - recall: 0.8731 - val_loss: 0.4671 - val_auc: 0.3399 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2140 - auc: 0.9792 - accuracy: 0.9491 - precision: 0.8767 - recall: 0.8846 \n",
      "Epoch 5: val_loss improved from 0.46712 to 0.45786, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.2140 - auc: 0.9792 - accuracy: 0.9491 - precision: 0.8767 - recall: 0.8846 - val_loss: 0.4579 - val_auc: 0.3252 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.1157e-04\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2113 - auc: 0.9783 - accuracy: 0.9498 - precision: 0.8832 - recall: 0.8800 \n",
      "Epoch 6: val_loss improved from 0.45786 to 0.45312, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2113 - auc: 0.9783 - accuracy: 0.9498 - precision: 0.8832 - recall: 0.8800 - val_loss: 0.4531 - val_auc: 0.3737 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.1157e-04\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2096 - auc: 0.9790 - accuracy: 0.9496 - precision: 0.8803 - recall: 0.8828 \n",
      "Epoch 7: val_loss improved from 0.45312 to 0.45076, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2096 - auc: 0.9790 - accuracy: 0.9496 - precision: 0.8803 - recall: 0.8828 - val_loss: 0.4508 - val_auc: 0.2413 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.7668e-05\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2073 - auc: 0.9803 - accuracy: 0.9501 - precision: 0.8790 - recall: 0.8873 \n",
      "Epoch 8: val_loss improved from 0.45076 to 0.44976, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.2073 - auc: 0.9803 - accuracy: 0.9501 - precision: 0.8790 - recall: 0.8873 - val_loss: 0.4498 - val_auc: 0.3986 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.7668e-05\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2066 - auc: 0.9798 - accuracy: 0.9499 - precision: 0.8799 - recall: 0.8849 \n",
      "Epoch 9: val_loss improved from 0.44976 to 0.44915, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2066 - auc: 0.9798 - accuracy: 0.9499 - precision: 0.8799 - recall: 0.8849 - val_loss: 0.4491 - val_auc: 0.3723 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 4.1043e-05\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2069 - auc: 0.9789 - accuracy: 0.9500 - precision: 0.8839 - recall: 0.8803 \n",
      "Epoch 10: val_loss improved from 0.44915 to 0.44874, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2069 - auc: 0.9789 - accuracy: 0.9500 - precision: 0.8839 - recall: 0.8803 - val_loss: 0.4487 - val_auc: 0.3649 - val_accuracy: 0.8362 - val_precision: 1.0000 - val_recall: 4.4232e-04 - lr: 4.1043e-05\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2056 - auc: 0.9796 - accuracy: 0.9504 - precision: 0.8857 - recall: 0.8797 \n",
      "Epoch 11: val_loss improved from 0.44874 to 0.44847, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2056 - auc: 0.9796 - accuracy: 0.9504 - precision: 0.8857 - recall: 0.8797 - val_loss: 0.4485 - val_auc: 0.4122 - val_accuracy: 0.8364 - val_precision: 1.0000 - val_recall: 0.0013 - lr: 2.4894e-05\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2043 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8849 - recall: 0.8823 \n",
      "Epoch 12: val_loss improved from 0.44847 to 0.44783, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2043 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8849 - recall: 0.8823 - val_loss: 0.4478 - val_auc: 0.4782 - val_accuracy: 0.8365 - val_precision: 0.9881 - val_recall: 0.0019 - lr: 2.4894e-05\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2044 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8834 - recall: 0.8833 \n",
      "Epoch 13: val_loss improved from 0.44783 to 0.44649, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2044 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8834 - recall: 0.8833 - val_loss: 0.4465 - val_auc: 0.6334 - val_accuracy: 0.8365 - val_precision: 0.7470 - val_recall: 0.0037 - lr: 1.5099e-05\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2048 - auc: 0.9800 - accuracy: 0.9503 - precision: 0.8821 - recall: 0.8837 \n",
      "Epoch 14: val_loss improved from 0.44649 to 0.44456, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.2048 - auc: 0.9800 - accuracy: 0.9503 - precision: 0.8821 - recall: 0.8837 - val_loss: 0.4446 - val_auc: 0.4631 - val_accuracy: 0.8367 - val_precision: 0.5962 - val_recall: 0.0099 - lr: 1.5099e-05\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2042 - auc: 0.9805 - accuracy: 0.9504 - precision: 0.8829 - recall: 0.8838 \n",
      "Epoch 15: val_loss improved from 0.44456 to 0.44242, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 114s 11s/step - loss: 0.2042 - auc: 0.9805 - accuracy: 0.9504 - precision: 0.8829 - recall: 0.8838 - val_loss: 0.4424 - val_auc: 0.6416 - val_accuracy: 0.8369 - val_precision: 0.5596 - val_recall: 0.0209 - lr: 9.1578e-06\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2039 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8834 - recall: 0.8837 \n",
      "Epoch 16: val_loss improved from 0.44242 to 0.44009, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.2039 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8834 - recall: 0.8837 - val_loss: 0.4401 - val_auc: 0.5510 - val_accuracy: 0.8365 - val_precision: 0.5164 - val_recall: 0.0345 - lr: 9.1578e-06\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8835 - recall: 0.8837 \n",
      "Epoch 17: val_loss improved from 0.44009 to 0.43691, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 114s 11s/step - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8835 - recall: 0.8837 - val_loss: 0.4369 - val_auc: 0.6925 - val_accuracy: 0.8359 - val_precision: 0.4929 - val_recall: 0.0526 - lr: 5.5545e-06\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2038 - auc: 0.9803 - accuracy: 0.9504 - precision: 0.8833 - recall: 0.8832 \n",
      "Epoch 18: val_loss improved from 0.43691 to 0.43176, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.2038 - auc: 0.9803 - accuracy: 0.9504 - precision: 0.8833 - recall: 0.8832 - val_loss: 0.4318 - val_auc: 0.6916 - val_accuracy: 0.8370 - val_precision: 0.5171 - val_recall: 0.0760 - lr: 5.5545e-06\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8824 \n",
      "Epoch 19: val_loss improved from 0.43176 to 0.42230, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8824 - val_loss: 0.4223 - val_auc: 0.6853 - val_accuracy: 0.8403 - val_precision: 0.5629 - val_recall: 0.1123 - lr: 3.3690e-06\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8825 \n",
      "Epoch 20: val_loss improved from 0.42230 to 0.40827, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8825 - val_loss: 0.4083 - val_auc: 0.7520 - val_accuracy: 0.8455 - val_precision: 0.6054 - val_recall: 0.1639 - lr: 3.3690e-06\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8843 - recall: 0.8834 \n",
      "Epoch 21: val_loss improved from 0.40827 to 0.39120, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2034 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8843 - recall: 0.8834 - val_loss: 0.3912 - val_auc: 0.7683 - val_accuracy: 0.8531 - val_precision: 0.6470 - val_recall: 0.2282 - lr: 2.0434e-06\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2040 - auc: 0.9799 - accuracy: 0.9506 - precision: 0.8842 - recall: 0.8827 \n",
      "Epoch 22: val_loss improved from 0.39120 to 0.37247, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2040 - auc: 0.9799 - accuracy: 0.9506 - precision: 0.8842 - recall: 0.8827 - val_loss: 0.3725 - val_auc: 0.8069 - val_accuracy: 0.8622 - val_precision: 0.6792 - val_recall: 0.3015 - lr: 2.0434e-06\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8847 - recall: 0.8821 \n",
      "Epoch 23: val_loss improved from 0.37247 to 0.35273, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8847 - recall: 0.8821 - val_loss: 0.3527 - val_auc: 0.8226 - val_accuracy: 0.8725 - val_precision: 0.7060 - val_recall: 0.3806 - lr: 1.2394e-06\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9504 - precision: 0.8838 - recall: 0.8826 \n",
      "Epoch 24: val_loss improved from 0.35273 to 0.33411, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9504 - precision: 0.8838 - recall: 0.8826 - val_loss: 0.3341 - val_auc: 0.8377 - val_accuracy: 0.8839 - val_precision: 0.7300 - val_recall: 0.4624 - lr: 1.2394e-06\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2029 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8848 - recall: 0.8836 \n",
      "Epoch 25: val_loss improved from 0.33411 to 0.31748, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2029 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8848 - recall: 0.8836 - val_loss: 0.3175 - val_auc: 0.8555 - val_accuracy: 0.8941 - val_precision: 0.7458 - val_recall: 0.5362 - lr: 7.5172e-07\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8847 - recall: 0.8824 \n",
      "Epoch 26: val_loss improved from 0.31748 to 0.30313, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2034 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8847 - recall: 0.8824 - val_loss: 0.3031 - val_auc: 0.8765 - val_accuracy: 0.9033 - val_precision: 0.7556 - val_recall: 0.6063 - lr: 7.5172e-07\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2030 - auc: 0.9805 - accuracy: 0.9508 - precision: 0.8850 - recall: 0.8830 \n",
      "Epoch 27: val_loss improved from 0.30313 to 0.29150, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2030 - auc: 0.9805 - accuracy: 0.9508 - precision: 0.8850 - recall: 0.8830 - val_loss: 0.2915 - val_auc: 0.8965 - val_accuracy: 0.9114 - val_precision: 0.7609 - val_recall: 0.6694 - lr: 4.5594e-07\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8843 - recall: 0.8826 \n",
      "Epoch 28: val_loss improved from 0.29150 to 0.28227, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8843 - recall: 0.8826 - val_loss: 0.2823 - val_auc: 0.9171 - val_accuracy: 0.9172 - val_precision: 0.7615 - val_recall: 0.7206 - lr: 4.5594e-07\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9800 - accuracy: 0.9505 - precision: 0.8843 - recall: 0.8824 \n",
      "Epoch 29: val_loss improved from 0.28227 to 0.27508, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2036 - auc: 0.9800 - accuracy: 0.9505 - precision: 0.8843 - recall: 0.8824 - val_loss: 0.2751 - val_auc: 0.9297 - val_accuracy: 0.9220 - val_precision: 0.7595 - val_recall: 0.7664 - lr: 2.7654e-07\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2033 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8828 \n",
      "Epoch 30: val_loss improved from 0.27508 to 0.26984, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2033 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8828 - val_loss: 0.2698 - val_auc: 0.9392 - val_accuracy: 0.9254 - val_precision: 0.7563 - val_recall: 0.8040 - lr: 2.7654e-07\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2028 - auc: 0.9807 - accuracy: 0.9509 - precision: 0.8850 - recall: 0.8836 \n",
      "Epoch 31: val_loss improved from 0.26984 to 0.26628, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2028 - auc: 0.9807 - accuracy: 0.9509 - precision: 0.8850 - recall: 0.8836 - val_loss: 0.2663 - val_auc: 0.9460 - val_accuracy: 0.9278 - val_precision: 0.7520 - val_recall: 0.8344 - lr: 2.7654e-07\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8829 \n",
      "Epoch 32: val_loss improved from 0.26628 to 0.26419, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2035 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8829 - val_loss: 0.2642 - val_auc: 0.9513 - val_accuracy: 0.9294 - val_precision: 0.7475 - val_recall: 0.8595 - lr: 2.7654e-08\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2043 - auc: 0.9801 - accuracy: 0.9502 - precision: 0.8829 - recall: 0.8822 \n",
      "Epoch 33: val_loss improved from 0.26419 to 0.26324, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2043 - auc: 0.9801 - accuracy: 0.9502 - precision: 0.8829 - recall: 0.8822 - val_loss: 0.2632 - val_auc: 0.9564 - val_accuracy: 0.9304 - val_precision: 0.7431 - val_recall: 0.8790 - lr: 2.7654e-09\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8841 - recall: 0.8826 \n",
      "Epoch 34: val_loss improved from 0.26324 to 0.26313, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8841 - recall: 0.8826 - val_loss: 0.2631 - val_auc: 0.9595 - val_accuracy: 0.9305 - val_precision: 0.7378 - val_recall: 0.8936 - lr: 2.7654e-10\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2043 - auc: 0.9801 - accuracy: 0.9502 - precision: 0.8832 - recall: 0.8818 \n",
      "Epoch 35: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2043 - auc: 0.9801 - accuracy: 0.9502 - precision: 0.8832 - recall: 0.8818 - val_loss: 0.2635 - val_auc: 0.9621 - val_accuracy: 0.9302 - val_precision: 0.7322 - val_recall: 0.9049 - lr: 2.7654e-11\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8844 - recall: 0.8823 \n",
      "Epoch 36: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8844 - recall: 0.8823 - val_loss: 0.2642 - val_auc: 0.9640 - val_accuracy: 0.9298 - val_precision: 0.7272 - val_recall: 0.9146 - lr: 2.7654e-12\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9801 - accuracy: 0.9505 - precision: 0.8844 - recall: 0.8822 \n",
      "Epoch 37: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.2036 - auc: 0.9801 - accuracy: 0.9505 - precision: 0.8844 - recall: 0.8822 - val_loss: 0.2652 - val_auc: 0.9657 - val_accuracy: 0.9293 - val_precision: 0.7228 - val_recall: 0.9225 - lr: 2.7654e-13\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8843 - recall: 0.8830 \n",
      "Epoch 38: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2035 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8843 - recall: 0.8830 - val_loss: 0.2663 - val_auc: 0.9670 - val_accuracy: 0.9288 - val_precision: 0.7187 - val_recall: 0.9289 - lr: 2.7654e-14\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9805 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8826 \n",
      "Epoch 39: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2035 - auc: 0.9805 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8826 - val_loss: 0.2676 - val_auc: 0.9682 - val_accuracy: 0.9281 - val_precision: 0.7145 - val_recall: 0.9342 - lr: 2.7654e-15\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2037 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8839 - recall: 0.8828 \n",
      "Epoch 40: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2037 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8839 - recall: 0.8828 - val_loss: 0.2687 - val_auc: 0.9692 - val_accuracy: 0.9273 - val_precision: 0.7107 - val_recall: 0.9382 - lr: 2.7654e-16\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2031 - auc: 0.9807 - accuracy: 0.9506 - precision: 0.8843 - recall: 0.8829 \n",
      "Epoch 41: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2031 - auc: 0.9807 - accuracy: 0.9506 - precision: 0.8843 - recall: 0.8829 - val_loss: 0.2700 - val_auc: 0.9700 - val_accuracy: 0.9265 - val_precision: 0.7070 - val_recall: 0.9420 - lr: 2.7654e-17\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8841 - recall: 0.8825 \n",
      "Epoch 42: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8841 - recall: 0.8825 - val_loss: 0.2713 - val_auc: 0.9713 - val_accuracy: 0.9257 - val_precision: 0.7035 - val_recall: 0.9448 - lr: 2.7654e-18\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2037 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8840 - recall: 0.8828 \n",
      "Epoch 43: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2037 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8840 - recall: 0.8828 - val_loss: 0.2724 - val_auc: 0.9718 - val_accuracy: 0.9250 - val_precision: 0.7006 - val_recall: 0.9470 - lr: 2.7654e-19\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8846 - recall: 0.8829 \n",
      "Epoch 44: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8846 - recall: 0.8829 - val_loss: 0.2734 - val_auc: 0.9723 - val_accuracy: 0.9244 - val_precision: 0.6981 - val_recall: 0.9494 - lr: 2.7654e-20\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2029 - auc: 0.9807 - accuracy: 0.9508 - precision: 0.8846 - recall: 0.8833 \n",
      "Epoch 45: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.2029 - auc: 0.9807 - accuracy: 0.9508 - precision: 0.8846 - recall: 0.8833 - val_loss: 0.2744 - val_auc: 0.9728 - val_accuracy: 0.9237 - val_precision: 0.6953 - val_recall: 0.9512 - lr: 2.7654e-21\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8849 - recall: 0.8826 \n",
      "Epoch 46: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2032 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8849 - recall: 0.8826 - val_loss: 0.2753 - val_auc: 0.9732 - val_accuracy: 0.9232 - val_precision: 0.6932 - val_recall: 0.9528 - lr: 2.7654e-22\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2038 - auc: 0.9802 - accuracy: 0.9505 - precision: 0.8840 - recall: 0.8825 \n",
      "Epoch 47: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2038 - auc: 0.9802 - accuracy: 0.9505 - precision: 0.8840 - recall: 0.8825 - val_loss: 0.2761 - val_auc: 0.9736 - val_accuracy: 0.9227 - val_precision: 0.6915 - val_recall: 0.9540 - lr: 2.7654e-23\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9803 - accuracy: 0.9506 - precision: 0.8842 - recall: 0.8829\n",
      "Epoch 48: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2035 - auc: 0.9803 - accuracy: 0.9506 - precision: 0.8842 - recall: 0.8829 - val_loss: 0.2768 - val_auc: 0.9739 - val_accuracy: 0.9222 - val_precision: 0.6897 - val_recall: 0.9552 - lr: 2.7654e-24\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8839 - recall: 0.8832\n",
      "Epoch 49: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 95s 9s/step - loss: 0.2034 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8839 - recall: 0.8832 - val_loss: 0.2776 - val_auc: 0.9741 - val_accuracy: 0.9219 - val_precision: 0.6883 - val_recall: 0.9566 - lr: 2.7654e-25\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9803 - accuracy: 0.9506 - precision: 0.8851 - recall: 0.8819\n",
      "Epoch 50: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2034 - auc: 0.9803 - accuracy: 0.9506 - precision: 0.8851 - recall: 0.8819 - val_loss: 0.2782 - val_auc: 0.9743 - val_accuracy: 0.9216 - val_precision: 0.6871 - val_recall: 0.9573 - lr: 2.7654e-26\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8832\n",
      "Epoch 51: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2033 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8832 - val_loss: 0.2788 - val_auc: 0.9745 - val_accuracy: 0.9212 - val_precision: 0.6858 - val_recall: 0.9583 - lr: 2.7654e-27\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - auc: 0.9806 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8829\n",
      "Epoch 52: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2032 - auc: 0.9806 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8829 - val_loss: 0.2794 - val_auc: 0.9747 - val_accuracy: 0.9208 - val_precision: 0.6844 - val_recall: 0.9590 - lr: 2.7654e-28\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8839 - recall: 0.8830\n",
      "Epoch 53: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.2036 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8839 - recall: 0.8830 - val_loss: 0.2798 - val_auc: 0.9748 - val_accuracy: 0.9206 - val_precision: 0.6835 - val_recall: 0.9597 - lr: 2.7654e-29\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8823\n",
      "Epoch 54: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.2036 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8842 - recall: 0.8823 - val_loss: 0.2802 - val_auc: 0.9750 - val_accuracy: 0.9204 - val_precision: 0.6827 - val_recall: 0.9603 - lr: 2.7654e-30\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2030 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8832 \n",
      "Epoch 55: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2030 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8832 - val_loss: 0.2808 - val_auc: 0.9751 - val_accuracy: 0.9200 - val_precision: 0.6816 - val_recall: 0.9609 - lr: 2.7654e-31\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9806 - accuracy: 0.9507 - precision: 0.8842 - recall: 0.8833 \n",
      "Epoch 56: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2034 - auc: 0.9806 - accuracy: 0.9507 - precision: 0.8842 - recall: 0.8833 - val_loss: 0.2811 - val_auc: 0.9751 - val_accuracy: 0.9198 - val_precision: 0.6808 - val_recall: 0.9615 - lr: 2.7654e-32\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8841 - recall: 0.8838\n",
      "Epoch 57: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2032 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8841 - recall: 0.8838 - val_loss: 0.2815 - val_auc: 0.9752 - val_accuracy: 0.9196 - val_precision: 0.6802 - val_recall: 0.9619 - lr: 2.7654e-33\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2028 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8851 - recall: 0.8834\n",
      "Epoch 58: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2028 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8851 - recall: 0.8834 - val_loss: 0.2818 - val_auc: 0.9753 - val_accuracy: 0.9195 - val_precision: 0.6796 - val_recall: 0.9623 - lr: 2.7654e-34\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2029 - auc: 0.9806 - accuracy: 0.9508 - precision: 0.8847 - recall: 0.8832\n",
      "Epoch 59: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2029 - auc: 0.9806 - accuracy: 0.9508 - precision: 0.8847 - recall: 0.8832 - val_loss: 0.2821 - val_auc: 0.9754 - val_accuracy: 0.9193 - val_precision: 0.6791 - val_recall: 0.9626 - lr: 2.7654e-35\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8832 \n",
      "Epoch 60: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2034 - auc: 0.9805 - accuracy: 0.9506 - precision: 0.8841 - recall: 0.8832 - val_loss: 0.2822 - val_auc: 0.9754 - val_accuracy: 0.9193 - val_precision: 0.6789 - val_recall: 0.9628 - lr: 2.7654e-36\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8824 \n",
      "Epoch 61: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2035 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8824 - val_loss: 0.2824 - val_auc: 0.9755 - val_accuracy: 0.9192 - val_precision: 0.6785 - val_recall: 0.9631 - lr: 2.7654e-37\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2042 - auc: 0.9799 - accuracy: 0.9502 - precision: 0.8830 - recall: 0.8824 \n",
      "Epoch 62: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2042 - auc: 0.9799 - accuracy: 0.9502 - precision: 0.8830 - recall: 0.8824 - val_loss: 0.2825 - val_auc: 0.9755 - val_accuracy: 0.9191 - val_precision: 0.6783 - val_recall: 0.9632 - lr: 2.7654e-38\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8838 - recall: 0.8829 \n",
      "Epoch 63: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2034 - auc: 0.9804 - accuracy: 0.9505 - precision: 0.8838 - recall: 0.8829 - val_loss: 0.2827 - val_auc: 0.9756 - val_accuracy: 0.9190 - val_precision: 0.6779 - val_recall: 0.9634 - lr: 2.7654e-39\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2037 - auc: 0.9801 - accuracy: 0.9504 - precision: 0.8837 - recall: 0.8825\n",
      "Epoch 64: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2037 - auc: 0.9801 - accuracy: 0.9504 - precision: 0.8837 - recall: 0.8825 - val_loss: 0.2829 - val_auc: 0.9756 - val_accuracy: 0.9189 - val_precision: 0.6775 - val_recall: 0.9635 - lr: 2.7654e-40\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8827 \n",
      "Epoch 65: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2032 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8827 - val_loss: 0.2831 - val_auc: 0.9756 - val_accuracy: 0.9187 - val_precision: 0.6771 - val_recall: 0.9637 - lr: 2.7655e-41\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8824\n",
      "Epoch 66: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2035 - auc: 0.9804 - accuracy: 0.9506 - precision: 0.8845 - recall: 0.8824 - val_loss: 0.2832 - val_auc: 0.9756 - val_accuracy: 0.9187 - val_precision: 0.6769 - val_recall: 0.9638 - lr: 2.7662e-42\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2039 - auc: 0.9803 - accuracy: 0.9503 - precision: 0.8837 - recall: 0.8820 \n",
      "Epoch 67: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2039 - auc: 0.9803 - accuracy: 0.9503 - precision: 0.8837 - recall: 0.8820 - val_loss: 0.2832 - val_auc: 0.9757 - val_accuracy: 0.9187 - val_precision: 0.6770 - val_recall: 0.9639 - lr: 2.7606e-43\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2030 - auc: 0.9807 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8833 \n",
      "Epoch 68: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.2030 - auc: 0.9807 - accuracy: 0.9507 - precision: 0.8844 - recall: 0.8833 - val_loss: 0.2833 - val_auc: 0.9757 - val_accuracy: 0.9186 - val_precision: 0.6767 - val_recall: 0.9639 - lr: 2.8026e-44\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2040 - auc: 0.9798 - accuracy: 0.9503 - precision: 0.8835 - recall: 0.8822 \n",
      "Epoch 69: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2040 - auc: 0.9798 - accuracy: 0.9503 - precision: 0.8835 - recall: 0.8822 - val_loss: 0.2833 - val_auc: 0.9757 - val_accuracy: 0.9186 - val_precision: 0.6767 - val_recall: 0.9640 - lr: 2.8026e-45\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2042 - auc: 0.9800 - accuracy: 0.9502 - precision: 0.8834 - recall: 0.8820 \n",
      "Epoch 70: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2042 - auc: 0.9800 - accuracy: 0.9502 - precision: 0.8834 - recall: 0.8820 - val_loss: 0.2834 - val_auc: 0.9757 - val_accuracy: 0.9186 - val_precision: 0.6767 - val_recall: 0.9640 - lr: 0.0000e+00\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2030 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8848 - recall: 0.8827 \n",
      "Epoch 71: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2030 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8848 - recall: 0.8827 - val_loss: 0.2836 - val_auc: 0.9757 - val_accuracy: 0.9185 - val_precision: 0.6764 - val_recall: 0.9642 - lr: 0.0000e+00\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2031 - auc: 0.9807 - accuracy: 0.9507 - precision: 0.8847 - recall: 0.8825\n",
      "Epoch 72: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2031 - auc: 0.9807 - accuracy: 0.9507 - precision: 0.8847 - recall: 0.8825 - val_loss: 0.2838 - val_auc: 0.9757 - val_accuracy: 0.9185 - val_precision: 0.6761 - val_recall: 0.9643 - lr: 0.0000e+00\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2035 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8844 - recall: 0.8826\n",
      "Epoch 73: val_loss did not improve from 0.26313\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2035 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8844 - recall: 0.8826 - val_loss: 0.2839 - val_auc: 0.9757 - val_accuracy: 0.9184 - val_precision: 0.6760 - val_recall: 0.9644 - lr: 0.0000e+00\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2032 - auc: 0.9806 - accuracy: 0.9507 - precision: 0.8845 - recall: 0.8833 \n",
      "Epoch 74: val_loss did not improve from 0.26313\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2032 - auc: 0.9806 - accuracy: 0.9507 - precision: 0.8845 - recall: 0.8833 - val_loss: 0.2839 - val_auc: 0.9757 - val_accuracy: 0.9184 - val_precision: 0.6759 - val_recall: 0.9644 - lr: 0.0000e+00\n",
      "Epoch 74: early stopping\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2002 - auc: 0.9631 - accuracy: 0.9594 - precision: 0.8068 - recall: 0.8242\n",
      "Loading weights from checkpoint: pixel_core_fold_16.hdf5\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2820 - auc: 0.9739 - accuracy: 0.9456 - precision: 0.8666 - recall: 0.8756\n",
      "Epoch 1: val_loss improved from inf to 0.42343, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2820 - auc: 0.9739 - accuracy: 0.9456 - precision: 0.8666 - recall: 0.8756 - val_loss: 0.4234 - val_auc: 0.8775 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2708 - auc: 0.9766 - accuracy: 0.9473 - precision: 0.8696 - recall: 0.8813 \n",
      "Epoch 2: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2708 - auc: 0.9766 - accuracy: 0.9473 - precision: 0.8696 - recall: 0.8813 - val_loss: 0.4483 - val_auc: 0.8782 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2648 - auc: 0.9779 - accuracy: 0.9477 - precision: 0.8734 - recall: 0.8783 \n",
      "Epoch 3: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2648 - auc: 0.9779 - accuracy: 0.9477 - precision: 0.8734 - recall: 0.8783 - val_loss: 0.4726 - val_auc: 0.6184 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2592 - auc: 0.9782 - accuracy: 0.9491 - precision: 0.8830 - recall: 0.8734 \n",
      "Epoch 4: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2592 - auc: 0.9782 - accuracy: 0.9491 - precision: 0.8830 - recall: 0.8734 - val_loss: 0.4871 - val_auc: 0.2986 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2553 - auc: 0.9800 - accuracy: 0.9488 - precision: 0.8718 - recall: 0.8868 \n",
      "Epoch 5: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2553 - auc: 0.9800 - accuracy: 0.9488 - precision: 0.8718 - recall: 0.8868 - val_loss: 0.4754 - val_auc: 0.1956 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.1157e-04\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2517 - auc: 0.9790 - accuracy: 0.9501 - precision: 0.8841 - recall: 0.8774 \n",
      "Epoch 6: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2517 - auc: 0.9790 - accuracy: 0.9501 - precision: 0.8841 - recall: 0.8774 - val_loss: 0.4760 - val_auc: 0.1278 - val_accuracy: 0.8426 - val_precision: 1.0000 - val_recall: 1.2116e-05 - lr: 1.1157e-04\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2492 - auc: 0.9799 - accuracy: 0.9506 - precision: 0.8865 - recall: 0.8770 \n",
      "Epoch 7: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2492 - auc: 0.9799 - accuracy: 0.9506 - precision: 0.8865 - recall: 0.8770 - val_loss: 0.4662 - val_auc: 0.1068 - val_accuracy: 0.8428 - val_precision: 1.0000 - val_recall: 0.0017 - lr: 6.7668e-05\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2475 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8830 - recall: 0.8812 \n",
      "Epoch 8: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2475 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8830 - recall: 0.8812 - val_loss: 0.4613 - val_auc: 0.1064 - val_accuracy: 0.8430 - val_precision: 1.0000 - val_recall: 0.0027 - lr: 6.7668e-05\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2459 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8796 \n",
      "Epoch 9: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2459 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8796 - val_loss: 0.4561 - val_auc: 0.1299 - val_accuracy: 0.8431 - val_precision: 1.0000 - val_recall: 0.0033 - lr: 4.1043e-05\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2462 - auc: 0.9801 - accuracy: 0.9503 - precision: 0.8827 - recall: 0.8803\n",
      "Epoch 10: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2462 - auc: 0.9801 - accuracy: 0.9503 - precision: 0.8827 - recall: 0.8803 - val_loss: 0.4526 - val_auc: 0.1400 - val_accuracy: 0.8432 - val_precision: 1.0000 - val_recall: 0.0036 - lr: 4.1043e-05\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2447 - auc: 0.9804 - accuracy: 0.9508 - precision: 0.8853 - recall: 0.8799 \n",
      "Epoch 11: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2447 - auc: 0.9804 - accuracy: 0.9508 - precision: 0.8853 - recall: 0.8799 - val_loss: 0.4499 - val_auc: 0.1811 - val_accuracy: 0.8432 - val_precision: 1.0000 - val_recall: 0.0041 - lr: 2.4894e-05\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2446 - auc: 0.9802 - accuracy: 0.9507 - precision: 0.8863 - recall: 0.8781\n",
      "Epoch 12: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2446 - auc: 0.9802 - accuracy: 0.9507 - precision: 0.8863 - recall: 0.8781 - val_loss: 0.4462 - val_auc: 0.2042 - val_accuracy: 0.8438 - val_precision: 1.0000 - val_recall: 0.0076 - lr: 2.4894e-05\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2452 - auc: 0.9799 - accuracy: 0.9501 - precision: 0.8844 - recall: 0.8773\n",
      "Epoch 13: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2452 - auc: 0.9799 - accuracy: 0.9501 - precision: 0.8844 - recall: 0.8773 - val_loss: 0.4414 - val_auc: 0.2516 - val_accuracy: 0.8448 - val_precision: 1.0000 - val_recall: 0.0142 - lr: 1.5099e-05\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2440 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8859 - recall: 0.8786 \n",
      "Epoch 14: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2440 - auc: 0.9804 - accuracy: 0.9507 - precision: 0.8859 - recall: 0.8786 - val_loss: 0.4344 - val_auc: 0.3447 - val_accuracy: 0.8472 - val_precision: 0.9988 - val_recall: 0.0295 - lr: 1.5099e-05\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2429 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8800 \n",
      "Epoch 15: val_loss did not improve from 0.42343\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2429 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8800 - val_loss: 0.4257 - val_auc: 0.4222 - val_accuracy: 0.8501 - val_precision: 0.9987 - val_recall: 0.0481 - lr: 9.1578e-06\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2433 - auc: 0.9804 - accuracy: 0.9509 - precision: 0.8858 - recall: 0.8795 \n",
      "Epoch 16: val_loss improved from 0.42343 to 0.41695, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2433 - auc: 0.9804 - accuracy: 0.9509 - precision: 0.8858 - recall: 0.8795 - val_loss: 0.4170 - val_auc: 0.5236 - val_accuracy: 0.8535 - val_precision: 0.9984 - val_recall: 0.0693 - lr: 9.1578e-06\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2429 - auc: 0.9804 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8794 \n",
      "Epoch 17: val_loss improved from 0.41695 to 0.40707, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2429 - auc: 0.9804 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8794 - val_loss: 0.4071 - val_auc: 0.5881 - val_accuracy: 0.8573 - val_precision: 0.9966 - val_recall: 0.0936 - lr: 5.5545e-06\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2431 - auc: 0.9804 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8792\n",
      "Epoch 18: val_loss improved from 0.40707 to 0.39492, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2431 - auc: 0.9804 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8792 - val_loss: 0.3949 - val_auc: 0.7127 - val_accuracy: 0.8624 - val_precision: 0.9949 - val_recall: 0.1263 - lr: 5.5545e-06\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2426 - auc: 0.9808 - accuracy: 0.9511 - precision: 0.8864 - recall: 0.8798 \n",
      "Epoch 19: val_loss improved from 0.39492 to 0.38009, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2426 - auc: 0.9808 - accuracy: 0.9511 - precision: 0.8864 - recall: 0.8798 - val_loss: 0.3801 - val_auc: 0.7448 - val_accuracy: 0.8690 - val_precision: 0.9932 - val_recall: 0.1691 - lr: 3.3690e-06\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8795 \n",
      "Epoch 20: val_loss improved from 0.38009 to 0.36261, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2428 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8795 - val_loss: 0.3626 - val_auc: 0.7833 - val_accuracy: 0.8782 - val_precision: 0.9918 - val_recall: 0.2282 - lr: 3.3690e-06\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2432 - auc: 0.9801 - accuracy: 0.9507 - precision: 0.8852 - recall: 0.8791\n",
      "Epoch 21: val_loss improved from 0.36261 to 0.34451, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2432 - auc: 0.9801 - accuracy: 0.9507 - precision: 0.8852 - recall: 0.8791 - val_loss: 0.3445 - val_auc: 0.8155 - val_accuracy: 0.8883 - val_precision: 0.9893 - val_recall: 0.2934 - lr: 2.0434e-06\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2425 - auc: 0.9808 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8796 \n",
      "Epoch 22: val_loss improved from 0.34451 to 0.32631, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2425 - auc: 0.9808 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8796 - val_loss: 0.3263 - val_auc: 0.8519 - val_accuracy: 0.8988 - val_precision: 0.9849 - val_recall: 0.3625 - lr: 2.0434e-06\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2425 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8793\n",
      "Epoch 23: val_loss improved from 0.32631 to 0.30845, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2425 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8793 - val_loss: 0.3084 - val_auc: 0.8911 - val_accuracy: 0.9094 - val_precision: 0.9814 - val_recall: 0.4326 - lr: 1.2394e-06\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2426 - auc: 0.9805 - accuracy: 0.9510 - precision: 0.8863 - recall: 0.8795\n",
      "Epoch 24: val_loss improved from 0.30845 to 0.29123, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2426 - auc: 0.9805 - accuracy: 0.9510 - precision: 0.8863 - recall: 0.8795 - val_loss: 0.2912 - val_auc: 0.9079 - val_accuracy: 0.9200 - val_precision: 0.9751 - val_recall: 0.5048 - lr: 1.2394e-06\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8865 - recall: 0.8798 \n",
      "Epoch 25: val_loss improved from 0.29123 to 0.27657, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2424 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8865 - recall: 0.8798 - val_loss: 0.2766 - val_auc: 0.9215 - val_accuracy: 0.9293 - val_precision: 0.9687 - val_recall: 0.5691 - lr: 7.5172e-07\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9805 - accuracy: 0.9511 - precision: 0.8863 - recall: 0.8802 \n",
      "Epoch 26: val_loss improved from 0.27657 to 0.26461, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2424 - auc: 0.9805 - accuracy: 0.9511 - precision: 0.8863 - recall: 0.8802 - val_loss: 0.2646 - val_auc: 0.9335 - val_accuracy: 0.9363 - val_precision: 0.9618 - val_recall: 0.6200 - lr: 7.5172e-07\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2431 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8854 - recall: 0.8792\n",
      "Epoch 27: val_loss improved from 0.26461 to 0.25437, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2431 - auc: 0.9805 - accuracy: 0.9507 - precision: 0.8854 - recall: 0.8792 - val_loss: 0.2544 - val_auc: 0.9437 - val_accuracy: 0.9425 - val_precision: 0.9552 - val_recall: 0.6660 - lr: 4.5594e-07\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9803 - accuracy: 0.9509 - precision: 0.8859 - recall: 0.8796 \n",
      "Epoch 28: val_loss improved from 0.25437 to 0.24587, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2428 - auc: 0.9803 - accuracy: 0.9509 - precision: 0.8859 - recall: 0.8796 - val_loss: 0.2459 - val_auc: 0.9504 - val_accuracy: 0.9483 - val_precision: 0.9498 - val_recall: 0.7093 - lr: 4.5594e-07\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2432 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8854 - recall: 0.8793 \n",
      "Epoch 29: val_loss improved from 0.24587 to 0.23941, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2432 - auc: 0.9803 - accuracy: 0.9507 - precision: 0.8854 - recall: 0.8793 - val_loss: 0.2394 - val_auc: 0.9556 - val_accuracy: 0.9527 - val_precision: 0.9435 - val_recall: 0.7440 - lr: 2.7654e-07\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2420 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8802\n",
      "Epoch 30: val_loss improved from 0.23941 to 0.23481, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2420 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8802 - val_loss: 0.2348 - val_auc: 0.9597 - val_accuracy: 0.9559 - val_precision: 0.9367 - val_recall: 0.7723 - lr: 2.7654e-07\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9510 - precision: 0.8859 - recall: 0.8799\n",
      "Epoch 31: val_loss improved from 0.23481 to 0.23149, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9510 - precision: 0.8859 - recall: 0.8799 - val_loss: 0.2315 - val_auc: 0.9628 - val_accuracy: 0.9580 - val_precision: 0.9285 - val_recall: 0.7944 - lr: 2.7654e-07\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2421 - auc: 0.9809 - accuracy: 0.9512 - precision: 0.8864 - recall: 0.8806\n",
      "Epoch 32: val_loss improved from 0.23149 to 0.22905, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.2421 - auc: 0.9809 - accuracy: 0.9512 - precision: 0.8864 - recall: 0.8806 - val_loss: 0.2291 - val_auc: 0.9653 - val_accuracy: 0.9595 - val_precision: 0.9203 - val_recall: 0.8134 - lr: 2.7654e-08\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2421 - auc: 0.9808 - accuracy: 0.9513 - precision: 0.8874 - recall: 0.8799\n",
      "Epoch 33: val_loss improved from 0.22905 to 0.22733, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2421 - auc: 0.9808 - accuracy: 0.9513 - precision: 0.8874 - recall: 0.8799 - val_loss: 0.2273 - val_auc: 0.9676 - val_accuracy: 0.9608 - val_precision: 0.9134 - val_recall: 0.8295 - lr: 2.7654e-09\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8792 \n",
      "Epoch 34: val_loss improved from 0.22733 to 0.22616, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2427 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8792 - val_loss: 0.2262 - val_auc: 0.9696 - val_accuracy: 0.9615 - val_precision: 0.9063 - val_recall: 0.8429 - lr: 2.7654e-10\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8791\n",
      "Epoch 35: val_loss improved from 0.22616 to 0.22546, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8862 - recall: 0.8791 - val_loss: 0.2255 - val_auc: 0.9714 - val_accuracy: 0.9620 - val_precision: 0.8994 - val_recall: 0.8540 - lr: 2.7654e-11\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8792\n",
      "Epoch 36: val_loss improved from 0.22546 to 0.22512, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8861 - recall: 0.8792 - val_loss: 0.2251 - val_auc: 0.9729 - val_accuracy: 0.9622 - val_precision: 0.8932 - val_recall: 0.8632 - lr: 2.7654e-12\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8792\n",
      "Epoch 37: val_loss improved from 0.22512 to 0.22504, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2428 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8792 - val_loss: 0.2250 - val_auc: 0.9742 - val_accuracy: 0.9621 - val_precision: 0.8867 - val_recall: 0.8706 - lr: 2.7654e-13\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9807 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8794\n",
      "Epoch 38: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2427 - auc: 0.9807 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8794 - val_loss: 0.2251 - val_auc: 0.9754 - val_accuracy: 0.9619 - val_precision: 0.8810 - val_recall: 0.8766 - lr: 2.7654e-14\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9799 - accuracy: 0.9509 - precision: 0.8857 - recall: 0.8800\n",
      "Epoch 39: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2428 - auc: 0.9799 - accuracy: 0.9509 - precision: 0.8857 - recall: 0.8800 - val_loss: 0.2254 - val_auc: 0.9763 - val_accuracy: 0.9618 - val_precision: 0.8760 - val_recall: 0.8819 - lr: 2.7654e-15\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2432 - auc: 0.9798 - accuracy: 0.9507 - precision: 0.8851 - recall: 0.8794\n",
      "Epoch 40: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2432 - auc: 0.9798 - accuracy: 0.9507 - precision: 0.8851 - recall: 0.8794 - val_loss: 0.2257 - val_auc: 0.9773 - val_accuracy: 0.9615 - val_precision: 0.8710 - val_recall: 0.8864 - lr: 2.7654e-16\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2425 - auc: 0.9806 - accuracy: 0.9510 - precision: 0.8864 - recall: 0.8796\n",
      "Epoch 41: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.2425 - auc: 0.9806 - accuracy: 0.9510 - precision: 0.8864 - recall: 0.8796 - val_loss: 0.2261 - val_auc: 0.9781 - val_accuracy: 0.9613 - val_precision: 0.8668 - val_recall: 0.8911 - lr: 2.7654e-17\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9804 - accuracy: 0.9511 - precision: 0.8864 - recall: 0.8801\n",
      "Epoch 42: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.2424 - auc: 0.9804 - accuracy: 0.9511 - precision: 0.8864 - recall: 0.8801 - val_loss: 0.2266 - val_auc: 0.9789 - val_accuracy: 0.9611 - val_precision: 0.8623 - val_recall: 0.8955 - lr: 2.7654e-18\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2430 - auc: 0.9801 - accuracy: 0.9508 - precision: 0.8857 - recall: 0.8790\n",
      "Epoch 43: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.2430 - auc: 0.9801 - accuracy: 0.9508 - precision: 0.8857 - recall: 0.8790 - val_loss: 0.2272 - val_auc: 0.9796 - val_accuracy: 0.9607 - val_precision: 0.8584 - val_recall: 0.8987 - lr: 2.7654e-19\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2426 - auc: 0.9807 - accuracy: 0.9510 - precision: 0.8860 - recall: 0.8799\n",
      "Epoch 44: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2426 - auc: 0.9807 - accuracy: 0.9510 - precision: 0.8860 - recall: 0.8799 - val_loss: 0.2278 - val_auc: 0.9799 - val_accuracy: 0.9602 - val_precision: 0.8542 - val_recall: 0.9013 - lr: 2.7654e-20\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2429 - auc: 0.9802 - accuracy: 0.9508 - precision: 0.8854 - recall: 0.8795 \n",
      "Epoch 45: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2429 - auc: 0.9802 - accuracy: 0.9508 - precision: 0.8854 - recall: 0.8795 - val_loss: 0.2284 - val_auc: 0.9801 - val_accuracy: 0.9598 - val_precision: 0.8508 - val_recall: 0.9034 - lr: 2.7654e-21\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2420 - auc: 0.9807 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8804 \n",
      "Epoch 46: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2420 - auc: 0.9807 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8804 - val_loss: 0.2290 - val_auc: 0.9804 - val_accuracy: 0.9595 - val_precision: 0.8475 - val_recall: 0.9054 - lr: 2.7654e-22\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9808 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8797 \n",
      "Epoch 47: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2428 - auc: 0.9808 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8797 - val_loss: 0.2296 - val_auc: 0.9808 - val_accuracy: 0.9591 - val_precision: 0.8448 - val_recall: 0.9069 - lr: 2.7654e-23\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2422 - auc: 0.9809 - accuracy: 0.9512 - precision: 0.8867 - recall: 0.8802 \n",
      "Epoch 48: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2422 - auc: 0.9809 - accuracy: 0.9512 - precision: 0.8867 - recall: 0.8802 - val_loss: 0.2301 - val_auc: 0.9811 - val_accuracy: 0.9588 - val_precision: 0.8424 - val_recall: 0.9084 - lr: 2.7654e-24\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8857 - recall: 0.8797 \n",
      "Epoch 49: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2427 - auc: 0.9806 - accuracy: 0.9509 - precision: 0.8857 - recall: 0.8797 - val_loss: 0.2306 - val_auc: 0.9813 - val_accuracy: 0.9585 - val_precision: 0.8398 - val_recall: 0.9100 - lr: 2.7654e-25\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9802 - accuracy: 0.9510 - precision: 0.8862 - recall: 0.8797 \n",
      "Epoch 50: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2428 - auc: 0.9802 - accuracy: 0.9510 - precision: 0.8862 - recall: 0.8797 - val_loss: 0.2312 - val_auc: 0.9816 - val_accuracy: 0.9583 - val_precision: 0.8377 - val_recall: 0.9117 - lr: 2.7654e-26\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2422 - auc: 0.9810 - accuracy: 0.9512 - precision: 0.8869 - recall: 0.8798 \n",
      "Epoch 51: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2422 - auc: 0.9810 - accuracy: 0.9512 - precision: 0.8869 - recall: 0.8798 - val_loss: 0.2317 - val_auc: 0.9818 - val_accuracy: 0.9580 - val_precision: 0.8354 - val_recall: 0.9132 - lr: 2.7654e-27\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2423 - auc: 0.9806 - accuracy: 0.9512 - precision: 0.8865 - recall: 0.8802\n",
      "Epoch 52: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2423 - auc: 0.9806 - accuracy: 0.9512 - precision: 0.8865 - recall: 0.8802 - val_loss: 0.2321 - val_auc: 0.9820 - val_accuracy: 0.9577 - val_precision: 0.8331 - val_recall: 0.9145 - lr: 2.7654e-28\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2437 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8846 - recall: 0.8790 \n",
      "Epoch 53: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2437 - auc: 0.9803 - accuracy: 0.9505 - precision: 0.8846 - recall: 0.8790 - val_loss: 0.2325 - val_auc: 0.9821 - val_accuracy: 0.9575 - val_precision: 0.8316 - val_recall: 0.9154 - lr: 2.7654e-29\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2422 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8801 \n",
      "Epoch 54: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2422 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8801 - val_loss: 0.2330 - val_auc: 0.9823 - val_accuracy: 0.9573 - val_precision: 0.8299 - val_recall: 0.9166 - lr: 2.7654e-30\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2425 - auc: 0.9807 - accuracy: 0.9510 - precision: 0.8865 - recall: 0.8794\n",
      "Epoch 55: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2425 - auc: 0.9807 - accuracy: 0.9510 - precision: 0.8865 - recall: 0.8794 - val_loss: 0.2334 - val_auc: 0.9824 - val_accuracy: 0.9571 - val_precision: 0.8283 - val_recall: 0.9174 - lr: 2.7654e-31\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2420 - auc: 0.9808 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8802 \n",
      "Epoch 56: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2420 - auc: 0.9808 - accuracy: 0.9513 - precision: 0.8871 - recall: 0.8802 - val_loss: 0.2338 - val_auc: 0.9825 - val_accuracy: 0.9569 - val_precision: 0.8268 - val_recall: 0.9184 - lr: 2.7654e-32\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2421 - auc: 0.9811 - accuracy: 0.9513 - precision: 0.8870 - recall: 0.8802 \n",
      "Epoch 57: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2421 - auc: 0.9811 - accuracy: 0.9513 - precision: 0.8870 - recall: 0.8802 - val_loss: 0.2342 - val_auc: 0.9826 - val_accuracy: 0.9566 - val_precision: 0.8253 - val_recall: 0.9192 - lr: 2.7654e-33\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2433 - auc: 0.9799 - accuracy: 0.9507 - precision: 0.8852 - recall: 0.8790\n",
      "Epoch 58: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2433 - auc: 0.9799 - accuracy: 0.9507 - precision: 0.8852 - recall: 0.8790 - val_loss: 0.2345 - val_auc: 0.9826 - val_accuracy: 0.9565 - val_precision: 0.8243 - val_recall: 0.9198 - lr: 2.7654e-34\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2431 - auc: 0.9801 - accuracy: 0.9506 - precision: 0.8851 - recall: 0.8788\n",
      "Epoch 59: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2431 - auc: 0.9801 - accuracy: 0.9506 - precision: 0.8851 - recall: 0.8788 - val_loss: 0.2348 - val_auc: 0.9827 - val_accuracy: 0.9564 - val_precision: 0.8234 - val_recall: 0.9205 - lr: 2.7654e-35\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2421 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8869 - recall: 0.8804 \n",
      "Epoch 60: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2421 - auc: 0.9809 - accuracy: 0.9513 - precision: 0.8869 - recall: 0.8804 - val_loss: 0.2352 - val_auc: 0.9828 - val_accuracy: 0.9562 - val_precision: 0.8222 - val_recall: 0.9211 - lr: 2.7654e-36\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2426 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8858 - recall: 0.8797 \n",
      "Epoch 61: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2426 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8858 - recall: 0.8797 - val_loss: 0.2355 - val_auc: 0.9829 - val_accuracy: 0.9561 - val_precision: 0.8212 - val_recall: 0.9215 - lr: 2.7654e-37\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2422 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8800\n",
      "Epoch 62: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2422 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8800 - val_loss: 0.2357 - val_auc: 0.9829 - val_accuracy: 0.9559 - val_precision: 0.8204 - val_recall: 0.9220 - lr: 2.7654e-38\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2432 - auc: 0.9801 - accuracy: 0.9507 - precision: 0.8853 - recall: 0.8791 \n",
      "Epoch 63: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2432 - auc: 0.9801 - accuracy: 0.9507 - precision: 0.8853 - recall: 0.8791 - val_loss: 0.2359 - val_auc: 0.9829 - val_accuracy: 0.9559 - val_precision: 0.8198 - val_recall: 0.9224 - lr: 2.7654e-39\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9809 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8799 \n",
      "Epoch 64: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2424 - auc: 0.9809 - accuracy: 0.9511 - precision: 0.8866 - recall: 0.8799 - val_loss: 0.2361 - val_auc: 0.9829 - val_accuracy: 0.9558 - val_precision: 0.8192 - val_recall: 0.9226 - lr: 2.7654e-40\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9805 - accuracy: 0.9512 - precision: 0.8865 - recall: 0.8803 \n",
      "Epoch 65: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2424 - auc: 0.9805 - accuracy: 0.9512 - precision: 0.8865 - recall: 0.8803 - val_loss: 0.2363 - val_auc: 0.9830 - val_accuracy: 0.9557 - val_precision: 0.8185 - val_recall: 0.9230 - lr: 2.7655e-41\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2424 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8861 - recall: 0.8804 \n",
      "Epoch 66: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2424 - auc: 0.9806 - accuracy: 0.9511 - precision: 0.8861 - recall: 0.8804 - val_loss: 0.2365 - val_auc: 0.9830 - val_accuracy: 0.9555 - val_precision: 0.8177 - val_recall: 0.9232 - lr: 2.7662e-42\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2429 - auc: 0.9803 - accuracy: 0.9509 - precision: 0.8856 - recall: 0.8796 \n",
      "Epoch 67: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2429 - auc: 0.9803 - accuracy: 0.9509 - precision: 0.8856 - recall: 0.8796 - val_loss: 0.2366 - val_auc: 0.9830 - val_accuracy: 0.9555 - val_precision: 0.8174 - val_recall: 0.9234 - lr: 2.7606e-43\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2430 - auc: 0.9802 - accuracy: 0.9508 - precision: 0.8858 - recall: 0.8790 \n",
      "Epoch 68: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2430 - auc: 0.9802 - accuracy: 0.9508 - precision: 0.8858 - recall: 0.8790 - val_loss: 0.2368 - val_auc: 0.9831 - val_accuracy: 0.9554 - val_precision: 0.8168 - val_recall: 0.9237 - lr: 2.8026e-44\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2418 - auc: 0.9810 - accuracy: 0.9514 - precision: 0.8872 - recall: 0.8809 \n",
      "Epoch 69: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2418 - auc: 0.9810 - accuracy: 0.9514 - precision: 0.8872 - recall: 0.8809 - val_loss: 0.2370 - val_auc: 0.9831 - val_accuracy: 0.9553 - val_precision: 0.8164 - val_recall: 0.9239 - lr: 2.8026e-45\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2422 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8803 \n",
      "Epoch 70: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2422 - auc: 0.9808 - accuracy: 0.9512 - precision: 0.8868 - recall: 0.8803 - val_loss: 0.2371 - val_auc: 0.9831 - val_accuracy: 0.9552 - val_precision: 0.8158 - val_recall: 0.9242 - lr: 0.0000e+00\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8794 \n",
      "Epoch 71: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.2428 - auc: 0.9802 - accuracy: 0.9509 - precision: 0.8860 - recall: 0.8794 - val_loss: 0.2373 - val_auc: 0.9831 - val_accuracy: 0.9552 - val_precision: 0.8155 - val_recall: 0.9243 - lr: 0.0000e+00\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2428 - auc: 0.9805 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8793 \n",
      "Epoch 72: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.2428 - auc: 0.9805 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8793 - val_loss: 0.2374 - val_auc: 0.9831 - val_accuracy: 0.9551 - val_precision: 0.8150 - val_recall: 0.9245 - lr: 0.0000e+00\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2427 - auc: 0.9801 - accuracy: 0.9510 - precision: 0.8863 - recall: 0.8795\n",
      "Epoch 73: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2427 - auc: 0.9801 - accuracy: 0.9510 - precision: 0.8863 - recall: 0.8795 - val_loss: 0.2375 - val_auc: 0.9831 - val_accuracy: 0.9550 - val_precision: 0.8147 - val_recall: 0.9247 - lr: 0.0000e+00\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2426 - auc: 0.9804 - accuracy: 0.9510 - precision: 0.8862 - recall: 0.8795 \n",
      "Epoch 74: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2426 - auc: 0.9804 - accuracy: 0.9510 - precision: 0.8862 - recall: 0.8795 - val_loss: 0.2375 - val_auc: 0.9832 - val_accuracy: 0.9550 - val_precision: 0.8145 - val_recall: 0.9248 - lr: 0.0000e+00\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2434 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8850 - recall: 0.8790\n",
      "Epoch 75: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2434 - auc: 0.9802 - accuracy: 0.9506 - precision: 0.8850 - recall: 0.8790 - val_loss: 0.2375 - val_auc: 0.9832 - val_accuracy: 0.9550 - val_precision: 0.8144 - val_recall: 0.9248 - lr: 0.0000e+00\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2431 - auc: 0.9801 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8793 \n",
      "Epoch 76: val_loss did not improve from 0.22504\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2431 - auc: 0.9801 - accuracy: 0.9508 - precision: 0.8855 - recall: 0.8793 - val_loss: 0.2376 - val_auc: 0.9832 - val_accuracy: 0.9550 - val_precision: 0.8143 - val_recall: 0.9248 - lr: 0.0000e+00\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2436 - auc: 0.9802 - accuracy: 0.9504 - precision: 0.8847 - recall: 0.8781 \n",
      "Epoch 77: val_loss did not improve from 0.22504\n",
      "Restoring model weights from the end of the best epoch: 37.\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2436 - auc: 0.9802 - accuracy: 0.9504 - precision: 0.8847 - recall: 0.8781 - val_loss: 0.2376 - val_auc: 0.9832 - val_accuracy: 0.9550 - val_precision: 0.8143 - val_recall: 0.9248 - lr: 0.0000e+00\n",
      "Epoch 77: early stopping\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3065 - auc: 0.9743 - accuracy: 0.9275 - precision: 0.7038 - recall: 0.9229\n",
      "Loading weights from checkpoint: pixel_core_fold_19.hdf5\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1894 - auc: 0.9752 - accuracy: 0.9486 - precision: 0.8811 - recall: 0.8521 \n",
      "Epoch 1: val_loss improved from inf to 0.70108, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1894 - auc: 0.9752 - accuracy: 0.9486 - precision: 0.8811 - recall: 0.8521 - val_loss: 0.7011 - val_auc: 0.2652 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1861 - auc: 0.9762 - accuracy: 0.9485 - precision: 0.8756 - recall: 0.8586 \n",
      "Epoch 2: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1861 - auc: 0.9762 - accuracy: 0.9485 - precision: 0.8756 - recall: 0.8586 - val_loss: 0.7183 - val_auc: 0.8818 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 3.0327e-04\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1812 - auc: 0.9763 - accuracy: 0.9501 - precision: 0.8908 - recall: 0.8490 \n",
      "Epoch 3: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1812 - auc: 0.9763 - accuracy: 0.9501 - precision: 0.8908 - recall: 0.8490 - val_loss: 0.7058 - val_auc: 0.8464 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1790 - auc: 0.9775 - accuracy: 0.9501 - precision: 0.8814 - recall: 0.8607 \n",
      "Epoch 4: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1790 - auc: 0.9775 - accuracy: 0.9501 - precision: 0.8814 - recall: 0.8607 - val_loss: 0.7764 - val_auc: 0.0731 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.8394e-04\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1775 - auc: 0.9773 - accuracy: 0.9504 - precision: 0.8876 - recall: 0.8543 \n",
      "Epoch 5: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1775 - auc: 0.9773 - accuracy: 0.9504 - precision: 0.8876 - recall: 0.8543 - val_loss: 0.8172 - val_auc: 0.0676 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.1157e-04\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1768 - auc: 0.9774 - accuracy: 0.9502 - precision: 0.8880 - recall: 0.8529 \n",
      "Epoch 6: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1768 - auc: 0.9774 - accuracy: 0.9502 - precision: 0.8880 - recall: 0.8529 - val_loss: 0.8396 - val_auc: 0.0469 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 1.1157e-04\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1756 - auc: 0.9777 - accuracy: 0.9505 - precision: 0.8878 - recall: 0.8548 \n",
      "Epoch 7: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1756 - auc: 0.9777 - accuracy: 0.9505 - precision: 0.8878 - recall: 0.8548 - val_loss: 0.8592 - val_auc: 0.0865 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.7668e-05\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1741 - auc: 0.9779 - accuracy: 0.9510 - precision: 0.8908 - recall: 0.8541 \n",
      "Epoch 8: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1741 - auc: 0.9779 - accuracy: 0.9510 - precision: 0.8908 - recall: 0.8541 - val_loss: 0.8691 - val_auc: 0.1111 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 6.7668e-05\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1736 - auc: 0.9781 - accuracy: 0.9510 - precision: 0.8888 - recall: 0.8565 \n",
      "Epoch 9: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1736 - auc: 0.9781 - accuracy: 0.9510 - precision: 0.8888 - recall: 0.8565 - val_loss: 0.8813 - val_auc: 0.1312 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 4.1043e-05\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1732 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8901 - recall: 0.8558 \n",
      "Epoch 10: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1732 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8901 - recall: 0.8558 - val_loss: 0.8916 - val_auc: 0.1651 - val_accuracy: 0.6745 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 4.1043e-05\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1729 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8896 - recall: 0.8562 \n",
      "Epoch 11: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1729 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8896 - recall: 0.8562 - val_loss: 0.8993 - val_auc: 0.1934 - val_accuracy: 0.6746 - val_precision: 1.0000 - val_recall: 5.3319e-04 - lr: 2.4894e-05\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1740 - auc: 0.9778 - accuracy: 0.9505 - precision: 0.8863 - recall: 0.8567 \n",
      "Epoch 12: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1740 - auc: 0.9778 - accuracy: 0.9505 - precision: 0.8863 - recall: 0.8567 - val_loss: 0.9021 - val_auc: 0.2686 - val_accuracy: 0.6752 - val_precision: 1.0000 - val_recall: 0.0021 - lr: 2.4894e-05\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1732 - auc: 0.9782 - accuracy: 0.9508 - precision: 0.8877 - recall: 0.8570 \n",
      "Epoch 13: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1732 - auc: 0.9782 - accuracy: 0.9508 - precision: 0.8877 - recall: 0.8570 - val_loss: 0.8920 - val_auc: 0.4398 - val_accuracy: 0.6785 - val_precision: 0.9981 - val_recall: 0.0123 - lr: 1.5099e-05\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1731 - auc: 0.9781 - accuracy: 0.9508 - precision: 0.8876 - recall: 0.8566 \n",
      "Epoch 14: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1731 - auc: 0.9781 - accuracy: 0.9508 - precision: 0.8876 - recall: 0.8566 - val_loss: 0.8747 - val_auc: 0.4288 - val_accuracy: 0.6835 - val_precision: 0.9870 - val_recall: 0.0280 - lr: 1.5099e-05\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9513 - precision: 0.8904 - recall: 0.8561 \n",
      "Epoch 15: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9513 - precision: 0.8904 - recall: 0.8561 - val_loss: 0.8463 - val_auc: 0.4569 - val_accuracy: 0.6919 - val_precision: 0.9772 - val_recall: 0.0549 - lr: 9.1578e-06\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1720 - auc: 0.9785 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8567 \n",
      "Epoch 16: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1720 - auc: 0.9785 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8567 - val_loss: 0.8086 - val_auc: 0.6291 - val_accuracy: 0.7033 - val_precision: 0.9752 - val_recall: 0.0907 - lr: 9.1578e-06\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1719 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8900 - recall: 0.8568 \n",
      "Epoch 17: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1719 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8900 - recall: 0.8568 - val_loss: 0.7629 - val_auc: 0.6606 - val_accuracy: 0.7169 - val_precision: 0.9751 - val_recall: 0.1339 - lr: 5.5545e-06\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1721 - auc: 0.9782 - accuracy: 0.9512 - precision: 0.8895 - recall: 0.8568 \n",
      "Epoch 18: val_loss did not improve from 0.70108\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1721 - auc: 0.9782 - accuracy: 0.9512 - precision: 0.8895 - recall: 0.8568 - val_loss: 0.7097 - val_auc: 0.7090 - val_accuracy: 0.7321 - val_precision: 0.9741 - val_recall: 0.1819 - lr: 5.5545e-06\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8569\n",
      "Epoch 19: val_loss improved from 0.70108 to 0.64519, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8569 - val_loss: 0.6452 - val_auc: 0.8364 - val_accuracy: 0.7520 - val_precision: 0.9716 - val_recall: 0.2453 - lr: 3.3690e-06\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8900 - recall: 0.8571 \n",
      "Epoch 20: val_loss improved from 0.64519 to 0.57762, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8900 - recall: 0.8571 - val_loss: 0.5776 - val_auc: 0.8629 - val_accuracy: 0.7751 - val_precision: 0.9706 - val_recall: 0.3188 - lr: 3.3690e-06\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1719 - auc: 0.9784 - accuracy: 0.9512 - precision: 0.8891 - recall: 0.8573 \n",
      "Epoch 21: val_loss improved from 0.57762 to 0.51241, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1719 - auc: 0.9784 - accuracy: 0.9512 - precision: 0.8891 - recall: 0.8573 - val_loss: 0.5124 - val_auc: 0.8878 - val_accuracy: 0.7980 - val_precision: 0.9697 - val_recall: 0.3916 - lr: 2.0434e-06\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8898 - recall: 0.8574 \n",
      "Epoch 22: val_loss improved from 0.51241 to 0.45036, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8898 - recall: 0.8574 - val_loss: 0.4504 - val_auc: 0.9122 - val_accuracy: 0.8201 - val_precision: 0.9679 - val_recall: 0.4626 - lr: 2.0434e-06\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1722 - auc: 0.9781 - accuracy: 0.9511 - precision: 0.8895 - recall: 0.8563 \n",
      "Epoch 23: val_loss improved from 0.45036 to 0.39116, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1722 - auc: 0.9781 - accuracy: 0.9511 - precision: 0.8895 - recall: 0.8563 - val_loss: 0.3912 - val_auc: 0.9313 - val_accuracy: 0.8419 - val_precision: 0.9654 - val_recall: 0.5335 - lr: 1.2394e-06\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9511 - precision: 0.8892 - recall: 0.8564 \n",
      "Epoch 24: val_loss improved from 0.39116 to 0.33743, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9511 - precision: 0.8892 - recall: 0.8564 - val_loss: 0.3374 - val_auc: 0.9468 - val_accuracy: 0.8632 - val_precision: 0.9630 - val_recall: 0.6029 - lr: 1.2394e-06\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8571 \n",
      "Epoch 25: val_loss improved from 0.33743 to 0.29224, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8571 - val_loss: 0.2922 - val_auc: 0.9648 - val_accuracy: 0.8821 - val_precision: 0.9607 - val_recall: 0.6650 - lr: 7.5172e-07\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9783 - accuracy: 0.9514 - precision: 0.8904 - recall: 0.8567 \n",
      "Epoch 26: val_loss improved from 0.29224 to 0.25634, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1716 - auc: 0.9783 - accuracy: 0.9514 - precision: 0.8904 - recall: 0.8567 - val_loss: 0.2563 - val_auc: 0.9715 - val_accuracy: 0.8991 - val_precision: 0.9582 - val_recall: 0.7214 - lr: 7.5172e-07\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8900 - recall: 0.8572 \n",
      "Epoch 27: val_loss improved from 0.25634 to 0.22927, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8900 - recall: 0.8572 - val_loss: 0.2293 - val_auc: 0.9764 - val_accuracy: 0.9126 - val_precision: 0.9547 - val_recall: 0.7679 - lr: 4.5594e-07\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9783 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 \n",
      "Epoch 28: val_loss improved from 0.22927 to 0.20914, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1716 - auc: 0.9783 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 - val_loss: 0.2091 - val_auc: 0.9799 - val_accuracy: 0.9229 - val_precision: 0.9511 - val_recall: 0.8045 - lr: 4.5594e-07\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9783 - accuracy: 0.9513 - precision: 0.8899 - recall: 0.8568 \n",
      "Epoch 29: val_loss improved from 0.20914 to 0.19496, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1717 - auc: 0.9783 - accuracy: 0.9513 - precision: 0.8899 - recall: 0.8568 - val_loss: 0.1950 - val_auc: 0.9822 - val_accuracy: 0.9305 - val_precision: 0.9469 - val_recall: 0.8331 - lr: 2.7654e-07\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1726 - auc: 0.9780 - accuracy: 0.9509 - precision: 0.8882 - recall: 0.8566 \n",
      "Epoch 30: val_loss improved from 0.19496 to 0.18513, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1726 - auc: 0.9780 - accuracy: 0.9509 - precision: 0.8882 - recall: 0.8566 - val_loss: 0.1851 - val_auc: 0.9838 - val_accuracy: 0.9362 - val_precision: 0.9429 - val_recall: 0.8557 - lr: 2.7654e-07\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1720 - auc: 0.9784 - accuracy: 0.9511 - precision: 0.8894 - recall: 0.8565 \n",
      "Epoch 31: val_loss improved from 0.18513 to 0.17845, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1720 - auc: 0.9784 - accuracy: 0.9511 - precision: 0.8894 - recall: 0.8565 - val_loss: 0.1785 - val_auc: 0.9848 - val_accuracy: 0.9403 - val_precision: 0.9389 - val_recall: 0.8733 - lr: 2.7654e-07\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 \n",
      "Epoch 32: val_loss improved from 0.17845 to 0.17389, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1715 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 - val_loss: 0.1739 - val_auc: 0.9856 - val_accuracy: 0.9432 - val_precision: 0.9350 - val_recall: 0.8872 - lr: 2.7654e-08\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1723 - auc: 0.9781 - accuracy: 0.9511 - precision: 0.8893 - recall: 0.8562 \n",
      "Epoch 33: val_loss improved from 0.17389 to 0.17075, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1723 - auc: 0.9781 - accuracy: 0.9511 - precision: 0.8893 - recall: 0.8562 - val_loss: 0.1707 - val_auc: 0.9861 - val_accuracy: 0.9451 - val_precision: 0.9307 - val_recall: 0.8981 - lr: 2.7654e-09\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8892 - recall: 0.8572 \n",
      "Epoch 34: val_loss improved from 0.17075 to 0.16858, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1721 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8892 - recall: 0.8572 - val_loss: 0.1686 - val_auc: 0.9865 - val_accuracy: 0.9466 - val_precision: 0.9269 - val_recall: 0.9076 - lr: 2.7654e-10\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8902 - recall: 0.8574 \n",
      "Epoch 35: val_loss improved from 0.16858 to 0.16711, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8902 - recall: 0.8574 - val_loss: 0.1671 - val_auc: 0.9869 - val_accuracy: 0.9477 - val_precision: 0.9232 - val_recall: 0.9156 - lr: 2.7654e-11\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8898 - recall: 0.8575 \n",
      "Epoch 36: val_loss improved from 0.16711 to 0.16614, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8898 - recall: 0.8575 - val_loss: 0.1661 - val_auc: 0.9872 - val_accuracy: 0.9484 - val_precision: 0.9195 - val_recall: 0.9223 - lr: 2.7654e-12\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1725 - auc: 0.9782 - accuracy: 0.9509 - precision: 0.8881 - recall: 0.8569 \n",
      "Epoch 37: val_loss improved from 0.16614 to 0.16554, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1725 - auc: 0.9782 - accuracy: 0.9509 - precision: 0.8881 - recall: 0.8569 - val_loss: 0.1655 - val_auc: 0.9875 - val_accuracy: 0.9489 - val_precision: 0.9161 - val_recall: 0.9281 - lr: 2.7654e-13\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1714 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 \n",
      "Epoch 38: val_loss improved from 0.16554 to 0.16524, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1714 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8571 - val_loss: 0.1652 - val_auc: 0.9877 - val_accuracy: 0.9491 - val_precision: 0.9124 - val_recall: 0.9332 - lr: 2.7654e-14\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1720 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8893 - recall: 0.8573 \n",
      "Epoch 39: val_loss improved from 0.16524 to 0.16519, saving model to pixel_core_fold_19.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1720 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8893 - recall: 0.8573 - val_loss: 0.1652 - val_auc: 0.9879 - val_accuracy: 0.9492 - val_precision: 0.9091 - val_recall: 0.9376 - lr: 2.7654e-15\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9516 - precision: 0.8907 - recall: 0.8574 \n",
      "Epoch 40: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9516 - precision: 0.8907 - recall: 0.8574 - val_loss: 0.1654 - val_auc: 0.9881 - val_accuracy: 0.9491 - val_precision: 0.9060 - val_recall: 0.9413 - lr: 2.7654e-16\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1724 - auc: 0.9780 - accuracy: 0.9510 - precision: 0.8892 - recall: 0.8562 \n",
      "Epoch 41: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1724 - auc: 0.9780 - accuracy: 0.9510 - precision: 0.8892 - recall: 0.8562 - val_loss: 0.1657 - val_auc: 0.9882 - val_accuracy: 0.9490 - val_precision: 0.9030 - val_recall: 0.9447 - lr: 2.7654e-17\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8906 - recall: 0.8573 \n",
      "Epoch 42: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8906 - recall: 0.8573 - val_loss: 0.1662 - val_auc: 0.9883 - val_accuracy: 0.9487 - val_precision: 0.9002 - val_recall: 0.9475 - lr: 2.7654e-18\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - auc: 0.9775 - accuracy: 0.9507 - precision: 0.8883 - recall: 0.8556 \n",
      "Epoch 43: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1730 - auc: 0.9775 - accuracy: 0.9507 - precision: 0.8883 - recall: 0.8556 - val_loss: 0.1667 - val_auc: 0.9884 - val_accuracy: 0.9484 - val_precision: 0.8973 - val_recall: 0.9502 - lr: 2.7654e-19\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1713 - auc: 0.9787 - accuracy: 0.9515 - precision: 0.8907 - recall: 0.8572 \n",
      "Epoch 44: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1713 - auc: 0.9787 - accuracy: 0.9515 - precision: 0.8907 - recall: 0.8572 - val_loss: 0.1674 - val_auc: 0.9885 - val_accuracy: 0.9481 - val_precision: 0.8949 - val_recall: 0.9525 - lr: 2.7654e-20\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9513 - precision: 0.8896 - recall: 0.8574 \n",
      "Epoch 45: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9513 - precision: 0.8896 - recall: 0.8574 - val_loss: 0.1681 - val_auc: 0.9886 - val_accuracy: 0.9478 - val_precision: 0.8925 - val_recall: 0.9548 - lr: 2.7654e-21\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9784 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8571 \n",
      "Epoch 46: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1717 - auc: 0.9784 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8571 - val_loss: 0.1688 - val_auc: 0.9886 - val_accuracy: 0.9475 - val_precision: 0.8901 - val_recall: 0.9567 - lr: 2.7654e-22\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1714 - auc: 0.9787 - accuracy: 0.9515 - precision: 0.8903 - recall: 0.8575 \n",
      "Epoch 47: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1714 - auc: 0.9787 - accuracy: 0.9515 - precision: 0.8903 - recall: 0.8575 - val_loss: 0.1696 - val_auc: 0.9887 - val_accuracy: 0.9471 - val_precision: 0.8879 - val_recall: 0.9585 - lr: 2.7654e-23\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8570 \n",
      "Epoch 48: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8570 - val_loss: 0.1704 - val_auc: 0.9887 - val_accuracy: 0.9468 - val_precision: 0.8858 - val_recall: 0.9602 - lr: 2.7654e-24\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8895 - recall: 0.8571 \n",
      "Epoch 49: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1717 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8895 - recall: 0.8571 - val_loss: 0.1712 - val_auc: 0.9888 - val_accuracy: 0.9463 - val_precision: 0.8837 - val_recall: 0.9617 - lr: 2.7654e-25\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8904 - recall: 0.8570 \n",
      "Epoch 50: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1715 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8904 - recall: 0.8570 - val_loss: 0.1721 - val_auc: 0.9888 - val_accuracy: 0.9460 - val_precision: 0.8818 - val_recall: 0.9631 - lr: 2.7654e-26\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8569 \n",
      "Epoch 51: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1714 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8569 - val_loss: 0.1729 - val_auc: 0.9889 - val_accuracy: 0.9456 - val_precision: 0.8801 - val_recall: 0.9643 - lr: 2.7654e-27\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8902 - recall: 0.8568 \n",
      "Epoch 52: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8902 - recall: 0.8568 - val_loss: 0.1737 - val_auc: 0.9889 - val_accuracy: 0.9453 - val_precision: 0.8786 - val_recall: 0.9654 - lr: 2.7654e-28\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1725 - auc: 0.9781 - accuracy: 0.9508 - precision: 0.8882 - recall: 0.8561 \n",
      "Epoch 53: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1725 - auc: 0.9781 - accuracy: 0.9508 - precision: 0.8882 - recall: 0.8561 - val_loss: 0.1744 - val_auc: 0.9889 - val_accuracy: 0.9450 - val_precision: 0.8772 - val_recall: 0.9665 - lr: 2.7654e-29\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8902 - recall: 0.8572 \n",
      "Epoch 54: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1716 - auc: 0.9784 - accuracy: 0.9514 - precision: 0.8902 - recall: 0.8572 - val_loss: 0.1751 - val_auc: 0.9889 - val_accuracy: 0.9448 - val_precision: 0.8758 - val_recall: 0.9675 - lr: 2.7654e-30\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8894 - recall: 0.8576 \n",
      "Epoch 55: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8894 - recall: 0.8576 - val_loss: 0.1758 - val_auc: 0.9890 - val_accuracy: 0.9444 - val_precision: 0.8745 - val_recall: 0.9683 - lr: 2.7654e-31\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1725 - auc: 0.9780 - accuracy: 0.9509 - precision: 0.8887 - recall: 0.8563 \n",
      "Epoch 56: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1725 - auc: 0.9780 - accuracy: 0.9509 - precision: 0.8887 - recall: 0.8563 - val_loss: 0.1765 - val_auc: 0.9890 - val_accuracy: 0.9441 - val_precision: 0.8733 - val_recall: 0.9690 - lr: 2.7654e-32\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1720 - auc: 0.9782 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8565 \n",
      "Epoch 57: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1720 - auc: 0.9782 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8565 - val_loss: 0.1772 - val_auc: 0.9890 - val_accuracy: 0.9438 - val_precision: 0.8720 - val_recall: 0.9697 - lr: 2.7654e-33\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1723 - auc: 0.9782 - accuracy: 0.9510 - precision: 0.8887 - recall: 0.8567 \n",
      "Epoch 58: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1723 - auc: 0.9782 - accuracy: 0.9510 - precision: 0.8887 - recall: 0.8567 - val_loss: 0.1778 - val_auc: 0.9890 - val_accuracy: 0.9434 - val_precision: 0.8708 - val_recall: 0.9702 - lr: 2.7654e-34\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9512 - precision: 0.8893 - recall: 0.8570 \n",
      "Epoch 59: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9512 - precision: 0.8893 - recall: 0.8570 - val_loss: 0.1784 - val_auc: 0.9890 - val_accuracy: 0.9432 - val_precision: 0.8698 - val_recall: 0.9708 - lr: 2.7654e-35\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8571 \n",
      "Epoch 60: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8571 - val_loss: 0.1790 - val_auc: 0.9890 - val_accuracy: 0.9430 - val_precision: 0.8689 - val_recall: 0.9713 - lr: 2.7654e-36\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8569 \n",
      "Epoch 61: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1716 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8905 - recall: 0.8569 - val_loss: 0.1795 - val_auc: 0.9890 - val_accuracy: 0.9427 - val_precision: 0.8680 - val_recall: 0.9717 - lr: 2.7654e-37\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - auc: 0.9786 - accuracy: 0.9512 - precision: 0.8888 - recall: 0.8577 \n",
      "Epoch 62: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1718 - auc: 0.9786 - accuracy: 0.9512 - precision: 0.8888 - recall: 0.8577 - val_loss: 0.1799 - val_auc: 0.9890 - val_accuracy: 0.9425 - val_precision: 0.8673 - val_recall: 0.9721 - lr: 2.7654e-38\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1726 - auc: 0.9781 - accuracy: 0.9509 - precision: 0.8891 - recall: 0.8557 \n",
      "Epoch 63: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1726 - auc: 0.9781 - accuracy: 0.9509 - precision: 0.8891 - recall: 0.8557 - val_loss: 0.1803 - val_auc: 0.9890 - val_accuracy: 0.9423 - val_precision: 0.8665 - val_recall: 0.9725 - lr: 2.7654e-39\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1728 - auc: 0.9778 - accuracy: 0.9510 - precision: 0.8886 - recall: 0.8568 \n",
      "Epoch 64: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1728 - auc: 0.9778 - accuracy: 0.9510 - precision: 0.8886 - recall: 0.8568 - val_loss: 0.1807 - val_auc: 0.9890 - val_accuracy: 0.9421 - val_precision: 0.8658 - val_recall: 0.9729 - lr: 2.7654e-40\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1723 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8893 - recall: 0.8566 \n",
      "Epoch 65: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1723 - auc: 0.9782 - accuracy: 0.9511 - precision: 0.8893 - recall: 0.8566 - val_loss: 0.1812 - val_auc: 0.9890 - val_accuracy: 0.9419 - val_precision: 0.8652 - val_recall: 0.9732 - lr: 2.7655e-41\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8570 \n",
      "Epoch 66: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1715 - auc: 0.9786 - accuracy: 0.9514 - precision: 0.8903 - recall: 0.8570 - val_loss: 0.1816 - val_auc: 0.9891 - val_accuracy: 0.9418 - val_precision: 0.8646 - val_recall: 0.9735 - lr: 2.7662e-42\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9517 - precision: 0.8909 - recall: 0.8577 \n",
      "Epoch 67: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9517 - precision: 0.8909 - recall: 0.8577 - val_loss: 0.1819 - val_auc: 0.9891 - val_accuracy: 0.9416 - val_precision: 0.8640 - val_recall: 0.9737 - lr: 2.7606e-43\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9782 - accuracy: 0.9515 - precision: 0.8905 - recall: 0.8571 \n",
      "Epoch 68: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1716 - auc: 0.9782 - accuracy: 0.9515 - precision: 0.8905 - recall: 0.8571 - val_loss: 0.1822 - val_auc: 0.9891 - val_accuracy: 0.9414 - val_precision: 0.8635 - val_recall: 0.9739 - lr: 2.8026e-44\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9516 - precision: 0.8910 - recall: 0.8574 \n",
      "Epoch 69: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1711 - auc: 0.9787 - accuracy: 0.9516 - precision: 0.8910 - recall: 0.8574 - val_loss: 0.1826 - val_auc: 0.9891 - val_accuracy: 0.9412 - val_precision: 0.8630 - val_recall: 0.9741 - lr: 2.8026e-45\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8568 \n",
      "Epoch 70: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1718 - auc: 0.9783 - accuracy: 0.9512 - precision: 0.8897 - recall: 0.8568 - val_loss: 0.1828 - val_auc: 0.9891 - val_accuracy: 0.9411 - val_precision: 0.8626 - val_recall: 0.9742 - lr: 0.0000e+00\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8899 - recall: 0.8576 \n",
      "Epoch 71: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8899 - recall: 0.8576 - val_loss: 0.1831 - val_auc: 0.9891 - val_accuracy: 0.9410 - val_precision: 0.8623 - val_recall: 0.9744 - lr: 0.0000e+00\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1717 - auc: 0.9784 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8567 \n",
      "Epoch 72: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1717 - auc: 0.9784 - accuracy: 0.9513 - precision: 0.8898 - recall: 0.8567 - val_loss: 0.1833 - val_auc: 0.9891 - val_accuracy: 0.9409 - val_precision: 0.8619 - val_recall: 0.9746 - lr: 0.0000e+00\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8899 - recall: 0.8569 \n",
      "Epoch 73: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1718 - auc: 0.9785 - accuracy: 0.9513 - precision: 0.8899 - recall: 0.8569 - val_loss: 0.1835 - val_auc: 0.9891 - val_accuracy: 0.9408 - val_precision: 0.8616 - val_recall: 0.9746 - lr: 0.0000e+00\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1722 - auc: 0.9784 - accuracy: 0.9511 - precision: 0.8885 - recall: 0.8573 \n",
      "Epoch 74: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1722 - auc: 0.9784 - accuracy: 0.9511 - precision: 0.8885 - recall: 0.8573 - val_loss: 0.1837 - val_auc: 0.9891 - val_accuracy: 0.9407 - val_precision: 0.8613 - val_recall: 0.9747 - lr: 0.0000e+00\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1724 - auc: 0.9780 - accuracy: 0.9510 - precision: 0.8888 - recall: 0.8564 \n",
      "Epoch 75: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1724 - auc: 0.9780 - accuracy: 0.9510 - precision: 0.8888 - recall: 0.8564 - val_loss: 0.1838 - val_auc: 0.9891 - val_accuracy: 0.9406 - val_precision: 0.8611 - val_recall: 0.9749 - lr: 0.0000e+00\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8572 \n",
      "Epoch 76: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1715 - auc: 0.9785 - accuracy: 0.9514 - precision: 0.8901 - recall: 0.8572 - val_loss: 0.1840 - val_auc: 0.9891 - val_accuracy: 0.9406 - val_precision: 0.8609 - val_recall: 0.9750 - lr: 0.0000e+00\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1713 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8903 - recall: 0.8573 \n",
      "Epoch 77: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1713 - auc: 0.9786 - accuracy: 0.9515 - precision: 0.8903 - recall: 0.8573 - val_loss: 0.1841 - val_auc: 0.9891 - val_accuracy: 0.9405 - val_precision: 0.8606 - val_recall: 0.9750 - lr: 0.0000e+00\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9513 - precision: 0.8897 - recall: 0.8573 \n",
      "Epoch 78: val_loss did not improve from 0.16519\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1716 - auc: 0.9786 - accuracy: 0.9513 - precision: 0.8897 - recall: 0.8573 - val_loss: 0.1843 - val_auc: 0.9891 - val_accuracy: 0.9404 - val_precision: 0.8604 - val_recall: 0.9751 - lr: 0.0000e+00\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1725 - auc: 0.9783 - accuracy: 0.9509 - precision: 0.8880 - recall: 0.8568 \n",
      "Epoch 79: val_loss did not improve from 0.16519\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1725 - auc: 0.9783 - accuracy: 0.9509 - precision: 0.8880 - recall: 0.8568 - val_loss: 0.1843 - val_auc: 0.9891 - val_accuracy: 0.9403 - val_precision: 0.8603 - val_recall: 0.9752 - lr: 0.0000e+00\n",
      "Epoch 79: early stopping\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1044 - auc: 0.9940 - accuracy: 0.9804 - precision: 0.8230 - recall: 0.9236\n",
      "Average AUC: 0.9771 +/- 0.0128\n",
      "Average Accuracy: 0.9558 +/- 0.0218\n",
      "Average Precision: 0.7779 +/- 0.0528\n",
      "Average Recall: 0.8902 +/- 0.0467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation metrics initialization\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "new_size = (512, 512)\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('model_evaluation_results.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    # Check if the file is empty by seeking to the end and getting the position\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    if file.tell() == 0:\n",
    "        # File is empty, write the header\n",
    "        writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    file.flush() \n",
    "    indices = [14,16,19]\n",
    "    # Iterate over each fold\n",
    "    i = 0\n",
    "    for i, fold in enumerate([folds[index - 1] for index in indices], start=1):\n",
    "        augmented_train_images, test_image, validation_images = fold\n",
    "        i = indices[i-1]\n",
    "        # Load and preprocess images and labels\n",
    "        train_images, train_masks = load_images_and_labels(\n",
    "            augmented_train_images, augmented_label_dir, new_size)\n",
    "        test_images, test_masks = load_images_and_labels(\n",
    "            test_image, original_label_dir, new_size)\n",
    "        val_images, val_masks = load_images_and_labels(\n",
    "            validation_images, original_label_dir, new_size)\n",
    "\n",
    "        # Create a new instance of the model\n",
    "        model = unet()\n",
    "\n",
    "        # Train the model\n",
    "        trained_model = train_unet(model, train_images, train_masks, val_images, val_masks, 150, 32, \"pixel_core_fold_{i}.hdf5\".format(i=i))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = trained_model.evaluate(\n",
    "            test_images, test_masks)\n",
    "\n",
    "        # Store the evaluation metrics\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Write the fold results to the CSV file\n",
    "        writer.writerow([i, loss, auc, accuracy, precision, recall])\n",
    "        file.flush() \n",
    "\n",
    "# Calculate average and standard deviation of metrics\n",
    "avg_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "avg_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Average AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron\\Documents\\GitHub\\RizzGPT\\Microarray-Dearraying\\UNetDetection.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m plot_training_predictions(model, images, masks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_predictions(model, training_images, training_masks, num_samples=3):\n",
    "    # Make sure there is enough data for the number of samples requested\n",
    "    if num_samples > len(training_images):\n",
    "        num_samples = len(training_images)\n",
    "        print(f\"Number of available samples is less than requested. Setting num_samples to {num_samples}.\")\n",
    "\n",
    "    # Randomly select some samples from the training images and masks\n",
    "    indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    sample_images = np.array([training_images[i] for i in indices])\n",
    "    sample_masks = np.array([training_masks[i] for i in indices])\n",
    "\n",
    "    # Generate predictions for the sample_images\n",
    "    predicted_masks = model.predict(sample_images)\n",
    "\n",
    "    # Convert predicted masks to binary\n",
    "    binary_predicted_masks = (predicted_masks > 0.114).astype(np.uint8)\n",
    "\n",
    "    # Set up the matplotlib figure and axes, based on the number of samples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)  # If only one sample, make sure axes are iterable\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(np.squeeze(sample_images[i]), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Display true mask for the image\n",
    "        axes[i, 1].imshow(np.squeeze(sample_masks[i]), cmap='gray')\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Display predicted mask for the image\n",
    "        axes[i, 2].imshow(np.squeeze(binary_predicted_masks[i]), cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_predictions(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Call the function after loading your images and masks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m verify_masks(images, masks, num_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mask_alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def verify_masks(images, masks, num_samples=3, mask_alpha=0.3):\n",
    "    \"\"\"\n",
    "    This function overlays the mask onto the image to verify position and size.\n",
    "    Parameters:\n",
    "    - images: numpy array of images.\n",
    "    - masks: numpy array of masks.\n",
    "    - num_samples: number of samples to display for verification.\n",
    "    - mask_alpha: transparency level of the mask overlay.\n",
    "    \"\"\"\n",
    "    # Set the number of images to display\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    # Create figure to display images and masks\n",
    "    plt.figure(figsize=(20, num_samples * 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.imshow(masks[i].squeeze(), cmap='jet', alpha=mask_alpha)  # 'jet' colormap for the mask\n",
    "        plt.title(f'Image {i} with Mask Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after loading your images and masks\n",
    "verify_masks(images, masks, num_samples=2, mask_alpha=0.3)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
