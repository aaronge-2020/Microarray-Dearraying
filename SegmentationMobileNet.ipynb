{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import resize\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_mask_from_json(json_data, shape):\n",
    "    mask = np.zeros(shape, dtype=np.float32)\n",
    "    for item in json_data:\n",
    "        rr, cc = disk((item['y'], item['x']), item['radius'], shape=shape)\n",
    "        mask[rr, cc] = 1.0\n",
    "    return mask\n",
    "\n",
    "def resize_labels(labels, original_size, new_size):\n",
    "    scale_x = new_size[1] / original_size[1]\n",
    "    scale_y = new_size[0] / original_size[0]\n",
    "    resized_labels = []\n",
    "    for label in labels:\n",
    "        resized_label = {\n",
    "            'x': label['x'] * scale_x,\n",
    "            'y': label['y'] * scale_y,\n",
    "            'radius': label['radius'] * scale_x  # Assuming uniform scaling in x and y\n",
    "        }\n",
    "        resized_labels.append(resized_label)\n",
    "    return resized_labels\n",
    "\n",
    "def load_images_and_labels(image_paths, label_dir, new_size):\n",
    "    original_size = (1024, 1024)  # Original size of the images and labels\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Extract filename without extension to match with the label\n",
    "        base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        label_file = os.path.join(label_dir, base_filename + '.json')\n",
    "\n",
    "        # Load and resize image\n",
    "        image = img_to_array(load_img(image_path, color_mode='rgb', target_size=new_size))\n",
    "        images.append(image / 255.0)  # Normalizing to [0, 1]\n",
    "\n",
    "        # Load and resize corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        resized_json_data = resize_labels(json_data, original_size, new_size)\n",
    "        mask = create_mask_from_json(resized_json_data, shape=new_size)\n",
    "        masks.append(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks).reshape(-1, *new_size, 1)\n",
    "\n",
    "\n",
    "\n",
    "def create_loocv_folds(image_files, augmented_image_dir):\n",
    "    folds = []\n",
    "    n = len(image_files)\n",
    "\n",
    "    for i in range(n):\n",
    "        test_image = image_files[i]\n",
    "        \n",
    "        # Ensure validation images are different from the test image and rotate them\n",
    "        val_indices = [(i + 1) % n, (i + 2) % n]\n",
    "        validation_images = [image_files[j] for j in val_indices]\n",
    "\n",
    "        # Remaining images for training, excluding the test and validation images\n",
    "        train_images = [img for idx, img in enumerate(image_files) if idx not in [i, val_indices[0], val_indices[1]]]\n",
    "\n",
    "        # Augmented images for training\n",
    "        augmented_train_images = [os.path.join(augmented_image_dir, os.path.basename(img).replace('.png', f'_aug_{k}.png')) \n",
    "                                  for img in train_images for k in range(20)]\n",
    "\n",
    "        folds.append((augmented_train_images, [test_image], validation_images))\n",
    "\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)              (None, 256, 256, 32)         864       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalizati  (None, 256, 256, 32)         128       ['Conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)           (None, 256, 256, 32)         0         ['bn_Conv1[0][0]']            \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (D  (None, 256, 256, 32)         288       ['Conv1_relu[0][0]']          \n",
      " epthwiseConv2D)                                                                                  \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN  (None, 256, 256, 32)         128       ['expanded_conv_depthwise[0][0\n",
      "  (BatchNormalization)                                              ]']                           \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_re  (None, 256, 256, 32)         0         ['expanded_conv_depthwise_BN[0\n",
      " lu (ReLU)                                                          ][0]']                        \n",
      "                                                                                                  \n",
      " expanded_conv_project (Con  (None, 256, 256, 16)         512       ['expanded_conv_depthwise_relu\n",
      " v2D)                                                               [0][0]']                      \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (  (None, 256, 256, 16)         64        ['expanded_conv_project[0][0]'\n",
      " BatchNormalization)                                                ]                             \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)     (None, 256, 256, 96)         1536      ['expanded_conv_project_BN[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNo  (None, 256, 256, 96)         384       ['block_1_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)  (None, 256, 256, 96)         0         ['block_1_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D  (None, 257, 257, 96)         0         ['block_1_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_1_depthwise (Depthwi  (None, 128, 128, 96)         864       ['block_1_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (Batc  (None, 128, 128, 96)         384       ['block_1_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (Re  (None, 128, 128, 96)         0         ['block_1_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)    (None, 128, 128, 24)         2304      ['block_1_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_1_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_1_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_2_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_2_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_depthwise (Depthwi  (None, 128, 128, 144)        1296      ['block_2_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (Batc  (None, 128, 128, 144)        576       ['block_2_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (Re  (None, 128, 128, 144)        0         ['block_2_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)    (None, 128, 128, 24)         3456      ['block_2_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchN  (None, 128, 128, 24)         96        ['block_2_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_2_add (Add)           (None, 128, 128, 24)         0         ['block_1_project_BN[0][0]',  \n",
      "                                                                     'block_2_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)     (None, 128, 128, 144)        3456      ['block_2_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNo  (None, 128, 128, 144)        576       ['block_3_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)  (None, 128, 128, 144)        0         ['block_3_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D  (None, 129, 129, 144)        0         ['block_3_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_3_depthwise (Depthwi  (None, 64, 64, 144)          1296      ['block_3_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (Batc  (None, 64, 64, 144)          576       ['block_3_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (Re  (None, 64, 64, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)    (None, 64, 64, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_3_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_3_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_4_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_4_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_4_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_4_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_4_add (Add)           (None, 64, 64, 32)           0         ['block_3_project_BN[0][0]',  \n",
      "                                                                     'block_4_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_4_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_5_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_5_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_depthwise (Depthwi  (None, 64, 64, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (Batc  (None, 64, 64, 192)          768       ['block_5_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (Re  (None, 64, 64, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)    (None, 64, 64, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchN  (None, 64, 64, 32)           128       ['block_5_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_5_add (Add)           (None, 64, 64, 32)           0         ['block_4_add[0][0]',         \n",
      "                                                                     'block_5_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)     (None, 64, 64, 192)          6144      ['block_5_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNo  (None, 64, 64, 192)          768       ['block_6_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)  (None, 64, 64, 192)          0         ['block_6_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D  (None, 65, 65, 192)          0         ['block_6_expand_relu[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_6_depthwise (Depthwi  (None, 32, 32, 192)          1728      ['block_6_pad[0][0]']         \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (Batc  (None, 32, 32, 192)          768       ['block_6_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (Re  (None, 32, 32, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)    (None, 32, 32, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_6_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_6_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_7_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_7_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_7_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_7_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_7_add (Add)           (None, 32, 32, 64)           0         ['block_6_project_BN[0][0]',  \n",
      "                                                                     'block_7_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_7_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_8_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_8_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_8_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_8_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_8_add (Add)           (None, 32, 32, 64)           0         ['block_7_add[0][0]',         \n",
      "                                                                     'block_8_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)     (None, 32, 32, 384)          24576     ['block_8_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNo  (None, 32, 32, 384)          1536      ['block_9_expand[0][0]']      \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)  (None, 32, 32, 384)          0         ['block_9_expand_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_depthwise (Depthwi  (None, 32, 32, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
      " seConv2D)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (Batc  (None, 32, 32, 384)          1536      ['block_9_depthwise[0][0]']   \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (Re  (None, 32, 32, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
      " LU)                                                                                              \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)    (None, 32, 32, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchN  (None, 32, 32, 64)           256       ['block_9_project[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_9_add (Add)           (None, 32, 32, 64)           0         ['block_8_add[0][0]',         \n",
      "                                                                     'block_9_project_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)    (None, 32, 32, 384)          24576     ['block_9_add[0][0]']         \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchN  (None, 32, 32, 384)          1536      ['block_10_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU  (None, 32, 32, 384)          0         ['block_10_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_10_depthwise (Depthw  (None, 32, 32, 384)          3456      ['block_10_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (Bat  (None, 32, 32, 384)          1536      ['block_10_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (R  (None, 32, 32, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)   (None, 32, 32, 96)           36864     ['block_10_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_10_project_BN (Batch  (None, 32, 32, 96)           384       ['block_10_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_10_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_11_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_11_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_11_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_11_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_11_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_11_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_11_project_BN (Batch  (None, 32, 32, 96)           384       ['block_11_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_11_add (Add)          (None, 32, 32, 96)           0         ['block_10_project_BN[0][0]', \n",
      "                                                                     'block_11_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_11_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_12_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_12_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_12_depthwise (Depthw  (None, 32, 32, 576)          5184      ['block_12_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (Bat  (None, 32, 32, 576)          2304      ['block_12_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (R  (None, 32, 32, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)   (None, 32, 32, 96)           55296     ['block_12_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_12_project_BN (Batch  (None, 32, 32, 96)           384       ['block_12_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_12_add (Add)          (None, 32, 32, 96)           0         ['block_11_add[0][0]',        \n",
      "                                                                     'block_12_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)    (None, 32, 32, 576)          55296     ['block_12_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchN  (None, 32, 32, 576)          2304      ['block_13_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU  (None, 32, 32, 576)          0         ['block_13_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2  (None, 33, 33, 576)          0         ['block_13_expand_relu[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block_13_depthwise (Depthw  (None, 16, 16, 576)          5184      ['block_13_pad[0][0]']        \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (Bat  (None, 16, 16, 576)          2304      ['block_13_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (R  (None, 16, 16, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)   (None, 16, 16, 160)          92160     ['block_13_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_13_project_BN (Batch  (None, 16, 16, 160)          640       ['block_13_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_13_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_14_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_14_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_14_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_14_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_14_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_14_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_14_project_BN (Batch  (None, 16, 16, 160)          640       ['block_14_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_14_add (Add)          (None, 16, 16, 160)          0         ['block_13_project_BN[0][0]', \n",
      "                                                                     'block_14_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_14_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_15_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_15_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_15_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_15_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_15_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)   (None, 16, 16, 160)          153600    ['block_15_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_15_project_BN (Batch  (None, 16, 16, 160)          640       ['block_15_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " block_15_add (Add)          (None, 16, 16, 160)          0         ['block_14_add[0][0]',        \n",
      "                                                                     'block_15_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)    (None, 16, 16, 960)          153600    ['block_15_add[0][0]']        \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchN  (None, 16, 16, 960)          3840      ['block_16_expand[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU  (None, 16, 16, 960)          0         ['block_16_expand_BN[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " block_16_depthwise (Depthw  (None, 16, 16, 960)          8640      ['block_16_expand_relu[0][0]']\n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (Bat  (None, 16, 16, 960)          3840      ['block_16_depthwise[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (R  (None, 16, 16, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
      " eLU)                                                               ]                             \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)   (None, 16, 16, 320)          307200    ['block_16_depthwise_relu[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " block_16_project_BN (Batch  (None, 16, 16, 320)          1280      ['block_16_project[0][0]']    \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)             (None, 16, 16, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalizat  (None, 16, 16, 1280)         5120      ['Conv_1[0][0]']              \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " out_relu (ReLU)             (None, 16, 16, 1280)         0         ['Conv_1_bn[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 16, 16, 256)          327936    ['out_relu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 16, 16, 256)          1024      ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 256)          65792     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 256)          590080    ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 256)          590080    ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 256)          590080    ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 1024)         0         ['conv2d_1[0][0]',            \n",
      "                                                                     'conv2d_2[0][0]',            \n",
      "                                                                     'conv2d_3[0][0]',            \n",
      "                                                                     'conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 256)          262400    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 16, 16, 256)          1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 256)          65792     ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 32, 32, 256)          0         ['conv2d_6[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 64, 64, 256)          0         ['up_sampling2d[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 128, 128, 256)        0         ['up_sampling2d_1[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 256, 256, 256)        0         ['up_sampling2d_2[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSamplin  (None, 512, 512, 256)        0         ['up_sampling2d_3[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 512, 512, 1)          257       ['up_sampling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4752449 (18.13 MB)\n",
      "Trainable params: 2493441 (9.51 MB)\n",
      "Non-trainable params: 2259008 (8.62 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "def create_deeplabv3_plus_binary_model(input_shape=(512, 512, 3), l2_lambda=0.01, fine_tune_at=200):\n",
    "    # Load MobileNetV2 pre-trained on ImageNet as the backbone\n",
    "    backbone = tf.keras.applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Unfreeze the top layers of the model for fine-tuning\n",
    "    backbone.trainable = True\n",
    "    for layer in backbone.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Use features from the backbone network - feature extraction\n",
    "    x = backbone.output\n",
    "\n",
    "    # Apply atrous convolutions / spatial pyramid pooling\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same', kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Atrous Spatial Pyramid Pooling (ASPP)\n",
    "    b0 = layers.Conv2D(256, (1, 1), activation='relu', padding='same', dilation_rate=1, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b1 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=6, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=12, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "    b3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same', dilation_rate=18, kernel_regularizer=regularizers.l2(l2_lambda))(x)\n",
    "\n",
    "    # Concatenate the atrous and image-level features\n",
    "    x = layers.Concatenate()([b0, b1, b2, b3])\n",
    "\n",
    "    # Add a convolutional layer on top of the concatenated features\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Decoder\n",
    "    # Start with a simple 1x1 convolution\n",
    "    x = layers.Conv2D(256, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Perform upsampling in steps to reach the output size of 512x512.\n",
    "    # Each UpSampling2D layer doubles the size of the feature map\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 32x32\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 64x64\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 128x128\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 256x256\n",
    "    x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)  # size becomes 512x512\n",
    "\n",
    "    # Output layer for binary segmentation\n",
    "    output = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = models.Model(inputs=backbone.input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_deeplabv3_plus_binary_model()\n",
    "\n",
    "# Compile the model (if you're about to train it)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary to verify the architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(512, 512, 3), num_filters=16, depth=2, dropout=0.5, batch_norm=True):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "    # FINAL CONVOLUTION\n",
    "    output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 512, 512, 16)         448       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 512, 512, 16)         64        ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 512, 512, 16)         0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 512, 512, 16)         2320      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 512, 512, 16)         64        ['conv2d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 512, 512, 16)         0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 256, 256, 16)         0         ['activation_1[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256, 256, 16)         0         ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 32)         4640      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 256, 256, 32)         128       ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 256, 256, 32)         9248      ['activation_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 256, 256, 32)         128       ['conv2d_11[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 128, 128, 32)         0         ['activation_3[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128, 128, 32)         0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 128, 128, 64)         18496     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 128, 128, 64)         256       ['conv2d_12[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_4 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 128, 128, 64)         36928     ['activation_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 128, 128, 64)         256       ['conv2d_13[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_5 (Activation)   (None, 128, 128, 64)         0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSamplin  (None, 256, 256, 64)         0         ['activation_5[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 256, 256, 96)         0         ['up_sampling2d_5[0][0]',     \n",
      " )                                                                   'activation_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 256, 256, 32)         27680     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 256, 256, 32)         128       ['conv2d_14[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_6 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 256, 256, 32)         9248      ['activation_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 256, 256, 32)         128       ['conv2d_15[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)   (None, 256, 256, 32)         0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSamplin  (None, 512, 512, 32)         0         ['activation_7[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 512, 512, 48)         0         ['up_sampling2d_6[0][0]',     \n",
      " )                                                                   'activation_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 512, 512, 16)         6928      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 512, 512, 16)         64        ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)   (None, 512, 512, 16)         0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 512, 512, 16)         2320      ['activation_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 512, 512, 16)         64        ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)   (None, 512, 512, 16)         0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 512, 512, 1)          17        ['activation_9[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 119553 (467.00 KB)\n",
      "Trainable params: 118913 (464.50 KB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = unet()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Define a Learning Rate Schedule\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 0:\n",
    "        return lr\n",
    "    elif epoch < 30 and epoch%2 == 0:\n",
    "        return lr * tf.math.exp(-0.5)\n",
    "    elif epoch > 30:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "log_dir = \"./tensorboard_logs\"\n",
    "\n",
    "def weighted_binary_crossentropy(zero_weight, one_weight):\n",
    "    def loss(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def train_unet(model, train_images, train_masks, val_images, val_masks, epochs=300, batch_size=32, checkpoint_path='pixel_cores.hdf5'):\n",
    "    # Define the custom loss function\n",
    "    custom_loss = weighted_binary_crossentropy(zero_weight=1, one_weight=1)\n",
    "\n",
    "    # Check if a previous checkpoint exists\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading weights from checkpoint: {checkpoint_path}\")\n",
    "        # Load the model with the custom loss function\n",
    "        model = load_model(checkpoint_path, custom_objects={'loss': custom_loss})\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss=custom_loss, metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "    model_checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    \n",
    "    # Define the TensorBoard callback\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Define the EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, verbose=1, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model with the given training and validation data\n",
    "    history = model.fit(\n",
    "        x=train_images, \n",
    "        y=train_masks, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(val_images, val_masks), \n",
    "        callbacks=[model_checkpoint, tensorboard_callback, lr_scheduler, early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv  # Import the csv module\n",
    "\n",
    "original_image_dir = './TMA_WSI_Padded_PNGs'\n",
    "augmented_image_dir = './augmented_images'\n",
    "original_label_dir = './TMA_WSI_Labels_updated'\n",
    "augmented_label_dir = './augmented_labels'\n",
    "\n",
    "# Use list comprehension to create the list of file paths\n",
    "original_image_files = [os.path.join(original_image_dir, file) for file in sorted(\n",
    "    os.listdir(original_image_dir)) if file.endswith('.png')]\n",
    "\n",
    "folds = create_loocv_folds(original_image_files, augmented_image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1334 - auc: 0.9899 - accuracy: 0.9487 - precision: 0.9153 - recall: 0.9282\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1503 - auc: 0.9857 - accuracy: 0.9400 - precision: 0.9299 - recall: 0.8824\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.1538 - auc: 0.9854 - accuracy: 0.9426 - precision: 0.8813 - recall: 0.9294\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.2064 - auc: 0.9867 - accuracy: 0.9191 - precision: 0.7952 - recall: 0.9891\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x2aa306fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.2330 - auc: 0.9349 - accuracy: 0.9194 - precision: 0.8770 - recall: 0.7710\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x2dc4151c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.4422 - auc: 0.6544 - accuracy: 0.8360 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.2001 - auc: 0.9928 - accuracy: 0.9353 - precision: 0.7342 - recall: 0.9853\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1296 - auc: 0.9816 - accuracy: 0.9556 - precision: 0.8792 - recall: 0.9208\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.4797 - auc: 0.8377 - accuracy: 0.8130 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.1365 - auc: 0.9886 - accuracy: 0.9579 - precision: 0.8526 - recall: 0.9307\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at pixel_core_fold_11.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, fold \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(folds):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Load the checkpointed model for the fold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     model_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpixel_core_fold_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(model_path, custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m: weighted_binary_crossentropy(zero_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, one_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Unpack the fold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     train_image, test_image, val_images \u001b[39m=\u001b[39m fold\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at pixel_core_fold_11.hdf5"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'model_evaluation_results.csv'\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Loss', 'Fold', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    # Iterate over each fold\n",
    "    for i, fold in enumerate(folds):\n",
    "        # Load the checkpointed model for the fold\n",
    "        model_path = f\"pixel_core_fold_{i+1}.hdf5\"\n",
    "        loaded_model = tf.keras.models.load_model(model_path, custom_objects={'loss': weighted_binary_crossentropy(zero_weight=1, one_weight=1)})\n",
    "\n",
    "        # Unpack the fold\n",
    "        train_image, test_image, val_images = fold\n",
    "\n",
    "        # Load the test images and masks\n",
    "        test_images, test_masks = load_images_and_labels(test_image, original_label_dir, (512,512))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = loaded_model.evaluate(test_images, test_masks)\n",
    "\n",
    "        # Write the evaluation metrics to the CSV file\n",
    "        writer.writerow([i+1, loss, auc, accuracy, precision, recall])\n",
    "    \n",
    "\n",
    "        # Flush the changes to the CSV file\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6318 - auc: 0.9115 - accuracy: 0.7152 - precision: 0.4048 - recall: 0.9436 \n",
      "Epoch 1: val_loss improved from inf to 2.06863, saving model to pixel_core_fold_11.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 121s 12s/step - loss: 0.6318 - auc: 0.9115 - accuracy: 0.7152 - precision: 0.4048 - recall: 0.9436 - val_loss: 2.0686 - val_auc: 0.4892 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4052 - auc: 0.9738 - accuracy: 0.9305 - precision: 0.7707 - recall: 0.9221 \n",
      "Epoch 2: val_loss did not improve from 2.06863\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.4052 - auc: 0.9738 - accuracy: 0.9305 - precision: 0.7707 - recall: 0.9221 - val_loss: 3.1166 - val_auc: 0.4952 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3607 - auc: 0.9775 - accuracy: 0.9494 - precision: 0.8489 - recall: 0.9046 \n",
      "Epoch 3: val_loss did not improve from 2.06863\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.3607 - auc: 0.9775 - accuracy: 0.9494 - precision: 0.8489 - recall: 0.9046 - val_loss: 2.2009 - val_auc: 0.4917 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3267 - auc: 0.9771 - accuracy: 0.9505 - precision: 0.8551 - recall: 0.9021 \n",
      "Epoch 4: val_loss improved from 2.06863 to 0.76326, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.3267 - auc: 0.9771 - accuracy: 0.9505 - precision: 0.8551 - recall: 0.9021 - val_loss: 0.7633 - val_auc: 0.6871 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2879 - auc: 0.9716 - accuracy: 0.9518 - precision: 0.8729 - recall: 0.8846 \n",
      "Epoch 5: val_loss improved from 0.76326 to 0.57223, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 114s 11s/step - loss: 0.2879 - auc: 0.9716 - accuracy: 0.9518 - precision: 0.8729 - recall: 0.8846 - val_loss: 0.5722 - val_auc: 0.6440 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2572 - auc: 0.9746 - accuracy: 0.9533 - precision: 0.8858 - recall: 0.8759 \n",
      "Epoch 6: val_loss improved from 0.57223 to 0.56517, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.2572 - auc: 0.9746 - accuracy: 0.9533 - precision: 0.8858 - recall: 0.8759 - val_loss: 0.5652 - val_auc: 0.4025 - val_accuracy: 0.7634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2387 - auc: 0.9784 - accuracy: 0.9538 - precision: 0.8856 - recall: 0.8795 \n",
      "Epoch 7: val_loss improved from 0.56517 to 0.55781, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.2387 - auc: 0.9784 - accuracy: 0.9538 - precision: 0.8856 - recall: 0.8795 - val_loss: 0.5578 - val_auc: 0.2708 - val_accuracy: 0.7635 - val_precision: 1.0000 - val_recall: 1.4513e-04 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2242 - auc: 0.9795 - accuracy: 0.9545 - precision: 0.8885 - recall: 0.8798 \n",
      "Epoch 8: val_loss improved from 0.55781 to 0.55351, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2242 - auc: 0.9795 - accuracy: 0.9545 - precision: 0.8885 - recall: 0.8798 - val_loss: 0.5535 - val_auc: 0.7075 - val_accuracy: 0.7636 - val_precision: 1.0000 - val_recall: 5.7244e-04 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2138 - auc: 0.9782 - accuracy: 0.9552 - precision: 0.8975 - recall: 0.8727 \n",
      "Epoch 9: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.2138 - auc: 0.9782 - accuracy: 0.9552 - precision: 0.8975 - recall: 0.8727 - val_loss: 0.5622 - val_auc: 0.6670 - val_accuracy: 0.7636 - val_precision: 0.9286 - val_recall: 8.3850e-04 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2030 - auc: 0.9802 - accuracy: 0.9557 - precision: 0.8860 - recall: 0.8897 \n",
      "Epoch 10: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.2030 - auc: 0.9802 - accuracy: 0.9557 - precision: 0.8860 - recall: 0.8897 - val_loss: 0.5761 - val_auc: 0.7439 - val_accuracy: 0.7637 - val_precision: 0.8820 - val_recall: 0.0011 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1946 - auc: 0.9807 - accuracy: 0.9565 - precision: 0.8922 - recall: 0.8866 \n",
      "Epoch 11: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1946 - auc: 0.9807 - accuracy: 0.9565 - precision: 0.8922 - recall: 0.8866 - val_loss: 0.5901 - val_auc: 0.7310 - val_accuracy: 0.7637 - val_precision: 0.8689 - val_recall: 0.0013 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1868 - auc: 0.9805 - accuracy: 0.9570 - precision: 0.8987 - recall: 0.8813 \n",
      "Epoch 12: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.1868 - auc: 0.9805 - accuracy: 0.9570 - precision: 0.8987 - recall: 0.8813 - val_loss: 0.6025 - val_auc: 0.4470 - val_accuracy: 0.7637 - val_precision: 0.8564 - val_recall: 0.0014 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1803 - auc: 0.9808 - accuracy: 0.9570 - precision: 0.8917 - recall: 0.8903 \n",
      "Epoch 13: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1803 - auc: 0.9808 - accuracy: 0.9570 - precision: 0.8917 - recall: 0.8903 - val_loss: 0.6107 - val_auc: 0.7631 - val_accuracy: 0.7637 - val_precision: 0.8264 - val_recall: 0.0016 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1741 - auc: 0.9816 - accuracy: 0.9576 - precision: 0.8955 - recall: 0.8887 \n",
      "Epoch 14: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1741 - auc: 0.9816 - accuracy: 0.9576 - precision: 0.8955 - recall: 0.8887 - val_loss: 0.6278 - val_auc: 0.7290 - val_accuracy: 0.7637 - val_precision: 0.8106 - val_recall: 0.0017 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1684 - auc: 0.9817 - accuracy: 0.9577 - precision: 0.8974 - recall: 0.8871 \n",
      "Epoch 15: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1684 - auc: 0.9817 - accuracy: 0.9577 - precision: 0.8974 - recall: 0.8871 - val_loss: 0.6382 - val_auc: 0.6418 - val_accuracy: 0.7638 - val_precision: 0.8440 - val_recall: 0.0017 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1638 - auc: 0.9826 - accuracy: 0.9576 - precision: 0.8930 - recall: 0.8920 \n",
      "Epoch 16: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1638 - auc: 0.9826 - accuracy: 0.9576 - precision: 0.8930 - recall: 0.8920 - val_loss: 0.6591 - val_auc: 0.5982 - val_accuracy: 0.7638 - val_precision: 0.8302 - val_recall: 0.0018 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1589 - auc: 0.9828 - accuracy: 0.9583 - precision: 0.8995 - recall: 0.8880 \n",
      "Epoch 17: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1589 - auc: 0.9828 - accuracy: 0.9583 - precision: 0.8995 - recall: 0.8880 - val_loss: 0.6730 - val_auc: 0.5262 - val_accuracy: 0.7638 - val_precision: 0.8212 - val_recall: 0.0018 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1540 - auc: 0.9839 - accuracy: 0.9588 - precision: 0.8945 - recall: 0.8967 \n",
      "Epoch 18: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1540 - auc: 0.9839 - accuracy: 0.9588 - precision: 0.8945 - recall: 0.8967 - val_loss: 0.6696 - val_auc: 0.5775 - val_accuracy: 0.7643 - val_precision: 0.8833 - val_recall: 0.0043 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1500 - auc: 0.9843 - accuracy: 0.9592 - precision: 0.8985 - recall: 0.8941 \n",
      "Epoch 19: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1500 - auc: 0.9843 - accuracy: 0.9592 - precision: 0.8985 - recall: 0.8941 - val_loss: 0.6671 - val_auc: 0.6947 - val_accuracy: 0.7656 - val_precision: 0.9296 - val_recall: 0.0100 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1485 - auc: 0.9843 - accuracy: 0.9585 - precision: 0.8921 - recall: 0.8982 \n",
      "Epoch 20: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1485 - auc: 0.9843 - accuracy: 0.9585 - precision: 0.8921 - recall: 0.8982 - val_loss: 0.6585 - val_auc: 0.6511 - val_accuracy: 0.7682 - val_precision: 0.9595 - val_recall: 0.0212 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1452 - auc: 0.9836 - accuracy: 0.9594 - precision: 0.9017 - recall: 0.8912 \n",
      "Epoch 21: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1452 - auc: 0.9836 - accuracy: 0.9594 - precision: 0.9017 - recall: 0.8912 - val_loss: 0.6607 - val_auc: 0.6303 - val_accuracy: 0.7703 - val_precision: 0.9697 - val_recall: 0.0299 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1426 - auc: 0.9846 - accuracy: 0.9591 - precision: 0.8918 - recall: 0.9022 \n",
      "Epoch 22: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1426 - auc: 0.9846 - accuracy: 0.9591 - precision: 0.8918 - recall: 0.9022 - val_loss: 0.6302 - val_auc: 0.7716 - val_accuracy: 0.7788 - val_precision: 0.9774 - val_recall: 0.0665 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1401 - auc: 0.9849 - accuracy: 0.9598 - precision: 0.9041 - recall: 0.8909 \n",
      "Epoch 23: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1401 - auc: 0.9849 - accuracy: 0.9598 - precision: 0.9041 - recall: 0.8909 - val_loss: 0.6086 - val_auc: 0.7272 - val_accuracy: 0.7849 - val_precision: 0.9807 - val_recall: 0.0924 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1386 - auc: 0.9850 - accuracy: 0.9594 - precision: 0.8968 - recall: 0.8974 \n",
      "Epoch 24: val_loss did not improve from 0.55351\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1386 - auc: 0.9850 - accuracy: 0.9594 - precision: 0.8968 - recall: 0.8974 - val_loss: 0.5815 - val_auc: 0.7755 - val_accuracy: 0.7949 - val_precision: 0.9819 - val_recall: 0.1357 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1375 - auc: 0.9850 - accuracy: 0.9593 - precision: 0.8985 - recall: 0.8951 \n",
      "Epoch 25: val_loss improved from 0.55351 to 0.53146, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1375 - auc: 0.9850 - accuracy: 0.9593 - precision: 0.8985 - recall: 0.8951 - val_loss: 0.5315 - val_auc: 0.7884 - val_accuracy: 0.8102 - val_precision: 0.9804 - val_recall: 0.2018 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1352 - auc: 0.9855 - accuracy: 0.9596 - precision: 0.8963 - recall: 0.8994 \n",
      "Epoch 26: val_loss improved from 0.53146 to 0.49090, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1352 - auc: 0.9855 - accuracy: 0.9596 - precision: 0.8963 - recall: 0.8994 - val_loss: 0.4909 - val_auc: 0.8043 - val_accuracy: 0.8227 - val_precision: 0.9821 - val_recall: 0.2550 - lr: 6.0653e-04\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1330 - auc: 0.9857 - accuracy: 0.9601 - precision: 0.8996 - recall: 0.8982 \n",
      "Epoch 27: val_loss improved from 0.49090 to 0.41461, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1330 - auc: 0.9857 - accuracy: 0.9601 - precision: 0.8996 - recall: 0.8982 - val_loss: 0.4146 - val_auc: 0.8616 - val_accuracy: 0.8490 - val_precision: 0.9773 - val_recall: 0.3704 - lr: 5.4881e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1315 - auc: 0.9860 - accuracy: 0.9603 - precision: 0.8994 - recall: 0.8995 \n",
      "Epoch 28: val_loss improved from 0.41461 to 0.34341, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1315 - auc: 0.9860 - accuracy: 0.9603 - precision: 0.8994 - recall: 0.8995 - val_loss: 0.3434 - val_auc: 0.9212 - val_accuracy: 0.8719 - val_precision: 0.9718 - val_recall: 0.4720 - lr: 5.4881e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1301 - auc: 0.9862 - accuracy: 0.9604 - precision: 0.9009 - recall: 0.8980 \n",
      "Epoch 29: val_loss improved from 0.34341 to 0.30359, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1301 - auc: 0.9862 - accuracy: 0.9604 - precision: 0.9009 - recall: 0.8980 - val_loss: 0.3036 - val_auc: 0.9408 - val_accuracy: 0.8853 - val_precision: 0.9699 - val_recall: 0.5316 - lr: 4.9659e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1292 - auc: 0.9862 - accuracy: 0.9602 - precision: 0.8959 - recall: 0.9031 \n",
      "Epoch 30: val_loss improved from 0.30359 to 0.26886, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1292 - auc: 0.9862 - accuracy: 0.9602 - precision: 0.8959 - recall: 0.9031 - val_loss: 0.2689 - val_auc: 0.9524 - val_accuracy: 0.8984 - val_precision: 0.9702 - val_recall: 0.5885 - lr: 4.9659e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1274 - auc: 0.9864 - accuracy: 0.9608 - precision: 0.9010 - recall: 0.9001 \n",
      "Epoch 31: val_loss improved from 0.26886 to 0.26818, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1274 - auc: 0.9864 - accuracy: 0.9608 - precision: 0.9010 - recall: 0.9001 - val_loss: 0.2682 - val_auc: 0.9522 - val_accuracy: 0.8987 - val_precision: 0.9711 - val_recall: 0.5894 - lr: 4.4933e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1272 - auc: 0.9859 - accuracy: 0.9608 - precision: 0.9043 - recall: 0.8959 \n",
      "Epoch 32: val_loss improved from 0.26818 to 0.22704, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1272 - auc: 0.9859 - accuracy: 0.9608 - precision: 0.9043 - recall: 0.8959 - val_loss: 0.2270 - val_auc: 0.9641 - val_accuracy: 0.9159 - val_precision: 0.9675 - val_recall: 0.6669 - lr: 4.4933e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1254 - auc: 0.9868 - accuracy: 0.9609 - precision: 0.8968 - recall: 0.9060 \n",
      "Epoch 33: val_loss improved from 0.22704 to 0.21254, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1254 - auc: 0.9868 - accuracy: 0.9609 - precision: 0.8968 - recall: 0.9060 - val_loss: 0.2125 - val_auc: 0.9694 - val_accuracy: 0.9227 - val_precision: 0.9657 - val_recall: 0.6982 - lr: 4.0657e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1252 - auc: 0.9867 - accuracy: 0.9606 - precision: 0.8977 - recall: 0.9031 \n",
      "Epoch 34: val_loss improved from 0.21254 to 0.19541, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1252 - auc: 0.9867 - accuracy: 0.9606 - precision: 0.8977 - recall: 0.9031 - val_loss: 0.1954 - val_auc: 0.9741 - val_accuracy: 0.9301 - val_precision: 0.9586 - val_recall: 0.7362 - lr: 4.0657e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1245 - auc: 0.9863 - accuracy: 0.9611 - precision: 0.9096 - recall: 0.8914 \n",
      "Epoch 35: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1245 - auc: 0.9863 - accuracy: 0.9611 - precision: 0.9096 - recall: 0.8914 - val_loss: 0.2027 - val_auc: 0.9707 - val_accuracy: 0.9266 - val_precision: 0.9610 - val_recall: 0.7187 - lr: 3.6788e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1231 - auc: 0.9874 - accuracy: 0.9608 - precision: 0.8944 - recall: 0.9084 \n",
      "Epoch 36: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1231 - auc: 0.9874 - accuracy: 0.9608 - precision: 0.8944 - recall: 0.9084 - val_loss: 0.2062 - val_auc: 0.9688 - val_accuracy: 0.9260 - val_precision: 0.9642 - val_recall: 0.7136 - lr: 3.6788e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1237 - auc: 0.9862 - accuracy: 0.9608 - precision: 0.9054 - recall: 0.8948 \n",
      "Epoch 37: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1237 - auc: 0.9862 - accuracy: 0.9608 - precision: 0.9054 - recall: 0.8948 - val_loss: 0.2011 - val_auc: 0.9715 - val_accuracy: 0.9276 - val_precision: 0.9627 - val_recall: 0.7218 - lr: 3.3287e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1227 - auc: 0.9874 - accuracy: 0.9606 - precision: 0.8943 - recall: 0.9074 \n",
      "Epoch 38: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1227 - auc: 0.9874 - accuracy: 0.9606 - precision: 0.8943 - recall: 0.9074 - val_loss: 0.2151 - val_auc: 0.9653 - val_accuracy: 0.9225 - val_precision: 0.9678 - val_recall: 0.6955 - lr: 3.3287e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1222 - auc: 0.9863 - accuracy: 0.9611 - precision: 0.9094 - recall: 0.8919 \n",
      "Epoch 39: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1222 - auc: 0.9863 - accuracy: 0.9611 - precision: 0.9094 - recall: 0.8919 - val_loss: 0.2042 - val_auc: 0.9712 - val_accuracy: 0.9257 - val_precision: 0.9644 - val_recall: 0.7120 - lr: 3.0119e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1207 - auc: 0.9879 - accuracy: 0.9611 - precision: 0.8969 - recall: 0.9072 \n",
      "Epoch 40: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1207 - auc: 0.9879 - accuracy: 0.9611 - precision: 0.8969 - recall: 0.9072 - val_loss: 0.2072 - val_auc: 0.9715 - val_accuracy: 0.9261 - val_precision: 0.9658 - val_recall: 0.7128 - lr: 3.0119e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1204 - auc: 0.9869 - accuracy: 0.9611 - precision: 0.8997 - recall: 0.9036 \n",
      "Epoch 41: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1204 - auc: 0.9869 - accuracy: 0.9611 - precision: 0.8997 - recall: 0.9036 - val_loss: 0.1963 - val_auc: 0.9758 - val_accuracy: 0.9298 - val_precision: 0.9619 - val_recall: 0.7321 - lr: 2.7253e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1194 - auc: 0.9878 - accuracy: 0.9615 - precision: 0.9031 - recall: 0.9014 \n",
      "Epoch 42: val_loss did not improve from 0.19541\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1194 - auc: 0.9878 - accuracy: 0.9615 - precision: 0.9031 - recall: 0.9014 - val_loss: 0.1991 - val_auc: 0.9751 - val_accuracy: 0.9287 - val_precision: 0.9636 - val_recall: 0.7263 - lr: 2.7253e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1192 - auc: 0.9874 - accuracy: 0.9615 - precision: 0.9051 - recall: 0.8989 \n",
      "Epoch 43: val_loss improved from 0.19541 to 0.19449, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1192 - auc: 0.9874 - accuracy: 0.9615 - precision: 0.9051 - recall: 0.8989 - val_loss: 0.1945 - val_auc: 0.9763 - val_accuracy: 0.9304 - val_precision: 0.9614 - val_recall: 0.7355 - lr: 2.4660e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1192 - auc: 0.9875 - accuracy: 0.9611 - precision: 0.8993 - recall: 0.9043 \n",
      "Epoch 44: val_loss did not improve from 0.19449\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1192 - auc: 0.9875 - accuracy: 0.9611 - precision: 0.8993 - recall: 0.9043 - val_loss: 0.2020 - val_auc: 0.9750 - val_accuracy: 0.9277 - val_precision: 0.9651 - val_recall: 0.7205 - lr: 2.4660e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1182 - auc: 0.9876 - accuracy: 0.9617 - precision: 0.9038 - recall: 0.9016 \n",
      "Epoch 45: val_loss did not improve from 0.19449\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1182 - auc: 0.9876 - accuracy: 0.9617 - precision: 0.9038 - recall: 0.9016 - val_loss: 0.2032 - val_auc: 0.9741 - val_accuracy: 0.9272 - val_precision: 0.9656 - val_recall: 0.7180 - lr: 2.2313e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1180 - auc: 0.9877 - accuracy: 0.9614 - precision: 0.9010 - recall: 0.9037 \n",
      "Epoch 46: val_loss did not improve from 0.19449\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1180 - auc: 0.9877 - accuracy: 0.9614 - precision: 0.9010 - recall: 0.9037 - val_loss: 0.1985 - val_auc: 0.9747 - val_accuracy: 0.9290 - val_precision: 0.9634 - val_recall: 0.7274 - lr: 2.2313e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1178 - auc: 0.9875 - accuracy: 0.9613 - precision: 0.9000 - recall: 0.9044 \n",
      "Epoch 47: val_loss did not improve from 0.19449\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1178 - auc: 0.9875 - accuracy: 0.9613 - precision: 0.9000 - recall: 0.9044 - val_loss: 0.1989 - val_auc: 0.9750 - val_accuracy: 0.9294 - val_precision: 0.9628 - val_recall: 0.7296 - lr: 2.0190e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1174 - auc: 0.9879 - accuracy: 0.9615 - precision: 0.9028 - recall: 0.9019 \n",
      "Epoch 48: val_loss improved from 0.19449 to 0.19117, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1174 - auc: 0.9879 - accuracy: 0.9615 - precision: 0.9028 - recall: 0.9019 - val_loss: 0.1912 - val_auc: 0.9783 - val_accuracy: 0.9313 - val_precision: 0.9589 - val_recall: 0.7414 - lr: 2.0190e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1165 - auc: 0.9880 - accuracy: 0.9618 - precision: 0.9056 - recall: 0.9004\n",
      "Epoch 49: val_loss improved from 0.19117 to 0.19032, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1165 - auc: 0.9880 - accuracy: 0.9618 - precision: 0.9056 - recall: 0.9004 - val_loss: 0.1903 - val_auc: 0.9779 - val_accuracy: 0.9320 - val_precision: 0.9572 - val_recall: 0.7460 - lr: 1.8268e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1162 - auc: 0.9883 - accuracy: 0.9617 - precision: 0.9015 - recall: 0.9045 \n",
      "Epoch 50: val_loss improved from 0.19032 to 0.18299, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1162 - auc: 0.9883 - accuracy: 0.9617 - precision: 0.9015 - recall: 0.9045 - val_loss: 0.1830 - val_auc: 0.9813 - val_accuracy: 0.9337 - val_precision: 0.9514 - val_recall: 0.7583 - lr: 1.8268e-04\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9884 - accuracy: 0.9616 - precision: 0.8996 - recall: 0.9065 \n",
      "Epoch 51: val_loss improved from 0.18299 to 0.16820, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1160 - auc: 0.9884 - accuracy: 0.9616 - precision: 0.8996 - recall: 0.9065 - val_loss: 0.1682 - val_auc: 0.9844 - val_accuracy: 0.9393 - val_precision: 0.9369 - val_recall: 0.7970 - lr: 1.6530e-04\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1156 - auc: 0.9880 - accuracy: 0.9620 - precision: 0.9072 - recall: 0.8994 \n",
      "Epoch 52: val_loss improved from 0.16820 to 0.16768, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1156 - auc: 0.9880 - accuracy: 0.9620 - precision: 0.9072 - recall: 0.8994 - val_loss: 0.1677 - val_auc: 0.9845 - val_accuracy: 0.9397 - val_precision: 0.9356 - val_recall: 0.8003 - lr: 1.6530e-04\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1150 - auc: 0.9886 - accuracy: 0.9619 - precision: 0.9022 - recall: 0.9048 \n",
      "Epoch 53: val_loss improved from 0.16768 to 0.16438, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1150 - auc: 0.9886 - accuracy: 0.9619 - precision: 0.9022 - recall: 0.9048 - val_loss: 0.1644 - val_auc: 0.9850 - val_accuracy: 0.9407 - val_precision: 0.9319 - val_recall: 0.8083 - lr: 1.4957e-04\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1152 - auc: 0.9882 - accuracy: 0.9619 - precision: 0.9041 - recall: 0.9025 \n",
      "Epoch 54: val_loss did not improve from 0.16438\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1152 - auc: 0.9882 - accuracy: 0.9619 - precision: 0.9041 - recall: 0.9025 - val_loss: 0.1653 - val_auc: 0.9849 - val_accuracy: 0.9405 - val_precision: 0.9324 - val_recall: 0.8070 - lr: 1.4957e-04\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1146 - auc: 0.9885 - accuracy: 0.9620 - precision: 0.9035 - recall: 0.9037 \n",
      "Epoch 55: val_loss improved from 0.16438 to 0.16267, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1146 - auc: 0.9885 - accuracy: 0.9620 - precision: 0.9035 - recall: 0.9037 - val_loss: 0.1627 - val_auc: 0.9850 - val_accuracy: 0.9417 - val_precision: 0.9272 - val_recall: 0.8180 - lr: 1.3534e-04\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1141 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9017 - recall: 0.9064 \n",
      "Epoch 56: val_loss improved from 0.16267 to 0.16111, saving model to pixel_core_fold_11.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1141 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9017 - recall: 0.9064 - val_loss: 0.1611 - val_auc: 0.9850 - val_accuracy: 0.9428 - val_precision: 0.9202 - val_recall: 0.8301 - lr: 1.3534e-04\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1140 - auc: 0.9887 - accuracy: 0.9619 - precision: 0.9020 - recall: 0.9055 \n",
      "Epoch 57: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1140 - auc: 0.9887 - accuracy: 0.9619 - precision: 0.9020 - recall: 0.9055 - val_loss: 0.1620 - val_auc: 0.9848 - val_accuracy: 0.9423 - val_precision: 0.9219 - val_recall: 0.8261 - lr: 1.2246e-04\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1140 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9045 - recall: 0.9027 \n",
      "Epoch 58: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1140 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9045 - recall: 0.9027 - val_loss: 0.1613 - val_auc: 0.9849 - val_accuracy: 0.9425 - val_precision: 0.9215 - val_recall: 0.8275 - lr: 1.2246e-04\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1136 - auc: 0.9886 - accuracy: 0.9621 - precision: 0.9044 - recall: 0.9034 \n",
      "Epoch 59: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1136 - auc: 0.9886 - accuracy: 0.9621 - precision: 0.9044 - recall: 0.9034 - val_loss: 0.1611 - val_auc: 0.9847 - val_accuracy: 0.9430 - val_precision: 0.9187 - val_recall: 0.8329 - lr: 1.1080e-04\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1142 - auc: 0.9883 - accuracy: 0.9618 - precision: 0.9038 - recall: 0.9026 \n",
      "Epoch 60: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1142 - auc: 0.9883 - accuracy: 0.9618 - precision: 0.9038 - recall: 0.9026 - val_loss: 0.1673 - val_auc: 0.9844 - val_accuracy: 0.9392 - val_precision: 0.9370 - val_recall: 0.7965 - lr: 1.1080e-04\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1133 - auc: 0.9888 - accuracy: 0.9621 - precision: 0.9047 - recall: 0.9028\n",
      "Epoch 61: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1133 - auc: 0.9888 - accuracy: 0.9621 - precision: 0.9047 - recall: 0.9028 - val_loss: 0.1695 - val_auc: 0.9840 - val_accuracy: 0.9383 - val_precision: 0.9400 - val_recall: 0.7895 - lr: 1.0026e-04\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1133 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9009 - recall: 0.9070\n",
      "Epoch 62: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1133 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9009 - recall: 0.9070 - val_loss: 0.1661 - val_auc: 0.9846 - val_accuracy: 0.9394 - val_precision: 0.9362 - val_recall: 0.7982 - lr: 1.0026e-04\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1142 - auc: 0.9881 - accuracy: 0.9618 - precision: 0.9068 - recall: 0.8986\n",
      "Epoch 63: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1142 - auc: 0.9881 - accuracy: 0.9618 - precision: 0.9068 - recall: 0.8986 - val_loss: 0.1687 - val_auc: 0.9842 - val_accuracy: 0.9389 - val_precision: 0.9380 - val_recall: 0.7941 - lr: 9.0718e-05\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1128 - auc: 0.9889 - accuracy: 0.9621 - precision: 0.9012 - recall: 0.9072\n",
      "Epoch 64: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.1128 - auc: 0.9889 - accuracy: 0.9621 - precision: 0.9012 - recall: 0.9072 - val_loss: 0.1661 - val_auc: 0.9846 - val_accuracy: 0.9395 - val_precision: 0.9355 - val_recall: 0.7995 - lr: 9.0718e-05\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1131 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9029 - recall: 0.9045\n",
      "Epoch 65: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.1131 - auc: 0.9887 - accuracy: 0.9620 - precision: 0.9029 - recall: 0.9045 - val_loss: 0.1650 - val_auc: 0.9848 - val_accuracy: 0.9403 - val_precision: 0.9330 - val_recall: 0.8057 - lr: 8.2085e-05\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1129 - auc: 0.9884 - accuracy: 0.9620 - precision: 0.9036 - recall: 0.9041\n",
      "Epoch 66: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1129 - auc: 0.9884 - accuracy: 0.9620 - precision: 0.9036 - recall: 0.9041 - val_loss: 0.1629 - val_auc: 0.9848 - val_accuracy: 0.9412 - val_precision: 0.9280 - val_recall: 0.8148 - lr: 8.2085e-05\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1128 - auc: 0.9888 - accuracy: 0.9620 - precision: 0.9048 - recall: 0.9023 \n",
      "Epoch 67: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1128 - auc: 0.9888 - accuracy: 0.9620 - precision: 0.9048 - recall: 0.9023 - val_loss: 0.1648 - val_auc: 0.9846 - val_accuracy: 0.9406 - val_precision: 0.9322 - val_recall: 0.8076 - lr: 7.4274e-05\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1119 - auc: 0.9890 - accuracy: 0.9623 - precision: 0.9042 - recall: 0.9050 \n",
      "Epoch 68: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1119 - auc: 0.9890 - accuracy: 0.9623 - precision: 0.9042 - recall: 0.9050 - val_loss: 0.1630 - val_auc: 0.9847 - val_accuracy: 0.9410 - val_precision: 0.9289 - val_recall: 0.8129 - lr: 7.4274e-05\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1125 - auc: 0.9887 - accuracy: 0.9621 - precision: 0.9036 - recall: 0.9043 \n",
      "Epoch 69: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1125 - auc: 0.9887 - accuracy: 0.9621 - precision: 0.9036 - recall: 0.9043 - val_loss: 0.1652 - val_auc: 0.9846 - val_accuracy: 0.9404 - val_precision: 0.9326 - val_recall: 0.8064 - lr: 6.7206e-05\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1125 - auc: 0.9886 - accuracy: 0.9621 - precision: 0.9044 - recall: 0.9034 \n",
      "Epoch 70: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1125 - auc: 0.9886 - accuracy: 0.9621 - precision: 0.9044 - recall: 0.9034 - val_loss: 0.1668 - val_auc: 0.9845 - val_accuracy: 0.9396 - val_precision: 0.9356 - val_recall: 0.7995 - lr: 6.7206e-05\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1123 - auc: 0.9887 - accuracy: 0.9622 - precision: 0.9057 - recall: 0.9021 \n",
      "Epoch 71: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1123 - auc: 0.9887 - accuracy: 0.9622 - precision: 0.9057 - recall: 0.9021 - val_loss: 0.1690 - val_auc: 0.9843 - val_accuracy: 0.9387 - val_precision: 0.9382 - val_recall: 0.7929 - lr: 6.0810e-05\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1118 - auc: 0.9892 - accuracy: 0.9622 - precision: 0.9017 - recall: 0.9072 \n",
      "Epoch 72: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1118 - auc: 0.9892 - accuracy: 0.9622 - precision: 0.9017 - recall: 0.9072 - val_loss: 0.1648 - val_auc: 0.9847 - val_accuracy: 0.9400 - val_precision: 0.9344 - val_recall: 0.8025 - lr: 6.0810e-05\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1122 - auc: 0.9887 - accuracy: 0.9621 - precision: 0.9023 - recall: 0.9060 \n",
      "Epoch 73: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1122 - auc: 0.9887 - accuracy: 0.9621 - precision: 0.9023 - recall: 0.9060 - val_loss: 0.1687 - val_auc: 0.9844 - val_accuracy: 0.9386 - val_precision: 0.9387 - val_recall: 0.7922 - lr: 5.5023e-05\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1115 - auc: 0.9889 - accuracy: 0.9624 - precision: 0.9066 - recall: 0.9026\n",
      "Epoch 74: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1115 - auc: 0.9889 - accuracy: 0.9624 - precision: 0.9066 - recall: 0.9026 - val_loss: 0.1712 - val_auc: 0.9839 - val_accuracy: 0.9378 - val_precision: 0.9407 - val_recall: 0.7868 - lr: 5.5023e-05\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1116 - auc: 0.9888 - accuracy: 0.9623 - precision: 0.9036 - recall: 0.9054 \n",
      "Epoch 75: val_loss did not improve from 0.16111\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1116 - auc: 0.9888 - accuracy: 0.9623 - precision: 0.9036 - recall: 0.9054 - val_loss: 0.1694 - val_auc: 0.9842 - val_accuracy: 0.9383 - val_precision: 0.9393 - val_recall: 0.7903 - lr: 4.9787e-05\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1115 - auc: 0.9889 - accuracy: 0.9623 - precision: 0.9061 - recall: 0.9025 \n",
      "Epoch 76: val_loss did not improve from 0.16111\n",
      "Restoring model weights from the end of the best epoch: 56.\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1115 - auc: 0.9889 - accuracy: 0.9623 - precision: 0.9061 - recall: 0.9025 - val_loss: 0.1721 - val_auc: 0.9839 - val_accuracy: 0.9374 - val_precision: 0.9422 - val_recall: 0.7832 - lr: 4.9787e-05\n",
      "Epoch 76: early stopping\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1385 - auc: 0.9901 - accuracy: 0.9502 - precision: 0.8280 - recall: 0.9590\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4520 - auc: 0.9145 - accuracy: 0.8436 - precision: 0.5814 - recall: 0.8253 \n",
      "Epoch 1: val_loss improved from inf to 1.96436, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.4520 - auc: 0.9145 - accuracy: 0.8436 - precision: 0.5814 - recall: 0.8253 - val_loss: 1.9644 - val_auc: 0.4969 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2931 - auc: 0.9729 - accuracy: 0.9354 - precision: 0.7982 - recall: 0.9129 \n",
      "Epoch 2: val_loss did not improve from 1.96436\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2931 - auc: 0.9729 - accuracy: 0.9354 - precision: 0.7982 - recall: 0.9129 - val_loss: 4.2283 - val_auc: 0.5000 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2469 - auc: 0.9785 - accuracy: 0.9460 - precision: 0.8397 - recall: 0.9077 \n",
      "Epoch 3: val_loss did not improve from 1.96436\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2469 - auc: 0.9785 - accuracy: 0.9460 - precision: 0.8397 - recall: 0.9077 - val_loss: 3.8190 - val_auc: 0.5000 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2140 - auc: 0.9802 - accuracy: 0.9510 - precision: 0.8696 - recall: 0.8930 \n",
      "Epoch 4: val_loss improved from 1.96436 to 1.53097, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2140 - auc: 0.9802 - accuracy: 0.9510 - precision: 0.8696 - recall: 0.8930 - val_loss: 1.5310 - val_auc: 0.4978 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1968 - auc: 0.9798 - accuracy: 0.9522 - precision: 0.8873 - recall: 0.8760 \n",
      "Epoch 5: val_loss improved from 1.53097 to 0.91780, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1968 - auc: 0.9798 - accuracy: 0.9522 - precision: 0.8873 - recall: 0.8760 - val_loss: 0.9178 - val_auc: 0.4951 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1856 - auc: 0.9809 - accuracy: 0.9531 - precision: 0.8929 - recall: 0.8743 \n",
      "Epoch 6: val_loss improved from 0.91780 to 0.82421, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1856 - auc: 0.9809 - accuracy: 0.9531 - precision: 0.8929 - recall: 0.8743 - val_loss: 0.8242 - val_auc: 0.5108 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1765 - auc: 0.9827 - accuracy: 0.9538 - precision: 0.8834 - recall: 0.8905 \n",
      "Epoch 7: val_loss improved from 0.82421 to 0.68389, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1765 - auc: 0.9827 - accuracy: 0.9538 - precision: 0.8834 - recall: 0.8905 - val_loss: 0.6839 - val_auc: 0.8060 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1689 - auc: 0.9818 - accuracy: 0.9549 - precision: 0.9028 - recall: 0.8720 \n",
      "Epoch 8: val_loss improved from 0.68389 to 0.59385, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1689 - auc: 0.9818 - accuracy: 0.9549 - precision: 0.9028 - recall: 0.8720 - val_loss: 0.5939 - val_auc: 0.8083 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1625 - auc: 0.9831 - accuracy: 0.9552 - precision: 0.8967 - recall: 0.8810 \n",
      "Epoch 9: val_loss improved from 0.59385 to 0.46705, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1625 - auc: 0.9831 - accuracy: 0.9552 - precision: 0.8967 - recall: 0.8810 - val_loss: 0.4671 - val_auc: 0.8976 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1569 - auc: 0.9835 - accuracy: 0.9556 - precision: 0.8967 - recall: 0.8837 \n",
      "Epoch 10: val_loss improved from 0.46705 to 0.38865, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1569 - auc: 0.9835 - accuracy: 0.9556 - precision: 0.8967 - recall: 0.8837 - val_loss: 0.3886 - val_auc: 0.9239 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1526 - auc: 0.9839 - accuracy: 0.9557 - precision: 0.9019 - recall: 0.8778\n",
      "Epoch 11: val_loss improved from 0.38865 to 0.35021, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1526 - auc: 0.9839 - accuracy: 0.9557 - precision: 0.9019 - recall: 0.8778 - val_loss: 0.3502 - val_auc: 0.9413 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1486 - auc: 0.9838 - accuracy: 0.9558 - precision: 0.9025 - recall: 0.8775 \n",
      "Epoch 12: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1486 - auc: 0.9838 - accuracy: 0.9558 - precision: 0.9025 - recall: 0.8775 - val_loss: 0.3607 - val_auc: 0.9444 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1446 - auc: 0.9842 - accuracy: 0.9564 - precision: 0.9011 - recall: 0.8823 \n",
      "Epoch 13: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1446 - auc: 0.9842 - accuracy: 0.9564 - precision: 0.9011 - recall: 0.8823 - val_loss: 0.3815 - val_auc: 0.7626 - val_accuracy: 0.8652 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1399 - auc: 0.9851 - accuracy: 0.9571 - precision: 0.9016 - recall: 0.8857 \n",
      "Epoch 14: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1399 - auc: 0.9851 - accuracy: 0.9571 - precision: 0.9016 - recall: 0.8857 - val_loss: 0.3919 - val_auc: 0.5796 - val_accuracy: 0.8652 - val_precision: 1.0000 - val_recall: 1.1321e-04 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1371 - auc: 0.9858 - accuracy: 0.9571 - precision: 0.9034 - recall: 0.8836\n",
      "Epoch 15: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1371 - auc: 0.9858 - accuracy: 0.9571 - precision: 0.9034 - recall: 0.8836 - val_loss: 0.4015 - val_auc: 0.3972 - val_accuracy: 0.8654 - val_precision: 1.0000 - val_recall: 0.0015 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1341 - auc: 0.9854 - accuracy: 0.9575 - precision: 0.9080 - recall: 0.8803\n",
      "Epoch 16: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1341 - auc: 0.9854 - accuracy: 0.9575 - precision: 0.9080 - recall: 0.8803 - val_loss: 0.4225 - val_auc: 0.2395 - val_accuracy: 0.8661 - val_precision: 1.0000 - val_recall: 0.0062 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1314 - auc: 0.9862 - accuracy: 0.9578 - precision: 0.9017 - recall: 0.8895 \n",
      "Epoch 17: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1314 - auc: 0.9862 - accuracy: 0.9578 - precision: 0.9017 - recall: 0.8895 - val_loss: 0.4056 - val_auc: 0.3465 - val_accuracy: 0.8678 - val_precision: 1.0000 - val_recall: 0.0195 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1287 - auc: 0.9864 - accuracy: 0.9583 - precision: 0.9107 - recall: 0.8811 \n",
      "Epoch 18: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1287 - auc: 0.9864 - accuracy: 0.9583 - precision: 0.9107 - recall: 0.8811 - val_loss: 0.4053 - val_auc: 0.4873 - val_accuracy: 0.8694 - val_precision: 1.0000 - val_recall: 0.0309 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1255 - auc: 0.9872 - accuracy: 0.9589 - precision: 0.9074 - recall: 0.8886\n",
      "Epoch 19: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1255 - auc: 0.9872 - accuracy: 0.9589 - precision: 0.9074 - recall: 0.8886 - val_loss: 0.3949 - val_auc: 0.5192 - val_accuracy: 0.8723 - val_precision: 0.9923 - val_recall: 0.0526 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1244 - auc: 0.9870 - accuracy: 0.9589 - precision: 0.9092 - recall: 0.8862 \n",
      "Epoch 20: val_loss did not improve from 0.35021\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1244 - auc: 0.9870 - accuracy: 0.9589 - precision: 0.9092 - recall: 0.8862 - val_loss: 0.3557 - val_auc: 0.8367 - val_accuracy: 0.8793 - val_precision: 0.9824 - val_recall: 0.1061 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1226 - auc: 0.9875 - accuracy: 0.9590 - precision: 0.9092 - recall: 0.8870\n",
      "Epoch 21: val_loss improved from 0.35021 to 0.32100, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1226 - auc: 0.9875 - accuracy: 0.9590 - precision: 0.9092 - recall: 0.8870 - val_loss: 0.3210 - val_auc: 0.9164 - val_accuracy: 0.8882 - val_precision: 0.9800 - val_recall: 0.1739 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1217 - auc: 0.9874 - accuracy: 0.9590 - precision: 0.9058 - recall: 0.8913\n",
      "Epoch 22: val_loss improved from 0.32100 to 0.30090, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1217 - auc: 0.9874 - accuracy: 0.9590 - precision: 0.9058 - recall: 0.8913 - val_loss: 0.3009 - val_auc: 0.9248 - val_accuracy: 0.8947 - val_precision: 0.9793 - val_recall: 0.2237 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1200 - auc: 0.9875 - accuracy: 0.9593 - precision: 0.9106 - recall: 0.8868\n",
      "Epoch 23: val_loss improved from 0.30090 to 0.27739, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1200 - auc: 0.9875 - accuracy: 0.9593 - precision: 0.9106 - recall: 0.8868 - val_loss: 0.2774 - val_auc: 0.8829 - val_accuracy: 0.9072 - val_precision: 0.9766 - val_recall: 0.3189 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1181 - auc: 0.9882 - accuracy: 0.9597 - precision: 0.9102 - recall: 0.8897 \n",
      "Epoch 24: val_loss improved from 0.27739 to 0.27628, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1181 - auc: 0.9882 - accuracy: 0.9597 - precision: 0.9102 - recall: 0.8897 - val_loss: 0.2763 - val_auc: 0.8480 - val_accuracy: 0.9089 - val_precision: 0.9748 - val_recall: 0.3325 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1172 - auc: 0.9881 - accuracy: 0.9598 - precision: 0.9080 - recall: 0.8925\n",
      "Epoch 25: val_loss improved from 0.27628 to 0.26784, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1172 - auc: 0.9881 - accuracy: 0.9598 - precision: 0.9080 - recall: 0.8925 - val_loss: 0.2678 - val_auc: 0.8636 - val_accuracy: 0.9108 - val_precision: 0.9737 - val_recall: 0.3478 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9883 - accuracy: 0.9600 - precision: 0.9122 - recall: 0.8887\n",
      "Epoch 26: val_loss improved from 0.26784 to 0.24676, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1160 - auc: 0.9883 - accuracy: 0.9600 - precision: 0.9122 - recall: 0.8887 - val_loss: 0.2468 - val_auc: 0.8398 - val_accuracy: 0.9200 - val_precision: 0.9618 - val_recall: 0.4230 - lr: 6.0653e-04\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1143 - auc: 0.9888 - accuracy: 0.9604 - precision: 0.9111 - recall: 0.8924\n",
      "Epoch 27: val_loss improved from 0.24676 to 0.23015, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1143 - auc: 0.9888 - accuracy: 0.9604 - precision: 0.9111 - recall: 0.8924 - val_loss: 0.2302 - val_auc: 0.8471 - val_accuracy: 0.9269 - val_precision: 0.9520 - val_recall: 0.4820 - lr: 5.4881e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1149 - auc: 0.9883 - accuracy: 0.9599 - precision: 0.9117 - recall: 0.8888 \n",
      "Epoch 28: val_loss improved from 0.23015 to 0.21796, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1149 - auc: 0.9883 - accuracy: 0.9599 - precision: 0.9117 - recall: 0.8888 - val_loss: 0.2180 - val_auc: 0.8677 - val_accuracy: 0.9320 - val_precision: 0.9417 - val_recall: 0.5285 - lr: 5.4881e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1136 - auc: 0.9888 - accuracy: 0.9601 - precision: 0.9087 - recall: 0.8936\n",
      "Epoch 29: val_loss improved from 0.21796 to 0.20963, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1136 - auc: 0.9888 - accuracy: 0.9601 - precision: 0.9087 - recall: 0.8936 - val_loss: 0.2096 - val_auc: 0.8815 - val_accuracy: 0.9352 - val_precision: 0.9265 - val_recall: 0.5639 - lr: 4.9659e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1117 - auc: 0.9890 - accuracy: 0.9607 - precision: 0.9123 - recall: 0.8928 \n",
      "Epoch 30: val_loss did not improve from 0.20963\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1117 - auc: 0.9890 - accuracy: 0.9607 - precision: 0.9123 - recall: 0.8928 - val_loss: 0.2226 - val_auc: 0.8569 - val_accuracy: 0.9301 - val_precision: 0.9337 - val_recall: 0.5179 - lr: 4.9659e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1111 - auc: 0.9892 - accuracy: 0.9608 - precision: 0.9102 - recall: 0.8957\n",
      "Epoch 31: val_loss did not improve from 0.20963\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1111 - auc: 0.9892 - accuracy: 0.9608 - precision: 0.9102 - recall: 0.8957 - val_loss: 0.2172 - val_auc: 0.8652 - val_accuracy: 0.9318 - val_precision: 0.9266 - val_recall: 0.5366 - lr: 4.4933e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1113 - auc: 0.9889 - accuracy: 0.9605 - precision: 0.9125 - recall: 0.8914\n",
      "Epoch 32: val_loss improved from 0.20963 to 0.20407, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1113 - auc: 0.9889 - accuracy: 0.9605 - precision: 0.9125 - recall: 0.8914 - val_loss: 0.2041 - val_auc: 0.8803 - val_accuracy: 0.9368 - val_precision: 0.9156 - val_recall: 0.5850 - lr: 4.4933e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1107 - auc: 0.9891 - accuracy: 0.9606 - precision: 0.9117 - recall: 0.8929\n",
      "Epoch 33: val_loss did not improve from 0.20407\n",
      "10/10 [==============================] - 95s 10s/step - loss: 0.1107 - auc: 0.9891 - accuracy: 0.9606 - precision: 0.9117 - recall: 0.8929 - val_loss: 0.2071 - val_auc: 0.8811 - val_accuracy: 0.9345 - val_precision: 0.9096 - val_recall: 0.5710 - lr: 4.0657e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1097 - auc: 0.9894 - accuracy: 0.9609 - precision: 0.9114 - recall: 0.8946\n",
      "Epoch 34: val_loss improved from 0.20407 to 0.18400, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1097 - auc: 0.9894 - accuracy: 0.9609 - precision: 0.9114 - recall: 0.8946 - val_loss: 0.1840 - val_auc: 0.9222 - val_accuracy: 0.9436 - val_precision: 0.8856 - val_recall: 0.6677 - lr: 4.0657e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1083 - auc: 0.9897 - accuracy: 0.9613 - precision: 0.9087 - recall: 0.9002\n",
      "Epoch 35: val_loss improved from 0.18400 to 0.17600, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1083 - auc: 0.9897 - accuracy: 0.9613 - precision: 0.9087 - recall: 0.9002 - val_loss: 0.1760 - val_auc: 0.9353 - val_accuracy: 0.9460 - val_precision: 0.8822 - val_recall: 0.6919 - lr: 3.6788e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1089 - auc: 0.9893 - accuracy: 0.9609 - precision: 0.9147 - recall: 0.8911 \n",
      "Epoch 36: val_loss improved from 0.17600 to 0.17105, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1089 - auc: 0.9893 - accuracy: 0.9609 - precision: 0.9147 - recall: 0.8911 - val_loss: 0.1710 - val_auc: 0.9389 - val_accuracy: 0.9477 - val_precision: 0.8760 - val_recall: 0.7125 - lr: 3.6788e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1087 - auc: 0.9895 - accuracy: 0.9610 - precision: 0.9112 - recall: 0.8954 \n",
      "Epoch 37: val_loss improved from 0.17105 to 0.16445, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1087 - auc: 0.9895 - accuracy: 0.9610 - precision: 0.9112 - recall: 0.8954 - val_loss: 0.1644 - val_auc: 0.9488 - val_accuracy: 0.9490 - val_precision: 0.8551 - val_recall: 0.7487 - lr: 3.3287e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1067 - auc: 0.9897 - accuracy: 0.9617 - precision: 0.9114 - recall: 0.8988 \n",
      "Epoch 38: val_loss improved from 0.16445 to 0.15861, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1067 - auc: 0.9897 - accuracy: 0.9617 - precision: 0.9114 - recall: 0.8988 - val_loss: 0.1586 - val_auc: 0.9528 - val_accuracy: 0.9522 - val_precision: 0.8708 - val_recall: 0.7578 - lr: 3.3287e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1073 - auc: 0.9897 - accuracy: 0.9613 - precision: 0.9110 - recall: 0.8972 \n",
      "Epoch 39: val_loss improved from 0.15861 to 0.14783, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1073 - auc: 0.9897 - accuracy: 0.9613 - precision: 0.9110 - recall: 0.8972 - val_loss: 0.1478 - val_auc: 0.9597 - val_accuracy: 0.9544 - val_precision: 0.8759 - val_recall: 0.7711 - lr: 3.0119e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1064 - auc: 0.9900 - accuracy: 0.9615 - precision: 0.9126 - recall: 0.8965 \n",
      "Epoch 40: val_loss improved from 0.14783 to 0.13827, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1064 - auc: 0.9900 - accuracy: 0.9615 - precision: 0.9126 - recall: 0.8965 - val_loss: 0.1383 - val_auc: 0.9668 - val_accuracy: 0.9571 - val_precision: 0.8772 - val_recall: 0.7931 - lr: 3.0119e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1058 - auc: 0.9899 - accuracy: 0.9618 - precision: 0.9134 - recall: 0.8970\n",
      "Epoch 41: val_loss improved from 0.13827 to 0.13303, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1058 - auc: 0.9899 - accuracy: 0.9618 - precision: 0.9134 - recall: 0.8970 - val_loss: 0.1330 - val_auc: 0.9694 - val_accuracy: 0.9582 - val_precision: 0.8740 - val_recall: 0.8059 - lr: 2.7253e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1052 - auc: 0.9900 - accuracy: 0.9619 - precision: 0.9131 - recall: 0.8981 \n",
      "Epoch 42: val_loss improved from 0.13303 to 0.13233, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1052 - auc: 0.9900 - accuracy: 0.9619 - precision: 0.9131 - recall: 0.8981 - val_loss: 0.1323 - val_auc: 0.9710 - val_accuracy: 0.9583 - val_precision: 0.8786 - val_recall: 0.8014 - lr: 2.7253e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1059 - auc: 0.9899 - accuracy: 0.9615 - precision: 0.9119 - recall: 0.8971\n",
      "Epoch 43: val_loss improved from 0.13233 to 0.12991, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1059 - auc: 0.9899 - accuracy: 0.9615 - precision: 0.9119 - recall: 0.8971 - val_loss: 0.1299 - val_auc: 0.9703 - val_accuracy: 0.9584 - val_precision: 0.8824 - val_recall: 0.7977 - lr: 2.4660e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1053 - auc: 0.9900 - accuracy: 0.9617 - precision: 0.9128 - recall: 0.8971\n",
      "Epoch 44: val_loss improved from 0.12991 to 0.12904, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1053 - auc: 0.9900 - accuracy: 0.9617 - precision: 0.9128 - recall: 0.8971 - val_loss: 0.1290 - val_auc: 0.9727 - val_accuracy: 0.9589 - val_precision: 0.8856 - val_recall: 0.7981 - lr: 2.4660e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1047 - auc: 0.9901 - accuracy: 0.9619 - precision: 0.9146 - recall: 0.8961 \n",
      "Epoch 45: val_loss improved from 0.12904 to 0.12333, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1047 - auc: 0.9901 - accuracy: 0.9619 - precision: 0.9146 - recall: 0.8961 - val_loss: 0.1233 - val_auc: 0.9729 - val_accuracy: 0.9603 - val_precision: 0.8895 - val_recall: 0.8053 - lr: 2.2313e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1041 - auc: 0.9903 - accuracy: 0.9620 - precision: 0.9097 - recall: 0.9027\n",
      "Epoch 46: val_loss improved from 0.12333 to 0.12142, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1041 - auc: 0.9903 - accuracy: 0.9620 - precision: 0.9097 - recall: 0.9027 - val_loss: 0.1214 - val_auc: 0.9738 - val_accuracy: 0.9606 - val_precision: 0.8916 - val_recall: 0.8056 - lr: 2.2313e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1047 - auc: 0.9901 - accuracy: 0.9617 - precision: 0.9101 - recall: 0.9006 \n",
      "Epoch 47: val_loss improved from 0.12142 to 0.11788, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1047 - auc: 0.9901 - accuracy: 0.9617 - precision: 0.9101 - recall: 0.9006 - val_loss: 0.1179 - val_auc: 0.9745 - val_accuracy: 0.9614 - val_precision: 0.8932 - val_recall: 0.8104 - lr: 2.0190e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1042 - auc: 0.9902 - accuracy: 0.9618 - precision: 0.9191 - recall: 0.8906\n",
      "Epoch 48: val_loss did not improve from 0.11788\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1042 - auc: 0.9902 - accuracy: 0.9618 - precision: 0.9191 - recall: 0.8906 - val_loss: 0.1231 - val_auc: 0.9718 - val_accuracy: 0.9591 - val_precision: 0.8899 - val_recall: 0.7946 - lr: 2.0190e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1036 - auc: 0.9903 - accuracy: 0.9621 - precision: 0.9151 - recall: 0.8967 \n",
      "Epoch 49: val_loss improved from 0.11788 to 0.11296, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1036 - auc: 0.9903 - accuracy: 0.9621 - precision: 0.9151 - recall: 0.8967 - val_loss: 0.1130 - val_auc: 0.9766 - val_accuracy: 0.9629 - val_precision: 0.8871 - val_recall: 0.8303 - lr: 1.8268e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1034 - auc: 0.9904 - accuracy: 0.9621 - precision: 0.9096 - recall: 0.9033 \n",
      "Epoch 50: val_loss improved from 0.11296 to 0.11151, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1034 - auc: 0.9904 - accuracy: 0.9621 - precision: 0.9096 - recall: 0.9033 - val_loss: 0.1115 - val_auc: 0.9773 - val_accuracy: 0.9635 - val_precision: 0.8852 - val_recall: 0.8377 - lr: 1.8268e-04\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1031 - auc: 0.9904 - accuracy: 0.9622 - precision: 0.9138 - recall: 0.8990 \n",
      "Epoch 51: val_loss improved from 0.11151 to 0.10599, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1031 - auc: 0.9904 - accuracy: 0.9622 - precision: 0.9138 - recall: 0.8990 - val_loss: 0.1060 - val_auc: 0.9789 - val_accuracy: 0.9650 - val_precision: 0.8864 - val_recall: 0.8494 - lr: 1.6530e-04\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1032 - auc: 0.9904 - accuracy: 0.9621 - precision: 0.9140 - recall: 0.8982 \n",
      "Epoch 52: val_loss improved from 0.10599 to 0.10468, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1032 - auc: 0.9904 - accuracy: 0.9621 - precision: 0.9140 - recall: 0.8982 - val_loss: 0.1047 - val_auc: 0.9803 - val_accuracy: 0.9660 - val_precision: 0.8830 - val_recall: 0.8623 - lr: 1.6530e-04\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1026 - auc: 0.9905 - accuracy: 0.9622 - precision: 0.9148 - recall: 0.8980 \n",
      "Epoch 53: val_loss improved from 0.10468 to 0.10151, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1026 - auc: 0.9905 - accuracy: 0.9622 - precision: 0.9148 - recall: 0.8980 - val_loss: 0.1015 - val_auc: 0.9803 - val_accuracy: 0.9662 - val_precision: 0.8873 - val_recall: 0.8584 - lr: 1.4957e-04\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1022 - auc: 0.9906 - accuracy: 0.9624 - precision: 0.9122 - recall: 0.9017 \n",
      "Epoch 54: val_loss improved from 0.10151 to 0.09993, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1022 - auc: 0.9906 - accuracy: 0.9624 - precision: 0.9122 - recall: 0.9017 - val_loss: 0.0999 - val_auc: 0.9831 - val_accuracy: 0.9673 - val_precision: 0.8839 - val_recall: 0.8717 - lr: 1.4957e-04\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1018 - auc: 0.9907 - accuracy: 0.9625 - precision: 0.9160 - recall: 0.8979\n",
      "Epoch 55: val_loss improved from 0.09993 to 0.09574, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1018 - auc: 0.9907 - accuracy: 0.9625 - precision: 0.9160 - recall: 0.8979 - val_loss: 0.0957 - val_auc: 0.9840 - val_accuracy: 0.9679 - val_precision: 0.8713 - val_recall: 0.8935 - lr: 1.3534e-04\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1021 - auc: 0.9905 - accuracy: 0.9624 - precision: 0.9142 - recall: 0.8997 \n",
      "Epoch 56: val_loss did not improve from 0.09574\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1021 - auc: 0.9905 - accuracy: 0.9624 - precision: 0.9142 - recall: 0.8997 - val_loss: 0.0976 - val_auc: 0.9856 - val_accuracy: 0.9676 - val_precision: 0.8653 - val_recall: 0.8994 - lr: 1.3534e-04\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1020 - auc: 0.9906 - accuracy: 0.9624 - precision: 0.9105 - recall: 0.9038 \n",
      "Epoch 57: val_loss improved from 0.09574 to 0.09546, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1020 - auc: 0.9906 - accuracy: 0.9624 - precision: 0.9105 - recall: 0.9038 - val_loss: 0.0955 - val_auc: 0.9852 - val_accuracy: 0.9682 - val_precision: 0.8734 - val_recall: 0.8933 - lr: 1.2246e-04\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1011 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9161 - recall: 0.8989 \n",
      "Epoch 58: val_loss improved from 0.09546 to 0.09383, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1011 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9161 - recall: 0.8989 - val_loss: 0.0938 - val_auc: 0.9861 - val_accuracy: 0.9682 - val_precision: 0.8739 - val_recall: 0.8932 - lr: 1.2246e-04\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1014 - auc: 0.9907 - accuracy: 0.9626 - precision: 0.9136 - recall: 0.9011 \n",
      "Epoch 59: val_loss improved from 0.09383 to 0.09250, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1014 - auc: 0.9907 - accuracy: 0.9626 - precision: 0.9136 - recall: 0.9011 - val_loss: 0.0925 - val_auc: 0.9872 - val_accuracy: 0.9687 - val_precision: 0.8756 - val_recall: 0.8948 - lr: 1.1080e-04\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1018 - auc: 0.9905 - accuracy: 0.9624 - precision: 0.9164 - recall: 0.8968 \n",
      "Epoch 60: val_loss did not improve from 0.09250\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1018 - auc: 0.9905 - accuracy: 0.9624 - precision: 0.9164 - recall: 0.8968 - val_loss: 0.0928 - val_auc: 0.9868 - val_accuracy: 0.9685 - val_precision: 0.8764 - val_recall: 0.8923 - lr: 1.1080e-04\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1008 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9114 - recall: 0.9049 \n",
      "Epoch 61: val_loss did not improve from 0.09250\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1008 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9114 - recall: 0.9049 - val_loss: 0.0933 - val_auc: 0.9874 - val_accuracy: 0.9683 - val_precision: 0.8696 - val_recall: 0.8997 - lr: 1.0026e-04\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1008 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9149 - recall: 0.9003 \n",
      "Epoch 62: val_loss improved from 0.09250 to 0.09199, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1008 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9149 - recall: 0.9003 - val_loss: 0.0920 - val_auc: 0.9884 - val_accuracy: 0.9688 - val_precision: 0.8699 - val_recall: 0.9033 - lr: 1.0026e-04\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1008 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9153 - recall: 0.8998 \n",
      "Epoch 63: val_loss improved from 0.09199 to 0.08931, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1008 - auc: 0.9908 - accuracy: 0.9627 - precision: 0.9153 - recall: 0.8998 - val_loss: 0.0893 - val_auc: 0.9887 - val_accuracy: 0.9695 - val_precision: 0.8756 - val_recall: 0.9023 - lr: 9.0718e-05\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1003 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9134 - recall: 0.9032 \n",
      "Epoch 64: val_loss did not improve from 0.08931\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1003 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9134 - recall: 0.9032 - val_loss: 0.0900 - val_auc: 0.9892 - val_accuracy: 0.9693 - val_precision: 0.8707 - val_recall: 0.9072 - lr: 9.0718e-05\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1005 - auc: 0.9908 - accuracy: 0.9628 - precision: 0.9163 - recall: 0.8992 \n",
      "Epoch 65: val_loss improved from 0.08931 to 0.08877, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1005 - auc: 0.9908 - accuracy: 0.9628 - precision: 0.9163 - recall: 0.8992 - val_loss: 0.0888 - val_auc: 0.9901 - val_accuracy: 0.9694 - val_precision: 0.8698 - val_recall: 0.9094 - lr: 8.2085e-05\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1011 - auc: 0.9907 - accuracy: 0.9625 - precision: 0.9131 - recall: 0.9013 \n",
      "Epoch 66: val_loss did not improve from 0.08877\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1011 - auc: 0.9907 - accuracy: 0.9625 - precision: 0.9131 - recall: 0.9013 - val_loss: 0.0895 - val_auc: 0.9907 - val_accuracy: 0.9690 - val_precision: 0.8629 - val_recall: 0.9151 - lr: 8.2085e-05\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1005 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9133 - recall: 0.9026 \n",
      "Epoch 67: val_loss improved from 0.08877 to 0.08745, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1005 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9133 - recall: 0.9026 - val_loss: 0.0874 - val_auc: 0.9906 - val_accuracy: 0.9695 - val_precision: 0.8683 - val_recall: 0.9122 - lr: 7.4274e-05\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1013 - auc: 0.9905 - accuracy: 0.9625 - precision: 0.9169 - recall: 0.8966 \n",
      "Epoch 68: val_loss improved from 0.08745 to 0.08681, saving model to pixel_core_fold_12.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1013 - auc: 0.9905 - accuracy: 0.9625 - precision: 0.9169 - recall: 0.8966 - val_loss: 0.0868 - val_auc: 0.9908 - val_accuracy: 0.9698 - val_precision: 0.8703 - val_recall: 0.9115 - lr: 7.4274e-05\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1004 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9123 - recall: 0.9040 \n",
      "Epoch 69: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1004 - auc: 0.9909 - accuracy: 0.9628 - precision: 0.9123 - recall: 0.9040 - val_loss: 0.0879 - val_auc: 0.9912 - val_accuracy: 0.9690 - val_precision: 0.8604 - val_recall: 0.9194 - lr: 6.7206e-05\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0999 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9141 - recall: 0.9025 \n",
      "Epoch 70: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.0999 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9141 - recall: 0.9025 - val_loss: 0.0880 - val_auc: 0.9917 - val_accuracy: 0.9691 - val_precision: 0.8605 - val_recall: 0.9200 - lr: 6.7206e-05\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1000 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9188 - recall: 0.8969 \n",
      "Epoch 71: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1000 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9188 - recall: 0.8969 - val_loss: 0.0871 - val_auc: 0.9915 - val_accuracy: 0.9694 - val_precision: 0.8636 - val_recall: 0.9179 - lr: 6.0810e-05\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0998 - auc: 0.9908 - accuracy: 0.9629 - precision: 0.9146 - recall: 0.9020 \n",
      "Epoch 72: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.0998 - auc: 0.9908 - accuracy: 0.9629 - precision: 0.9146 - recall: 0.9020 - val_loss: 0.0874 - val_auc: 0.9912 - val_accuracy: 0.9691 - val_precision: 0.8600 - val_recall: 0.9204 - lr: 6.0810e-05\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0999 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9118 - recall: 0.9053 \n",
      "Epoch 73: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.0999 - auc: 0.9909 - accuracy: 0.9629 - precision: 0.9118 - recall: 0.9053 - val_loss: 0.0891 - val_auc: 0.9915 - val_accuracy: 0.9686 - val_precision: 0.8548 - val_recall: 0.9238 - lr: 5.5023e-05\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0995 - auc: 0.9909 - accuracy: 0.9631 - precision: 0.9157 - recall: 0.9014 \n",
      "Epoch 74: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.0995 - auc: 0.9909 - accuracy: 0.9631 - precision: 0.9157 - recall: 0.9014 - val_loss: 0.0906 - val_auc: 0.9916 - val_accuracy: 0.9684 - val_precision: 0.8526 - val_recall: 0.9256 - lr: 5.5023e-05\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0995 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9164 - recall: 0.9002 \n",
      "Epoch 75: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.0995 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9164 - recall: 0.9002 - val_loss: 0.0905 - val_auc: 0.9917 - val_accuracy: 0.9681 - val_precision: 0.8490 - val_recall: 0.9284 - lr: 4.9787e-05\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1002 - auc: 0.9907 - accuracy: 0.9628 - precision: 0.9163 - recall: 0.8992 \n",
      "Epoch 76: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1002 - auc: 0.9907 - accuracy: 0.9628 - precision: 0.9163 - recall: 0.8992 - val_loss: 0.0893 - val_auc: 0.9919 - val_accuracy: 0.9686 - val_precision: 0.8525 - val_recall: 0.9272 - lr: 4.9787e-05\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0998 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9110 - recall: 0.9060 \n",
      "Epoch 77: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.0998 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9110 - recall: 0.9060 - val_loss: 0.0909 - val_auc: 0.9921 - val_accuracy: 0.9676 - val_precision: 0.8428 - val_recall: 0.9333 - lr: 4.5049e-05\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0995 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9159 - recall: 0.9008 \n",
      "Epoch 78: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.0995 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9159 - recall: 0.9008 - val_loss: 0.0911 - val_auc: 0.9922 - val_accuracy: 0.9680 - val_precision: 0.8467 - val_recall: 0.9311 - lr: 4.5049e-05\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0995 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9161 - recall: 0.9003 \n",
      "Epoch 79: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.0995 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9161 - recall: 0.9003 - val_loss: 0.0939 - val_auc: 0.9923 - val_accuracy: 0.9666 - val_precision: 0.8345 - val_recall: 0.9380 - lr: 4.0762e-05\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0992 - auc: 0.9911 - accuracy: 0.9631 - precision: 0.9136 - recall: 0.9040 \n",
      "Epoch 80: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.0992 - auc: 0.9911 - accuracy: 0.9631 - precision: 0.9136 - recall: 0.9040 - val_loss: 0.0941 - val_auc: 0.9923 - val_accuracy: 0.9665 - val_precision: 0.8337 - val_recall: 0.9383 - lr: 4.0762e-05\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0996 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9142 - recall: 0.9021 \n",
      "Epoch 81: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.0996 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9142 - recall: 0.9021 - val_loss: 0.0949 - val_auc: 0.9923 - val_accuracy: 0.9663 - val_precision: 0.8324 - val_recall: 0.9390 - lr: 3.6883e-05\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0991 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9164 - recall: 0.9005\n",
      "Epoch 82: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.0991 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9164 - recall: 0.9005 - val_loss: 0.0930 - val_auc: 0.9923 - val_accuracy: 0.9671 - val_precision: 0.8381 - val_recall: 0.9365 - lr: 3.6883e-05\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0990 - auc: 0.9911 - accuracy: 0.9631 - precision: 0.9151 - recall: 0.9024 \n",
      "Epoch 83: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.0990 - auc: 0.9911 - accuracy: 0.9631 - precision: 0.9151 - recall: 0.9024 - val_loss: 0.0924 - val_auc: 0.9923 - val_accuracy: 0.9671 - val_precision: 0.8380 - val_recall: 0.9367 - lr: 3.3373e-05\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0994 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9143 - recall: 0.9023 \n",
      "Epoch 84: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.0994 - auc: 0.9910 - accuracy: 0.9629 - precision: 0.9143 - recall: 0.9023 - val_loss: 0.0922 - val_auc: 0.9923 - val_accuracy: 0.9672 - val_precision: 0.8390 - val_recall: 0.9361 - lr: 3.3373e-05\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0993 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9133 - recall: 0.9037 \n",
      "Epoch 85: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.0993 - auc: 0.9910 - accuracy: 0.9630 - precision: 0.9133 - recall: 0.9037 - val_loss: 0.0910 - val_auc: 0.9922 - val_accuracy: 0.9678 - val_precision: 0.8437 - val_recall: 0.9337 - lr: 3.0197e-05\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0991 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9145 - recall: 0.9026\n",
      "Epoch 86: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.0991 - auc: 0.9911 - accuracy: 0.9630 - precision: 0.9145 - recall: 0.9026 - val_loss: 0.0903 - val_auc: 0.9922 - val_accuracy: 0.9682 - val_precision: 0.8469 - val_recall: 0.9325 - lr: 3.0197e-05\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0993 - auc: 0.9909 - accuracy: 0.9630 - precision: 0.9160 - recall: 0.9005 \n",
      "Epoch 87: val_loss did not improve from 0.08681\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.0993 - auc: 0.9909 - accuracy: 0.9630 - precision: 0.9160 - recall: 0.9005 - val_loss: 0.0900 - val_auc: 0.9923 - val_accuracy: 0.9684 - val_precision: 0.8486 - val_recall: 0.9313 - lr: 2.7324e-05\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0987 - auc: 0.9911 - accuracy: 0.9632 - precision: 0.9156 - recall: 0.9024\n",
      "Epoch 88: val_loss did not improve from 0.08681\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.0987 - auc: 0.9911 - accuracy: 0.9632 - precision: 0.9156 - recall: 0.9024 - val_loss: 0.0908 - val_auc: 0.9922 - val_accuracy: 0.9679 - val_precision: 0.8452 - val_recall: 0.9328 - lr: 2.7324e-05\n",
      "Epoch 88: early stopping\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2684 - auc: 0.9805 - accuracy: 0.8911 - precision: 0.9749 - recall: 0.6684\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4155 - auc: 0.8707 - accuracy: 0.8452 - precision: 0.6617 - recall: 0.5512 \n",
      "Epoch 1: val_loss improved from inf to 0.44072, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.4155 - auc: 0.8707 - accuracy: 0.8452 - precision: 0.6617 - recall: 0.5512 - val_loss: 0.4407 - val_auc: 0.5902 - val_accuracy: 0.8577 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2290 - auc: 0.9714 - accuracy: 0.9344 - precision: 0.8271 - recall: 0.8725 \n",
      "Epoch 2: val_loss did not improve from 0.44072\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.2290 - auc: 0.9714 - accuracy: 0.9344 - precision: 0.8271 - recall: 0.8725 - val_loss: 0.8381 - val_auc: 0.4788 - val_accuracy: 0.8577 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1907 - auc: 0.9762 - accuracy: 0.9452 - precision: 0.8826 - recall: 0.8550 \n",
      "Epoch 3: val_loss did not improve from 0.44072\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1907 - auc: 0.9762 - accuracy: 0.9452 - precision: 0.8826 - recall: 0.8550 - val_loss: 0.7843 - val_auc: 0.5153 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1751 - auc: 0.9792 - accuracy: 0.9474 - precision: 0.8845 - recall: 0.8645 \n",
      "Epoch 4: val_loss did not improve from 0.44072\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1751 - auc: 0.9792 - accuracy: 0.9474 - precision: 0.8845 - recall: 0.8645 - val_loss: 0.5820 - val_auc: 0.6549 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1643 - auc: 0.9800 - accuracy: 0.9493 - precision: 0.8883 - recall: 0.8702 \n",
      "Epoch 5: val_loss improved from 0.44072 to 0.42166, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1643 - auc: 0.9800 - accuracy: 0.9493 - precision: 0.8883 - recall: 0.8702 - val_loss: 0.4217 - val_auc: 0.7381 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1594 - auc: 0.9806 - accuracy: 0.9494 - precision: 0.8934 - recall: 0.8641 \n",
      "Epoch 6: val_loss improved from 0.42166 to 0.40716, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1594 - auc: 0.9806 - accuracy: 0.9494 - precision: 0.8934 - recall: 0.8641 - val_loss: 0.4072 - val_auc: 0.4684 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1543 - auc: 0.9815 - accuracy: 0.9496 - precision: 0.8928 - recall: 0.8662 \n",
      "Epoch 7: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1543 - auc: 0.9815 - accuracy: 0.9496 - precision: 0.8928 - recall: 0.8662 - val_loss: 0.4148 - val_auc: 0.5466 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1494 - auc: 0.9827 - accuracy: 0.9501 - precision: 0.8916 - recall: 0.8704 \n",
      "Epoch 8: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1494 - auc: 0.9827 - accuracy: 0.9501 - precision: 0.8916 - recall: 0.8704 - val_loss: 0.4190 - val_auc: 0.5690 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1456 - auc: 0.9828 - accuracy: 0.9505 - precision: 0.8911 - recall: 0.8732 \n",
      "Epoch 9: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1456 - auc: 0.9828 - accuracy: 0.9505 - precision: 0.8911 - recall: 0.8732 - val_loss: 0.4354 - val_auc: 0.6414 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1418 - auc: 0.9832 - accuracy: 0.9510 - precision: 0.9017 - recall: 0.8628 \n",
      "Epoch 10: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1418 - auc: 0.9832 - accuracy: 0.9510 - precision: 0.9017 - recall: 0.8628 - val_loss: 0.4575 - val_auc: 0.5736 - val_accuracy: 0.8596 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1393 - auc: 0.9837 - accuracy: 0.9510 - precision: 0.8939 - recall: 0.8721 \n",
      "Epoch 11: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1393 - auc: 0.9837 - accuracy: 0.9510 - precision: 0.8939 - recall: 0.8721 - val_loss: 0.4771 - val_auc: 0.6030 - val_accuracy: 0.8587 - val_precision: 0.0652 - val_recall: 4.7556e-04 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1372 - auc: 0.9837 - accuracy: 0.9511 - precision: 0.8969 - recall: 0.8693 \n",
      "Epoch 12: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1372 - auc: 0.9837 - accuracy: 0.9511 - precision: 0.8969 - recall: 0.8693 - val_loss: 0.4926 - val_auc: 0.5804 - val_accuracy: 0.8573 - val_precision: 0.0700 - val_recall: 0.0014 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1350 - auc: 0.9839 - accuracy: 0.9514 - precision: 0.8984 - recall: 0.8686 \n",
      "Epoch 13: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1350 - auc: 0.9839 - accuracy: 0.9514 - precision: 0.8984 - recall: 0.8686 - val_loss: 0.5195 - val_auc: 0.5577 - val_accuracy: 0.8559 - val_precision: 0.0927 - val_recall: 0.0030 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1338 - auc: 0.9841 - accuracy: 0.9516 - precision: 0.8985 - recall: 0.8699 \n",
      "Epoch 14: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1338 - auc: 0.9841 - accuracy: 0.9516 - precision: 0.8985 - recall: 0.8699 - val_loss: 0.5389 - val_auc: 0.4746 - val_accuracy: 0.8545 - val_precision: 0.1061 - val_recall: 0.0049 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1320 - auc: 0.9845 - accuracy: 0.9518 - precision: 0.8962 - recall: 0.8734\n",
      "Epoch 15: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1320 - auc: 0.9845 - accuracy: 0.9518 - precision: 0.8962 - recall: 0.8734 - val_loss: 0.5569 - val_auc: 0.5558 - val_accuracy: 0.8522 - val_precision: 0.1344 - val_recall: 0.0098 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1300 - auc: 0.9847 - accuracy: 0.9524 - precision: 0.9029 - recall: 0.8685 \n",
      "Epoch 16: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1300 - auc: 0.9847 - accuracy: 0.9524 - precision: 0.9029 - recall: 0.8685 - val_loss: 0.5656 - val_auc: 0.6882 - val_accuracy: 0.8537 - val_precision: 0.2486 - val_recall: 0.0210 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1281 - auc: 0.9855 - accuracy: 0.9528 - precision: 0.8948 - recall: 0.8805\n",
      "Epoch 17: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1281 - auc: 0.9855 - accuracy: 0.9528 - precision: 0.8948 - recall: 0.8805 - val_loss: 0.5766 - val_auc: 0.5545 - val_accuracy: 0.8540 - val_precision: 0.3176 - val_recall: 0.0349 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1283 - auc: 0.9851 - accuracy: 0.9524 - precision: 0.9006 - recall: 0.8716 \n",
      "Epoch 18: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1283 - auc: 0.9851 - accuracy: 0.9524 - precision: 0.9006 - recall: 0.8716 - val_loss: 0.5542 - val_auc: 0.6107 - val_accuracy: 0.8566 - val_precision: 0.4130 - val_recall: 0.0511 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1260 - auc: 0.9855 - accuracy: 0.9532 - precision: 0.8990 - recall: 0.8776 \n",
      "Epoch 19: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1260 - auc: 0.9855 - accuracy: 0.9532 - precision: 0.8990 - recall: 0.8776 - val_loss: 0.5628 - val_auc: 0.7722 - val_accuracy: 0.8568 - val_precision: 0.4261 - val_recall: 0.0589 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1247 - auc: 0.9859 - accuracy: 0.9535 - precision: 0.9008 - recall: 0.8772 \n",
      "Epoch 20: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1247 - auc: 0.9859 - accuracy: 0.9535 - precision: 0.9008 - recall: 0.8772 - val_loss: 0.5379 - val_auc: 0.7176 - val_accuracy: 0.8605 - val_precision: 0.5176 - val_recall: 0.0932 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1252 - auc: 0.9858 - accuracy: 0.9530 - precision: 0.8999 - recall: 0.8758 \n",
      "Epoch 21: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1252 - auc: 0.9858 - accuracy: 0.9530 - precision: 0.8999 - recall: 0.8758 - val_loss: 0.5093 - val_auc: 0.6971 - val_accuracy: 0.8651 - val_precision: 0.5892 - val_recall: 0.1298 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1231 - auc: 0.9862 - accuracy: 0.9538 - precision: 0.9093 - recall: 0.8685 \n",
      "Epoch 22: val_loss did not improve from 0.40716\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1231 - auc: 0.9862 - accuracy: 0.9538 - precision: 0.9093 - recall: 0.8685 - val_loss: 0.4683 - val_auc: 0.7945 - val_accuracy: 0.8707 - val_precision: 0.6413 - val_recall: 0.1796 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1228 - auc: 0.9864 - accuracy: 0.9536 - precision: 0.9018 - recall: 0.8765\n",
      "Epoch 23: val_loss improved from 0.40716 to 0.37068, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1228 - auc: 0.9864 - accuracy: 0.9536 - precision: 0.9018 - recall: 0.8765 - val_loss: 0.3707 - val_auc: 0.8741 - val_accuracy: 0.8887 - val_precision: 0.7441 - val_recall: 0.3158 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1215 - auc: 0.9867 - accuracy: 0.9540 - precision: 0.8987 - recall: 0.8821\n",
      "Epoch 24: val_loss improved from 0.37068 to 0.35830, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1215 - auc: 0.9867 - accuracy: 0.9540 - precision: 0.8987 - recall: 0.8821 - val_loss: 0.3583 - val_auc: 0.8187 - val_accuracy: 0.8892 - val_precision: 0.7490 - val_recall: 0.3168 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1213 - auc: 0.9866 - accuracy: 0.9541 - precision: 0.9023 - recall: 0.8786 \n",
      "Epoch 25: val_loss improved from 0.35830 to 0.27628, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1213 - auc: 0.9866 - accuracy: 0.9541 - precision: 0.9023 - recall: 0.8786 - val_loss: 0.2763 - val_auc: 0.8926 - val_accuracy: 0.9096 - val_precision: 0.7952 - val_recall: 0.4796 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1200 - auc: 0.9868 - accuracy: 0.9544 - precision: 0.9094 - recall: 0.8719\n",
      "Epoch 26: val_loss improved from 0.27628 to 0.26771, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1200 - auc: 0.9868 - accuracy: 0.9544 - precision: 0.9094 - recall: 0.8719 - val_loss: 0.2677 - val_auc: 0.8963 - val_accuracy: 0.9102 - val_precision: 0.8025 - val_recall: 0.4780 - lr: 6.0653e-04\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1202 - auc: 0.9868 - accuracy: 0.9541 - precision: 0.9004 - recall: 0.8809 \n",
      "Epoch 27: val_loss improved from 0.26771 to 0.21469, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1202 - auc: 0.9868 - accuracy: 0.9541 - precision: 0.9004 - recall: 0.8809 - val_loss: 0.2147 - val_auc: 0.9288 - val_accuracy: 0.9244 - val_precision: 0.8171 - val_recall: 0.5948 - lr: 5.4881e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1188 - auc: 0.9870 - accuracy: 0.9548 - precision: 0.9059 - recall: 0.8777 \n",
      "Epoch 28: val_loss did not improve from 0.21469\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1188 - auc: 0.9870 - accuracy: 0.9548 - precision: 0.9059 - recall: 0.8777 - val_loss: 0.2224 - val_auc: 0.9197 - val_accuracy: 0.9213 - val_precision: 0.8199 - val_recall: 0.5627 - lr: 5.4881e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1212 - auc: 0.9864 - accuracy: 0.9536 - precision: 0.8948 - recall: 0.8852 \n",
      "Epoch 29: val_loss did not improve from 0.21469\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1212 - auc: 0.9864 - accuracy: 0.9536 - precision: 0.8948 - recall: 0.8852 - val_loss: 0.2718 - val_auc: 0.8873 - val_accuracy: 0.9099 - val_precision: 0.8052 - val_recall: 0.4726 - lr: 4.9659e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1218 - auc: 0.9862 - accuracy: 0.9533 - precision: 0.9175 - recall: 0.8565\n",
      "Epoch 30: val_loss improved from 0.21469 to 0.18196, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1218 - auc: 0.9862 - accuracy: 0.9533 - precision: 0.9175 - recall: 0.8565 - val_loss: 0.1820 - val_auc: 0.9548 - val_accuracy: 0.9347 - val_precision: 0.8221 - val_recall: 0.6828 - lr: 4.9659e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1197 - auc: 0.9869 - accuracy: 0.9542 - precision: 0.8955 - recall: 0.8874 \n",
      "Epoch 31: val_loss did not improve from 0.18196\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1197 - auc: 0.9869 - accuracy: 0.9542 - precision: 0.8955 - recall: 0.8874 - val_loss: 0.2513 - val_auc: 0.9111 - val_accuracy: 0.9164 - val_precision: 0.8167 - val_recall: 0.5216 - lr: 4.4933e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1182 - auc: 0.9869 - accuracy: 0.9548 - precision: 0.9105 - recall: 0.8724\n",
      "Epoch 32: val_loss did not improve from 0.18196\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1182 - auc: 0.9869 - accuracy: 0.9548 - precision: 0.9105 - recall: 0.8724 - val_loss: 0.2275 - val_auc: 0.9252 - val_accuracy: 0.9222 - val_precision: 0.8281 - val_recall: 0.5626 - lr: 4.4933e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1169 - auc: 0.9876 - accuracy: 0.9551 - precision: 0.8995 - recall: 0.8869\n",
      "Epoch 33: val_loss did not improve from 0.18196\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1169 - auc: 0.9876 - accuracy: 0.9551 - precision: 0.8995 - recall: 0.8869 - val_loss: 0.2239 - val_auc: 0.9284 - val_accuracy: 0.9215 - val_precision: 0.8259 - val_recall: 0.5582 - lr: 4.0657e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1158 - auc: 0.9876 - accuracy: 0.9556 - precision: 0.9084 - recall: 0.8789 \n",
      "Epoch 34: val_loss did not improve from 0.18196\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1158 - auc: 0.9876 - accuracy: 0.9556 - precision: 0.9084 - recall: 0.8789 - val_loss: 0.2042 - val_auc: 0.9395 - val_accuracy: 0.9266 - val_precision: 0.8314 - val_recall: 0.5982 - lr: 4.0657e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9877 - accuracy: 0.9554 - precision: 0.9086 - recall: 0.8777 \n",
      "Epoch 35: val_loss improved from 0.18196 to 0.16392, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1160 - auc: 0.9877 - accuracy: 0.9554 - precision: 0.9086 - recall: 0.8777 - val_loss: 0.1639 - val_auc: 0.9569 - val_accuracy: 0.9378 - val_precision: 0.8359 - val_recall: 0.6929 - lr: 3.6788e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1170 - auc: 0.9872 - accuracy: 0.9549 - precision: 0.9004 - recall: 0.8851 \n",
      "Epoch 36: val_loss did not improve from 0.16392\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1170 - auc: 0.9872 - accuracy: 0.9549 - precision: 0.9004 - recall: 0.8851 - val_loss: 0.1831 - val_auc: 0.9495 - val_accuracy: 0.9322 - val_precision: 0.8408 - val_recall: 0.6379 - lr: 3.6788e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1160 - auc: 0.9875 - accuracy: 0.9553 - precision: 0.9097 - recall: 0.8757 \n",
      "Epoch 37: val_loss did not improve from 0.16392\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1160 - auc: 0.9875 - accuracy: 0.9553 - precision: 0.9097 - recall: 0.8757 - val_loss: 0.2229 - val_auc: 0.9321 - val_accuracy: 0.9215 - val_precision: 0.8430 - val_recall: 0.5418 - lr: 3.3287e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1148 - auc: 0.9879 - accuracy: 0.9558 - precision: 0.9034 - recall: 0.8859\n",
      "Epoch 38: val_loss did not improve from 0.16392\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1148 - auc: 0.9879 - accuracy: 0.9558 - precision: 0.9034 - recall: 0.8859 - val_loss: 0.2196 - val_auc: 0.9341 - val_accuracy: 0.9229 - val_precision: 0.8438 - val_recall: 0.5529 - lr: 3.3287e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1154 - auc: 0.9876 - accuracy: 0.9555 - precision: 0.9120 - recall: 0.8741 \n",
      "Epoch 39: val_loss did not improve from 0.16392\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1154 - auc: 0.9876 - accuracy: 0.9555 - precision: 0.9120 - recall: 0.8741 - val_loss: 0.1804 - val_auc: 0.9507 - val_accuracy: 0.9338 - val_precision: 0.8480 - val_recall: 0.6439 - lr: 3.0119e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1139 - auc: 0.9880 - accuracy: 0.9559 - precision: 0.9055 - recall: 0.8840 \n",
      "Epoch 40: val_loss improved from 0.16392 to 0.15360, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1139 - auc: 0.9880 - accuracy: 0.9559 - precision: 0.9055 - recall: 0.8840 - val_loss: 0.1536 - val_auc: 0.9636 - val_accuracy: 0.9421 - val_precision: 0.8557 - val_recall: 0.7072 - lr: 3.0119e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1146 - auc: 0.9878 - accuracy: 0.9556 - precision: 0.9103 - recall: 0.8771 \n",
      "Epoch 41: val_loss did not improve from 0.15360\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1146 - auc: 0.9878 - accuracy: 0.9556 - precision: 0.9103 - recall: 0.8771 - val_loss: 0.2022 - val_auc: 0.9387 - val_accuracy: 0.9283 - val_precision: 0.8589 - val_recall: 0.5850 - lr: 2.7253e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1138 - auc: 0.9881 - accuracy: 0.9558 - precision: 0.9014 - recall: 0.8888 \n",
      "Epoch 42: val_loss did not improve from 0.15360\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1138 - auc: 0.9881 - accuracy: 0.9558 - precision: 0.9014 - recall: 0.8888 - val_loss: 0.1917 - val_auc: 0.9430 - val_accuracy: 0.9319 - val_precision: 0.8603 - val_recall: 0.6148 - lr: 2.7253e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1133 - auc: 0.9882 - accuracy: 0.9560 - precision: 0.9104 - recall: 0.8788 \n",
      "Epoch 43: val_loss did not improve from 0.15360\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1133 - auc: 0.9882 - accuracy: 0.9560 - precision: 0.9104 - recall: 0.8788 - val_loss: 0.1879 - val_auc: 0.9434 - val_accuracy: 0.9337 - val_precision: 0.8528 - val_recall: 0.6380 - lr: 2.4660e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1134 - auc: 0.9880 - accuracy: 0.9559 - precision: 0.9042 - recall: 0.8859\n",
      "Epoch 44: val_loss did not improve from 0.15360\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1134 - auc: 0.9880 - accuracy: 0.9559 - precision: 0.9042 - recall: 0.8859 - val_loss: 0.1741 - val_auc: 0.9505 - val_accuracy: 0.9378 - val_precision: 0.8514 - val_recall: 0.6748 - lr: 2.4660e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1131 - auc: 0.9882 - accuracy: 0.9561 - precision: 0.9109 - recall: 0.8787\n",
      "Epoch 45: val_loss did not improve from 0.15360\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1131 - auc: 0.9882 - accuracy: 0.9561 - precision: 0.9109 - recall: 0.8787 - val_loss: 0.1900 - val_auc: 0.9404 - val_accuracy: 0.9335 - val_precision: 0.8453 - val_recall: 0.6443 - lr: 2.2313e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1121 - auc: 0.9884 - accuracy: 0.9564 - precision: 0.9108 - recall: 0.8803\n",
      "Epoch 46: val_loss improved from 0.15360 to 0.15296, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1121 - auc: 0.9884 - accuracy: 0.9564 - precision: 0.9108 - recall: 0.8803 - val_loss: 0.1530 - val_auc: 0.9595 - val_accuracy: 0.9447 - val_precision: 0.8450 - val_recall: 0.7419 - lr: 2.2313e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1139 - auc: 0.9879 - accuracy: 0.9556 - precision: 0.9014 - recall: 0.8877 \n",
      "Epoch 47: val_loss did not improve from 0.15296\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1139 - auc: 0.9879 - accuracy: 0.9556 - precision: 0.9014 - recall: 0.8877 - val_loss: 0.1932 - val_auc: 0.9353 - val_accuracy: 0.9333 - val_precision: 0.8459 - val_recall: 0.6416 - lr: 2.0190e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1124 - auc: 0.9883 - accuracy: 0.9562 - precision: 0.9112 - recall: 0.8790 \n",
      "Epoch 48: val_loss did not improve from 0.15296\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1124 - auc: 0.9883 - accuracy: 0.9562 - precision: 0.9112 - recall: 0.8790 - val_loss: 0.1681 - val_auc: 0.9495 - val_accuracy: 0.9400 - val_precision: 0.8396 - val_recall: 0.7080 - lr: 2.0190e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1112 - auc: 0.9886 - accuracy: 0.9566 - precision: 0.9100 - recall: 0.8825 \n",
      "Epoch 49: val_loss improved from 0.15296 to 0.14932, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1112 - auc: 0.9886 - accuracy: 0.9566 - precision: 0.9100 - recall: 0.8825 - val_loss: 0.1493 - val_auc: 0.9606 - val_accuracy: 0.9460 - val_precision: 0.8383 - val_recall: 0.7626 - lr: 1.8268e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1110 - auc: 0.9887 - accuracy: 0.9567 - precision: 0.9067 - recall: 0.8866\n",
      "Epoch 50: val_loss improved from 0.14932 to 0.14570, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1110 - auc: 0.9887 - accuracy: 0.9567 - precision: 0.9067 - recall: 0.8866 - val_loss: 0.1457 - val_auc: 0.9624 - val_accuracy: 0.9480 - val_precision: 0.8345 - val_recall: 0.7856 - lr: 1.8268e-04\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1114 - auc: 0.9885 - accuracy: 0.9566 - precision: 0.9097 - recall: 0.8825 \n",
      "Epoch 51: val_loss improved from 0.14570 to 0.13703, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1114 - auc: 0.9885 - accuracy: 0.9566 - precision: 0.9097 - recall: 0.8825 - val_loss: 0.1370 - val_auc: 0.9679 - val_accuracy: 0.9512 - val_precision: 0.8332 - val_recall: 0.8160 - lr: 1.6530e-04\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1114 - auc: 0.9886 - accuracy: 0.9565 - precision: 0.9066 - recall: 0.8860 \n",
      "Epoch 52: val_loss improved from 0.13703 to 0.13079, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1114 - auc: 0.9886 - accuracy: 0.9565 - precision: 0.9066 - recall: 0.8860 - val_loss: 0.1308 - val_auc: 0.9748 - val_accuracy: 0.9532 - val_precision: 0.8233 - val_recall: 0.8487 - lr: 1.6530e-04\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1116 - auc: 0.9885 - accuracy: 0.9564 - precision: 0.9103 - recall: 0.8810 \n",
      "Epoch 53: val_loss did not improve from 0.13079\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1116 - auc: 0.9885 - accuracy: 0.9564 - precision: 0.9103 - recall: 0.8810 - val_loss: 0.1321 - val_auc: 0.9740 - val_accuracy: 0.9529 - val_precision: 0.8270 - val_recall: 0.8404 - lr: 1.4957e-04\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1109 - auc: 0.9886 - accuracy: 0.9566 - precision: 0.9082 - recall: 0.8845 \n",
      "Epoch 54: val_loss improved from 0.13079 to 0.12343, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1109 - auc: 0.9886 - accuracy: 0.9566 - precision: 0.9082 - recall: 0.8845 - val_loss: 0.1234 - val_auc: 0.9809 - val_accuracy: 0.9532 - val_precision: 0.7931 - val_recall: 0.9020 - lr: 1.4957e-04\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1105 - auc: 0.9887 - accuracy: 0.9568 - precision: 0.9051 - recall: 0.8895\n",
      "Epoch 55: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1105 - auc: 0.9887 - accuracy: 0.9568 - precision: 0.9051 - recall: 0.8895 - val_loss: 0.1341 - val_auc: 0.9718 - val_accuracy: 0.9525 - val_precision: 0.8296 - val_recall: 0.8326 - lr: 1.3534e-04\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1107 - auc: 0.9887 - accuracy: 0.9567 - precision: 0.9142 - recall: 0.8781 \n",
      "Epoch 56: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1107 - auc: 0.9887 - accuracy: 0.9567 - precision: 0.9142 - recall: 0.8781 - val_loss: 0.1452 - val_auc: 0.9656 - val_accuracy: 0.9497 - val_precision: 0.8311 - val_recall: 0.8050 - lr: 1.3534e-04\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1116 - auc: 0.9884 - accuracy: 0.9563 - precision: 0.9041 - recall: 0.8878 \n",
      "Epoch 57: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 104s 11s/step - loss: 0.1116 - auc: 0.9884 - accuracy: 0.9563 - precision: 0.9041 - recall: 0.8878 - val_loss: 0.1276 - val_auc: 0.9758 - val_accuracy: 0.9538 - val_precision: 0.8160 - val_recall: 0.8666 - lr: 1.2246e-04\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9122 - recall: 0.8813\n",
      "Epoch 58: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9122 - recall: 0.8813 - val_loss: 0.1399 - val_auc: 0.9687 - val_accuracy: 0.9513 - val_precision: 0.8244 - val_recall: 0.8301 - lr: 1.2246e-04\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9085 - recall: 0.8856\n",
      "Epoch 59: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9085 - recall: 0.8856 - val_loss: 0.1424 - val_auc: 0.9669 - val_accuracy: 0.9510 - val_precision: 0.8234 - val_recall: 0.8289 - lr: 1.1080e-04\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1097 - auc: 0.9889 - accuracy: 0.9571 - precision: 0.9105 - recall: 0.8842\n",
      "Epoch 60: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1097 - auc: 0.9889 - accuracy: 0.9571 - precision: 0.9105 - recall: 0.8842 - val_loss: 0.1457 - val_auc: 0.9654 - val_accuracy: 0.9499 - val_precision: 0.8228 - val_recall: 0.8194 - lr: 1.1080e-04\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1104 - auc: 0.9887 - accuracy: 0.9568 - precision: 0.9088 - recall: 0.8847 \n",
      "Epoch 61: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1104 - auc: 0.9887 - accuracy: 0.9568 - precision: 0.9088 - recall: 0.8847 - val_loss: 0.1412 - val_auc: 0.9682 - val_accuracy: 0.9509 - val_precision: 0.8150 - val_recall: 0.8415 - lr: 1.0026e-04\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9568 - precision: 0.9074 - recall: 0.8867\n",
      "Epoch 62: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 104s 11s/step - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9568 - precision: 0.9074 - recall: 0.8867 - val_loss: 0.1393 - val_auc: 0.9694 - val_accuracy: 0.9513 - val_precision: 0.8147 - val_recall: 0.8449 - lr: 1.0026e-04\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1094 - auc: 0.9889 - accuracy: 0.9571 - precision: 0.9113 - recall: 0.8838 \n",
      "Epoch 63: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1094 - auc: 0.9889 - accuracy: 0.9571 - precision: 0.9113 - recall: 0.8838 - val_loss: 0.1332 - val_auc: 0.9735 - val_accuracy: 0.9528 - val_precision: 0.8125 - val_recall: 0.8633 - lr: 9.0718e-05\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1097 - auc: 0.9889 - accuracy: 0.9569 - precision: 0.9111 - recall: 0.8825\n",
      "Epoch 64: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1097 - auc: 0.9889 - accuracy: 0.9569 - precision: 0.9111 - recall: 0.8825 - val_loss: 0.1294 - val_auc: 0.9767 - val_accuracy: 0.9534 - val_precision: 0.8064 - val_recall: 0.8788 - lr: 9.0718e-05\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9568 - precision: 0.9049 - recall: 0.8894\n",
      "Epoch 65: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9568 - precision: 0.9049 - recall: 0.8894 - val_loss: 0.1310 - val_auc: 0.9755 - val_accuracy: 0.9530 - val_precision: 0.8040 - val_recall: 0.8799 - lr: 8.2085e-05\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1100 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9136 - recall: 0.8796 \n",
      "Epoch 66: val_loss did not improve from 0.12343\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1100 - auc: 0.9888 - accuracy: 0.9569 - precision: 0.9136 - recall: 0.8796 - val_loss: 0.1298 - val_auc: 0.9767 - val_accuracy: 0.9537 - val_precision: 0.8053 - val_recall: 0.8840 - lr: 8.2085e-05\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1095 - auc: 0.9889 - accuracy: 0.9570 - precision: 0.9098 - recall: 0.8849\n",
      "Epoch 67: val_loss improved from 0.12343 to 0.12341, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1095 - auc: 0.9889 - accuracy: 0.9570 - precision: 0.9098 - recall: 0.8849 - val_loss: 0.1234 - val_auc: 0.9821 - val_accuracy: 0.9536 - val_precision: 0.7885 - val_recall: 0.9146 - lr: 7.4274e-05\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9572 - precision: 0.9080 - recall: 0.8878 \n",
      "Epoch 68: val_loss did not improve from 0.12341\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9572 - precision: 0.9080 - recall: 0.8878 - val_loss: 0.1236 - val_auc: 0.9824 - val_accuracy: 0.9536 - val_precision: 0.7879 - val_recall: 0.9161 - lr: 7.4274e-05\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1092 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9095 - recall: 0.8856 \n",
      "Epoch 69: val_loss did not improve from 0.12341\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1092 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9095 - recall: 0.8856 - val_loss: 0.1258 - val_auc: 0.9805 - val_accuracy: 0.9537 - val_precision: 0.7928 - val_recall: 0.9069 - lr: 6.7206e-05\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9567 - precision: 0.9108 - recall: 0.8820\n",
      "Epoch 70: val_loss did not improve from 0.12341\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1101 - auc: 0.9888 - accuracy: 0.9567 - precision: 0.9108 - recall: 0.8820 - val_loss: 0.1276 - val_auc: 0.9801 - val_accuracy: 0.9531 - val_precision: 0.7894 - val_recall: 0.9077 - lr: 6.7206e-05\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9087 - recall: 0.8876\n",
      "Epoch 71: val_loss did not improve from 0.12341\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9087 - recall: 0.8876 - val_loss: 0.1243 - val_auc: 0.9840 - val_accuracy: 0.9526 - val_precision: 0.7768 - val_recall: 0.9295 - lr: 6.0810e-05\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1086 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9077 - recall: 0.8887 \n",
      "Epoch 72: val_loss improved from 0.12341 to 0.12320, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1086 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9077 - recall: 0.8887 - val_loss: 0.1232 - val_auc: 0.9837 - val_accuracy: 0.9533 - val_precision: 0.7812 - val_recall: 0.9274 - lr: 6.0810e-05\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1093 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9123 - recall: 0.8823\n",
      "Epoch 73: val_loss did not improve from 0.12320\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1093 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9123 - recall: 0.8823 - val_loss: 0.1237 - val_auc: 0.9834 - val_accuracy: 0.9537 - val_precision: 0.7833 - val_recall: 0.9262 - lr: 5.5023e-05\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9105 - recall: 0.8857\n",
      "Epoch 74: val_loss did not improve from 0.12320\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9105 - recall: 0.8857 - val_loss: 0.1263 - val_auc: 0.9864 - val_accuracy: 0.9521 - val_precision: 0.7665 - val_recall: 0.9477 - lr: 5.5023e-05\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9570 - precision: 0.9095 - recall: 0.8850\n",
      "Epoch 75: val_loss improved from 0.12320 to 0.12257, saving model to pixel_core_fold_13.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9570 - precision: 0.9095 - recall: 0.8850 - val_loss: 0.1226 - val_auc: 0.9851 - val_accuracy: 0.9541 - val_precision: 0.7796 - val_recall: 0.9382 - lr: 4.9787e-05\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9094 - recall: 0.8868 \n",
      "Epoch 76: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9094 - recall: 0.8868 - val_loss: 0.1240 - val_auc: 0.9853 - val_accuracy: 0.9537 - val_precision: 0.7761 - val_recall: 0.9420 - lr: 4.9787e-05\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9081 - recall: 0.8873 \n",
      "Epoch 77: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1091 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9081 - recall: 0.8873 - val_loss: 0.1242 - val_auc: 0.9843 - val_accuracy: 0.9535 - val_precision: 0.7781 - val_recall: 0.9352 - lr: 4.5049e-05\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1090 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9099 - recall: 0.8853 \n",
      "Epoch 78: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1090 - auc: 0.9890 - accuracy: 0.9571 - precision: 0.9099 - recall: 0.8853 - val_loss: 0.1239 - val_auc: 0.9867 - val_accuracy: 0.9538 - val_precision: 0.7744 - val_recall: 0.9465 - lr: 4.5049e-05\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9574 - precision: 0.9133 - recall: 0.8824\n",
      "Epoch 79: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1085 - auc: 0.9892 - accuracy: 0.9574 - precision: 0.9133 - recall: 0.8824 - val_loss: 0.1273 - val_auc: 0.9869 - val_accuracy: 0.9527 - val_precision: 0.7676 - val_recall: 0.9508 - lr: 4.0762e-05\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1083 - auc: 0.9893 - accuracy: 0.9572 - precision: 0.9079 - recall: 0.8883\n",
      "Epoch 80: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1083 - auc: 0.9893 - accuracy: 0.9572 - precision: 0.9079 - recall: 0.8883 - val_loss: 0.1290 - val_auc: 0.9868 - val_accuracy: 0.9516 - val_precision: 0.7617 - val_recall: 0.9532 - lr: 4.0762e-05\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1079 - auc: 0.9894 - accuracy: 0.9575 - precision: 0.9092 - recall: 0.8880\n",
      "Epoch 81: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1079 - auc: 0.9894 - accuracy: 0.9575 - precision: 0.9092 - recall: 0.8880 - val_loss: 0.1262 - val_auc: 0.9867 - val_accuracy: 0.9532 - val_precision: 0.7708 - val_recall: 0.9489 - lr: 3.6883e-05\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1086 - auc: 0.9891 - accuracy: 0.9573 - precision: 0.9118 - recall: 0.8839\n",
      "Epoch 82: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1086 - auc: 0.9891 - accuracy: 0.9573 - precision: 0.9118 - recall: 0.8839 - val_loss: 0.1306 - val_auc: 0.9875 - val_accuracy: 0.9520 - val_precision: 0.7626 - val_recall: 0.9553 - lr: 3.6883e-05\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1078 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9118 - recall: 0.8849 \n",
      "Epoch 83: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1078 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9118 - recall: 0.8849 - val_loss: 0.1354 - val_auc: 0.9881 - val_accuracy: 0.9501 - val_precision: 0.7520 - val_recall: 0.9613 - lr: 3.3373e-05\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9090 - recall: 0.8883 \n",
      "Epoch 84: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9090 - recall: 0.8883 - val_loss: 0.1350 - val_auc: 0.9880 - val_accuracy: 0.9502 - val_precision: 0.7528 - val_recall: 0.9610 - lr: 3.3373e-05\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1081 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9094 - recall: 0.8872\n",
      "Epoch 85: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1081 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9094 - recall: 0.8872 - val_loss: 0.1361 - val_auc: 0.9880 - val_accuracy: 0.9501 - val_precision: 0.7521 - val_recall: 0.9617 - lr: 3.0197e-05\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1094 - auc: 0.9889 - accuracy: 0.9569 - precision: 0.9113 - recall: 0.8827 \n",
      "Epoch 86: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 104s 11s/step - loss: 0.1094 - auc: 0.9889 - accuracy: 0.9569 - precision: 0.9113 - recall: 0.8827 - val_loss: 0.1355 - val_auc: 0.9881 - val_accuracy: 0.9507 - val_precision: 0.7548 - val_recall: 0.9613 - lr: 3.0197e-05\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1080 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9118 - recall: 0.8847 \n",
      "Epoch 87: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1080 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9118 - recall: 0.8847 - val_loss: 0.1391 - val_auc: 0.9882 - val_accuracy: 0.9491 - val_precision: 0.7468 - val_recall: 0.9642 - lr: 2.7324e-05\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1072 - auc: 0.9895 - accuracy: 0.9577 - precision: 0.9099 - recall: 0.8884 \n",
      "Epoch 88: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1072 - auc: 0.9895 - accuracy: 0.9577 - precision: 0.9099 - recall: 0.8884 - val_loss: 0.1391 - val_auc: 0.9882 - val_accuracy: 0.9490 - val_precision: 0.7463 - val_recall: 0.9641 - lr: 2.7324e-05\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9094 - recall: 0.8875 \n",
      "Epoch 89: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9574 - precision: 0.9094 - recall: 0.8875 - val_loss: 0.1377 - val_auc: 0.9883 - val_accuracy: 0.9496 - val_precision: 0.7490 - val_recall: 0.9636 - lr: 2.4724e-05\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1084 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9095 - recall: 0.8867 \n",
      "Epoch 90: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1084 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9095 - recall: 0.8867 - val_loss: 0.1354 - val_auc: 0.9882 - val_accuracy: 0.9506 - val_precision: 0.7543 - val_recall: 0.9616 - lr: 2.4724e-05\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9103 - recall: 0.8866 \n",
      "Epoch 91: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1079 - auc: 0.9893 - accuracy: 0.9575 - precision: 0.9103 - recall: 0.8866 - val_loss: 0.1365 - val_auc: 0.9882 - val_accuracy: 0.9502 - val_precision: 0.7524 - val_recall: 0.9621 - lr: 2.2371e-05\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1074 - auc: 0.9894 - accuracy: 0.9577 - precision: 0.9109 - recall: 0.8869 \n",
      "Epoch 92: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1074 - auc: 0.9894 - accuracy: 0.9577 - precision: 0.9109 - recall: 0.8869 - val_loss: 0.1364 - val_auc: 0.9883 - val_accuracy: 0.9503 - val_precision: 0.7525 - val_recall: 0.9623 - lr: 2.2371e-05\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1083 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9090 - recall: 0.8873 \n",
      "Epoch 93: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1083 - auc: 0.9892 - accuracy: 0.9573 - precision: 0.9090 - recall: 0.8873 - val_loss: 0.1372 - val_auc: 0.9883 - val_accuracy: 0.9500 - val_precision: 0.7512 - val_recall: 0.9631 - lr: 2.0242e-05\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1082 - auc: 0.9892 - accuracy: 0.9574 - precision: 0.9104 - recall: 0.8859 \n",
      "Epoch 94: val_loss did not improve from 0.12257\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1082 - auc: 0.9892 - accuracy: 0.9574 - precision: 0.9104 - recall: 0.8859 - val_loss: 0.1345 - val_auc: 0.9882 - val_accuracy: 0.9513 - val_precision: 0.7573 - val_recall: 0.9606 - lr: 2.0242e-05\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1080 - auc: 0.9892 - accuracy: 0.9575 - precision: 0.9110 - recall: 0.8860 \n",
      "Epoch 95: val_loss did not improve from 0.12257\n",
      "Restoring model weights from the end of the best epoch: 75.\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1080 - auc: 0.9892 - accuracy: 0.9575 - precision: 0.9110 - recall: 0.8860 - val_loss: 0.1365 - val_auc: 0.9883 - val_accuracy: 0.9506 - val_precision: 0.7538 - val_recall: 0.9622 - lr: 1.8316e-05\n",
      "Epoch 95: early stopping\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0890 - auc: 0.9897 - accuracy: 0.9697 - precision: 0.9076 - recall: 0.9038\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4753 - auc: 0.9042 - accuracy: 0.8242 - precision: 0.5585 - recall: 0.8183 \n",
      "Epoch 1: val_loss improved from inf to 0.45869, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 114s 11s/step - loss: 0.4753 - auc: 0.9042 - accuracy: 0.8242 - precision: 0.5585 - recall: 0.8183 - val_loss: 0.4587 - val_auc: 0.6967 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3048 - auc: 0.9704 - accuracy: 0.9282 - precision: 0.7900 - recall: 0.9015 \n",
      "Epoch 2: val_loss improved from 0.45869 to 0.44826, saving model to pixel_core_fold_14.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.3048 - auc: 0.9704 - accuracy: 0.9282 - precision: 0.7900 - recall: 0.9015 - val_loss: 0.4483 - val_auc: 0.5968 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2521 - auc: 0.9750 - accuracy: 0.9446 - precision: 0.8621 - recall: 0.8798 \n",
      "Epoch 3: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 109s 10s/step - loss: 0.2521 - auc: 0.9750 - accuracy: 0.9446 - precision: 0.8621 - recall: 0.8798 - val_loss: 0.4492 - val_auc: 0.7700 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2247 - auc: 0.9754 - accuracy: 0.9474 - precision: 0.8775 - recall: 0.8740 \n",
      "Epoch 4: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.2247 - auc: 0.9754 - accuracy: 0.9474 - precision: 0.8775 - recall: 0.8740 - val_loss: 0.5350 - val_auc: 0.8057 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2055 - auc: 0.9777 - accuracy: 0.9490 - precision: 0.8820 - recall: 0.8770 \n",
      "Epoch 5: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2055 - auc: 0.9777 - accuracy: 0.9490 - precision: 0.8820 - recall: 0.8770 - val_loss: 0.4779 - val_auc: 0.3280 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1939 - auc: 0.9788 - accuracy: 0.9495 - precision: 0.8831 - recall: 0.8782 \n",
      "Epoch 6: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1939 - auc: 0.9788 - accuracy: 0.9495 - precision: 0.8831 - recall: 0.8782 - val_loss: 0.4575 - val_auc: 0.1921 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1852 - auc: 0.9802 - accuracy: 0.9500 - precision: 0.8853 - recall: 0.8782 \n",
      "Epoch 7: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1852 - auc: 0.9802 - accuracy: 0.9500 - precision: 0.8853 - recall: 0.8782 - val_loss: 0.4567 - val_auc: 0.1389 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1757 - auc: 0.9817 - accuracy: 0.9517 - precision: 0.8938 - recall: 0.8766 \n",
      "Epoch 8: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1757 - auc: 0.9817 - accuracy: 0.9517 - precision: 0.8938 - recall: 0.8766 - val_loss: 0.4723 - val_auc: 0.2474 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1706 - auc: 0.9818 - accuracy: 0.9515 - precision: 0.8927 - recall: 0.8771\n",
      "Epoch 9: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1706 - auc: 0.9818 - accuracy: 0.9515 - precision: 0.8927 - recall: 0.8771 - val_loss: 0.4911 - val_auc: 0.3847 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1645 - auc: 0.9835 - accuracy: 0.9521 - precision: 0.8882 - recall: 0.8861 \n",
      "Epoch 10: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1645 - auc: 0.9835 - accuracy: 0.9521 - precision: 0.8882 - recall: 0.8861 - val_loss: 0.5104 - val_auc: 0.4346 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1609 - auc: 0.9833 - accuracy: 0.9521 - precision: 0.8929 - recall: 0.8798 \n",
      "Epoch 11: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1609 - auc: 0.9833 - accuracy: 0.9521 - precision: 0.8929 - recall: 0.8798 - val_loss: 0.5097 - val_auc: 0.4424 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1568 - auc: 0.9834 - accuracy: 0.9525 - precision: 0.8958 - recall: 0.8784\n",
      "Epoch 12: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1568 - auc: 0.9834 - accuracy: 0.9525 - precision: 0.8958 - recall: 0.8784 - val_loss: 0.5180 - val_auc: 0.4553 - val_accuracy: 0.8361 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1519 - auc: 0.9844 - accuracy: 0.9533 - precision: 0.8957 - recall: 0.8829\n",
      "Epoch 13: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.1519 - auc: 0.9844 - accuracy: 0.9533 - precision: 0.8957 - recall: 0.8829 - val_loss: 0.5215 - val_auc: 0.6513 - val_accuracy: 0.8361 - val_precision: 1.0000 - val_recall: 2.3280e-05 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1482 - auc: 0.9852 - accuracy: 0.9534 - precision: 0.8930 - recall: 0.8867\n",
      "Epoch 14: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1482 - auc: 0.9852 - accuracy: 0.9534 - precision: 0.8930 - recall: 0.8867 - val_loss: 0.5250 - val_auc: 0.6915 - val_accuracy: 0.8363 - val_precision: 1.0000 - val_recall: 9.5449e-04 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1457 - auc: 0.9851 - accuracy: 0.9538 - precision: 0.8995 - recall: 0.8810\n",
      "Epoch 15: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1457 - auc: 0.9851 - accuracy: 0.9538 - precision: 0.8995 - recall: 0.8810 - val_loss: 0.5309 - val_auc: 0.8673 - val_accuracy: 0.8364 - val_precision: 0.9487 - val_recall: 0.0017 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1434 - auc: 0.9844 - accuracy: 0.9537 - precision: 0.8961 - recall: 0.8845\n",
      "Epoch 16: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 99s 9s/step - loss: 0.1434 - auc: 0.9844 - accuracy: 0.9537 - precision: 0.8961 - recall: 0.8845 - val_loss: 0.5547 - val_auc: 0.7928 - val_accuracy: 0.8365 - val_precision: 0.8468 - val_recall: 0.0023 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1407 - auc: 0.9851 - accuracy: 0.9540 - precision: 0.8984 - recall: 0.8833\n",
      "Epoch 17: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1407 - auc: 0.9851 - accuracy: 0.9540 - precision: 0.8984 - recall: 0.8833 - val_loss: 0.5566 - val_auc: 0.8366 - val_accuracy: 0.8373 - val_precision: 0.9166 - val_recall: 0.0081 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1380 - auc: 0.9859 - accuracy: 0.9544 - precision: 0.8979 - recall: 0.8860\n",
      "Epoch 18: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1380 - auc: 0.9859 - accuracy: 0.9544 - precision: 0.8979 - recall: 0.8860 - val_loss: 0.5599 - val_auc: 0.8140 - val_accuracy: 0.8373 - val_precision: 0.8988 - val_recall: 0.0080 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1352 - auc: 0.9861 - accuracy: 0.9550 - precision: 0.9006 - recall: 0.8859\n",
      "Epoch 19: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 93s 9s/step - loss: 0.1352 - auc: 0.9861 - accuracy: 0.9550 - precision: 0.9006 - recall: 0.8859 - val_loss: 0.5484 - val_auc: 0.8676 - val_accuracy: 0.8395 - val_precision: 0.8823 - val_recall: 0.0240 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1351 - auc: 0.9856 - accuracy: 0.9547 - precision: 0.9021 - recall: 0.8822 \n",
      "Epoch 20: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1351 - auc: 0.9856 - accuracy: 0.9547 - precision: 0.9021 - recall: 0.8822 - val_loss: 0.5550 - val_auc: 0.8519 - val_accuracy: 0.8385 - val_precision: 0.8782 - val_recall: 0.0170 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1326 - auc: 0.9861 - accuracy: 0.9550 - precision: 0.8997 - recall: 0.8867\n",
      "Epoch 21: val_loss did not improve from 0.44826\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1326 - auc: 0.9861 - accuracy: 0.9550 - precision: 0.8997 - recall: 0.8867 - val_loss: 0.5525 - val_auc: 0.8826 - val_accuracy: 0.8389 - val_precision: 0.8678 - val_recall: 0.0200 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1306 - auc: 0.9867 - accuracy: 0.9553 - precision: 0.8978 - recall: 0.8905\n",
      "Epoch 22: val_loss did not improve from 0.44826\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1306 - auc: 0.9867 - accuracy: 0.9553 - precision: 0.8978 - recall: 0.8905 - val_loss: 0.5663 - val_auc: 0.8858 - val_accuracy: 0.8375 - val_precision: 0.8583 - val_recall: 0.0102 - lr: 7.4082e-04\n",
      "Epoch 22: early stopping\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3569 - auc: 0.4652 - accuracy: 0.8913 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5769 - auc: 0.8490 - accuracy: 0.8124 - precision: 0.5357 - recall: 0.7793 \n",
      "Epoch 1: val_loss improved from inf to 0.57629, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.5769 - auc: 0.8490 - accuracy: 0.8124 - precision: 0.5357 - recall: 0.7793 - val_loss: 0.5763 - val_auc: 0.6756 - val_accuracy: 0.8424 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3499 - auc: 0.9697 - accuracy: 0.9259 - precision: 0.7793 - recall: 0.9009 \n",
      "Epoch 2: val_loss improved from 0.57629 to 0.49502, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.3499 - auc: 0.9697 - accuracy: 0.9259 - precision: 0.7793 - recall: 0.9009 - val_loss: 0.4950 - val_auc: 0.8481 - val_accuracy: 0.8386 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2865 - auc: 0.9759 - accuracy: 0.9399 - precision: 0.8228 - recall: 0.9084 \n",
      "Epoch 3: val_loss improved from 0.49502 to 0.40579, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2865 - auc: 0.9759 - accuracy: 0.9399 - precision: 0.8228 - recall: 0.9084 - val_loss: 0.4058 - val_auc: 0.9054 - val_accuracy: 0.8437 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2436 - auc: 0.9791 - accuracy: 0.9449 - precision: 0.8497 - recall: 0.8951\n",
      "Epoch 4: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2436 - auc: 0.9791 - accuracy: 0.9449 - precision: 0.8497 - recall: 0.8951 - val_loss: 1.3853 - val_auc: 0.4896 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2161 - auc: 0.9803 - accuracy: 0.9491 - precision: 0.8786 - recall: 0.8783 \n",
      "Epoch 5: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.2161 - auc: 0.9803 - accuracy: 0.9491 - precision: 0.8786 - recall: 0.8783 - val_loss: 2.5936 - val_auc: 0.4965 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1968 - auc: 0.9807 - accuracy: 0.9502 - precision: 0.8877 - recall: 0.8725\n",
      "Epoch 6: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.1968 - auc: 0.9807 - accuracy: 0.9502 - precision: 0.8877 - recall: 0.8725 - val_loss: 2.3373 - val_auc: 0.4965 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1873 - auc: 0.9808 - accuracy: 0.9505 - precision: 0.8924 - recall: 0.8682\n",
      "Epoch 7: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1873 - auc: 0.9808 - accuracy: 0.9505 - precision: 0.8924 - recall: 0.8682 - val_loss: 1.4909 - val_auc: 0.4921 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1798 - auc: 0.9816 - accuracy: 0.9513 - precision: 0.8982 - recall: 0.8652\n",
      "Epoch 8: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1798 - auc: 0.9816 - accuracy: 0.9513 - precision: 0.8982 - recall: 0.8652 - val_loss: 1.1485 - val_auc: 0.4857 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1753 - auc: 0.9821 - accuracy: 0.9507 - precision: 0.8877 - recall: 0.8753 \n",
      "Epoch 9: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1753 - auc: 0.9821 - accuracy: 0.9507 - precision: 0.8877 - recall: 0.8753 - val_loss: 0.8503 - val_auc: 0.5714 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1699 - auc: 0.9823 - accuracy: 0.9516 - precision: 0.8944 - recall: 0.8715 \n",
      "Epoch 10: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1699 - auc: 0.9823 - accuracy: 0.9516 - precision: 0.8944 - recall: 0.8715 - val_loss: 0.5900 - val_auc: 0.8062 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1644 - auc: 0.9826 - accuracy: 0.9522 - precision: 0.8910 - recall: 0.8791 \n",
      "Epoch 11: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1644 - auc: 0.9826 - accuracy: 0.9522 - precision: 0.8910 - recall: 0.8791 - val_loss: 0.4324 - val_auc: 0.8870 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1604 - auc: 0.9833 - accuracy: 0.9523 - precision: 0.8917 - recall: 0.8788 \n",
      "Epoch 12: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1604 - auc: 0.9833 - accuracy: 0.9523 - precision: 0.8917 - recall: 0.8788 - val_loss: 0.4488 - val_auc: 0.9066 - val_accuracy: 0.8443 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1571 - auc: 0.9830 - accuracy: 0.9530 - precision: 0.8970 - recall: 0.8758 \n",
      "Epoch 13: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1571 - auc: 0.9830 - accuracy: 0.9530 - precision: 0.8970 - recall: 0.8758 - val_loss: 0.4188 - val_auc: 0.9347 - val_accuracy: 0.8443 - val_precision: 1.0000 - val_recall: 2.0827e-04 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1527 - auc: 0.9843 - accuracy: 0.9530 - precision: 0.8901 - recall: 0.8848 \n",
      "Epoch 14: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1527 - auc: 0.9843 - accuracy: 0.9530 - precision: 0.8901 - recall: 0.8848 - val_loss: 0.4305 - val_auc: 0.8920 - val_accuracy: 0.8445 - val_precision: 1.0000 - val_recall: 0.0011 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1517 - auc: 0.9824 - accuracy: 0.9529 - precision: 0.8946 - recall: 0.8787 \n",
      "Epoch 15: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1517 - auc: 0.9824 - accuracy: 0.9529 - precision: 0.8946 - recall: 0.8787 - val_loss: 0.4355 - val_auc: 0.9278 - val_accuracy: 0.8447 - val_precision: 0.7686 - val_recall: 0.0035 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1473 - auc: 0.9841 - accuracy: 0.9537 - precision: 0.8942 - recall: 0.8833 \n",
      "Epoch 16: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1473 - auc: 0.9841 - accuracy: 0.9537 - precision: 0.8942 - recall: 0.8833 - val_loss: 0.4494 - val_auc: 0.9207 - val_accuracy: 0.8447 - val_precision: 0.7101 - val_recall: 0.0044 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1437 - auc: 0.9851 - accuracy: 0.9541 - precision: 0.8949 - recall: 0.8843\n",
      "Epoch 17: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 104s 11s/step - loss: 0.1437 - auc: 0.9851 - accuracy: 0.9541 - precision: 0.8949 - recall: 0.8843 - val_loss: 0.4897 - val_auc: 0.5480 - val_accuracy: 0.8456 - val_precision: 0.6306 - val_recall: 0.0195 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1413 - auc: 0.9844 - accuracy: 0.9545 - precision: 0.8939 - recall: 0.8879 \n",
      "Epoch 18: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1413 - auc: 0.9844 - accuracy: 0.9545 - precision: 0.8939 - recall: 0.8879 - val_loss: 0.4984 - val_auc: 0.5397 - val_accuracy: 0.8469 - val_precision: 0.6659 - val_recall: 0.0328 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1397 - auc: 0.9840 - accuracy: 0.9546 - precision: 0.8975 - recall: 0.8839 \n",
      "Epoch 19: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1397 - auc: 0.9840 - accuracy: 0.9546 - precision: 0.8975 - recall: 0.8839 - val_loss: 0.4760 - val_auc: 0.7860 - val_accuracy: 0.8507 - val_precision: 0.7056 - val_recall: 0.0701 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1368 - auc: 0.9859 - accuracy: 0.9551 - precision: 0.8955 - recall: 0.8889 \n",
      "Epoch 20: val_loss did not improve from 0.40579\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1368 - auc: 0.9859 - accuracy: 0.9551 - precision: 0.8955 - recall: 0.8889 - val_loss: 0.4600 - val_auc: 0.8055 - val_accuracy: 0.8518 - val_precision: 0.7010 - val_recall: 0.0833 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1346 - auc: 0.9857 - accuracy: 0.9556 - precision: 0.9001 - recall: 0.8864 \n",
      "Epoch 21: val_loss improved from 0.40579 to 0.40530, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 104s 11s/step - loss: 0.1346 - auc: 0.9857 - accuracy: 0.9556 - precision: 0.9001 - recall: 0.8864 - val_loss: 0.4053 - val_auc: 0.7785 - val_accuracy: 0.8627 - val_precision: 0.7705 - val_recall: 0.1687 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1334 - auc: 0.9861 - accuracy: 0.9553 - precision: 0.8935 - recall: 0.8929 \n",
      "Epoch 22: val_loss improved from 0.40530 to 0.31535, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1334 - auc: 0.9861 - accuracy: 0.9553 - precision: 0.8935 - recall: 0.8929 - val_loss: 0.3153 - val_auc: 0.8901 - val_accuracy: 0.8813 - val_precision: 0.8192 - val_recall: 0.3044 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1324 - auc: 0.9860 - accuracy: 0.9556 - precision: 0.9038 - recall: 0.8819 \n",
      "Epoch 23: val_loss improved from 0.31535 to 0.29333, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1324 - auc: 0.9860 - accuracy: 0.9556 - precision: 0.9038 - recall: 0.8819 - val_loss: 0.2933 - val_auc: 0.9093 - val_accuracy: 0.8879 - val_precision: 0.8315 - val_recall: 0.3516 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1312 - auc: 0.9866 - accuracy: 0.9555 - precision: 0.8980 - recall: 0.8884 \n",
      "Epoch 24: val_loss improved from 0.29333 to 0.28384, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1312 - auc: 0.9866 - accuracy: 0.9555 - precision: 0.8980 - recall: 0.8884 - val_loss: 0.2838 - val_auc: 0.9186 - val_accuracy: 0.8919 - val_precision: 0.8328 - val_recall: 0.3823 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1291 - auc: 0.9866 - accuracy: 0.9561 - precision: 0.8978 - recall: 0.8916 \n",
      "Epoch 25: val_loss improved from 0.28384 to 0.25944, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1291 - auc: 0.9866 - accuracy: 0.9561 - precision: 0.8978 - recall: 0.8916 - val_loss: 0.2594 - val_auc: 0.9289 - val_accuracy: 0.8992 - val_precision: 0.8331 - val_recall: 0.4406 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1284 - auc: 0.9868 - accuracy: 0.9560 - precision: 0.8995 - recall: 0.8893 \n",
      "Epoch 26: val_loss improved from 0.25944 to 0.21644, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1284 - auc: 0.9868 - accuracy: 0.9560 - precision: 0.8995 - recall: 0.8893 - val_loss: 0.2164 - val_auc: 0.9441 - val_accuracy: 0.9208 - val_precision: 0.8546 - val_recall: 0.5919 - lr: 6.0653e-04\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1266 - auc: 0.9869 - accuracy: 0.9566 - precision: 0.9048 - recall: 0.8859\n",
      "Epoch 27: val_loss improved from 0.21644 to 0.19612, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 97s 10s/step - loss: 0.1266 - auc: 0.9869 - accuracy: 0.9566 - precision: 0.9048 - recall: 0.8859 - val_loss: 0.1961 - val_auc: 0.9540 - val_accuracy: 0.9332 - val_precision: 0.8476 - val_recall: 0.6962 - lr: 5.4881e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1258 - auc: 0.9873 - accuracy: 0.9567 - precision: 0.9048 - recall: 0.8861 \n",
      "Epoch 28: val_loss improved from 0.19612 to 0.18425, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1258 - auc: 0.9873 - accuracy: 0.9567 - precision: 0.9048 - recall: 0.8861 - val_loss: 0.1842 - val_auc: 0.9574 - val_accuracy: 0.9380 - val_precision: 0.8444 - val_recall: 0.7373 - lr: 5.4881e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1252 - auc: 0.9874 - accuracy: 0.9564 - precision: 0.8985 - recall: 0.8927 \n",
      "Epoch 29: val_loss improved from 0.18425 to 0.16666, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1252 - auc: 0.9874 - accuracy: 0.9564 - precision: 0.8985 - recall: 0.8927 - val_loss: 0.1667 - val_auc: 0.9719 - val_accuracy: 0.9454 - val_precision: 0.7909 - val_recall: 0.8825 - lr: 4.9659e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1243 - auc: 0.9875 - accuracy: 0.9567 - precision: 0.9012 - recall: 0.8909\n",
      "Epoch 30: val_loss improved from 0.16666 to 0.16259, saving model to pixel_core_fold_15.hdf5\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1243 - auc: 0.9875 - accuracy: 0.9567 - precision: 0.9012 - recall: 0.8909 - val_loss: 0.1626 - val_auc: 0.9678 - val_accuracy: 0.9475 - val_precision: 0.8250 - val_recall: 0.8415 - lr: 4.9659e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1233 - auc: 0.9876 - accuracy: 0.9570 - precision: 0.9057 - recall: 0.8868\n",
      "Epoch 31: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.1233 - auc: 0.9876 - accuracy: 0.9570 - precision: 0.9057 - recall: 0.8868 - val_loss: 0.1753 - val_auc: 0.9800 - val_accuracy: 0.9384 - val_precision: 0.7366 - val_recall: 0.9411 - lr: 4.4933e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1222 - auc: 0.9878 - accuracy: 0.9572 - precision: 0.9025 - recall: 0.8916 \n",
      "Epoch 32: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1222 - auc: 0.9878 - accuracy: 0.9572 - precision: 0.9025 - recall: 0.8916 - val_loss: 0.2231 - val_auc: 0.9834 - val_accuracy: 0.9073 - val_precision: 0.6315 - val_recall: 0.9721 - lr: 4.4933e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1229 - auc: 0.9874 - accuracy: 0.9567 - precision: 0.9056 - recall: 0.8855\n",
      "Epoch 33: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1229 - auc: 0.9874 - accuracy: 0.9567 - precision: 0.9056 - recall: 0.8855 - val_loss: 0.2397 - val_auc: 0.9835 - val_accuracy: 0.8969 - val_precision: 0.6048 - val_recall: 0.9745 - lr: 4.0657e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1224 - auc: 0.9876 - accuracy: 0.9567 - precision: 0.9034 - recall: 0.8880\n",
      "Epoch 34: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1224 - auc: 0.9876 - accuracy: 0.9567 - precision: 0.9034 - recall: 0.8880 - val_loss: 0.2545 - val_auc: 0.9851 - val_accuracy: 0.8914 - val_precision: 0.5913 - val_recall: 0.9803 - lr: 4.0657e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1214 - auc: 0.9873 - accuracy: 0.9570 - precision: 0.8983 - recall: 0.8957 \n",
      "Epoch 35: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1214 - auc: 0.9873 - accuracy: 0.9570 - precision: 0.8983 - recall: 0.8957 - val_loss: 0.3369 - val_auc: 0.9874 - val_accuracy: 0.8457 - val_precision: 0.5023 - val_recall: 0.9921 - lr: 3.6788e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1213 - auc: 0.9877 - accuracy: 0.9570 - precision: 0.9022 - recall: 0.8912 \n",
      "Epoch 36: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1213 - auc: 0.9877 - accuracy: 0.9570 - precision: 0.9022 - recall: 0.8912 - val_loss: 0.3965 - val_auc: 0.9882 - val_accuracy: 0.8145 - val_precision: 0.4561 - val_recall: 0.9937 - lr: 3.6788e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1201 - auc: 0.9877 - accuracy: 0.9575 - precision: 0.9073 - recall: 0.8877 \n",
      "Epoch 37: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1201 - auc: 0.9877 - accuracy: 0.9575 - precision: 0.9073 - recall: 0.8877 - val_loss: 0.3246 - val_auc: 0.9867 - val_accuracy: 0.8559 - val_precision: 0.5195 - val_recall: 0.9902 - lr: 3.3287e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1197 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9043 - recall: 0.8911 \n",
      "Epoch 38: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1197 - auc: 0.9879 - accuracy: 0.9575 - precision: 0.9043 - recall: 0.8911 - val_loss: 0.5449 - val_auc: 0.9903 - val_accuracy: 0.7034 - val_precision: 0.3440 - val_recall: 0.9979 - lr: 3.3287e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1187 - auc: 0.9881 - accuracy: 0.9579 - precision: 0.9073 - recall: 0.8896 \n",
      "Epoch 39: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1187 - auc: 0.9881 - accuracy: 0.9579 - precision: 0.9073 - recall: 0.8896 - val_loss: 0.4167 - val_auc: 0.9891 - val_accuracy: 0.8084 - val_precision: 0.4481 - val_recall: 0.9944 - lr: 3.0119e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1184 - auc: 0.9881 - accuracy: 0.9578 - precision: 0.9079 - recall: 0.8886\n",
      "Epoch 40: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1184 - auc: 0.9881 - accuracy: 0.9578 - precision: 0.9079 - recall: 0.8886 - val_loss: 0.6053 - val_auc: 0.9901 - val_accuracy: 0.6766 - val_precision: 0.3248 - val_recall: 0.9984 - lr: 3.0119e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1179 - auc: 0.9883 - accuracy: 0.9578 - precision: 0.9003 - recall: 0.8976\n",
      "Epoch 41: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1179 - auc: 0.9883 - accuracy: 0.9578 - precision: 0.9003 - recall: 0.8976 - val_loss: 0.5580 - val_auc: 0.9900 - val_accuracy: 0.7095 - val_precision: 0.3487 - val_recall: 0.9975 - lr: 2.7253e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1176 - auc: 0.9884 - accuracy: 0.9581 - precision: 0.9126 - recall: 0.8844 \n",
      "Epoch 42: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1176 - auc: 0.9884 - accuracy: 0.9581 - precision: 0.9126 - recall: 0.8844 - val_loss: 0.4615 - val_auc: 0.9899 - val_accuracy: 0.7872 - val_precision: 0.4222 - val_recall: 0.9953 - lr: 2.7253e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1178 - auc: 0.9880 - accuracy: 0.9578 - precision: 0.9023 - recall: 0.8952 \n",
      "Epoch 43: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1178 - auc: 0.9880 - accuracy: 0.9578 - precision: 0.9023 - recall: 0.8952 - val_loss: 0.7279 - val_auc: 0.9908 - val_accuracy: 0.5620 - val_precision: 0.2622 - val_recall: 0.9993 - lr: 2.4660e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1174 - auc: 0.9884 - accuracy: 0.9579 - precision: 0.9066 - recall: 0.8906 \n",
      "Epoch 44: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.1174 - auc: 0.9884 - accuracy: 0.9579 - precision: 0.9066 - recall: 0.8906 - val_loss: 0.6968 - val_auc: 0.9913 - val_accuracy: 0.5690 - val_precision: 0.2653 - val_recall: 0.9993 - lr: 2.4660e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1176 - auc: 0.9879 - accuracy: 0.9578 - precision: 0.9077 - recall: 0.8890 \n",
      "Epoch 45: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1176 - auc: 0.9879 - accuracy: 0.9578 - precision: 0.9077 - recall: 0.8890 - val_loss: 0.4465 - val_auc: 0.9895 - val_accuracy: 0.8014 - val_precision: 0.4392 - val_recall: 0.9946 - lr: 2.2313e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1165 - auc: 0.9885 - accuracy: 0.9580 - precision: 0.9052 - recall: 0.8930 \n",
      "Epoch 46: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1165 - auc: 0.9885 - accuracy: 0.9580 - precision: 0.9052 - recall: 0.8930 - val_loss: 0.4241 - val_auc: 0.9899 - val_accuracy: 0.8084 - val_precision: 0.4480 - val_recall: 0.9944 - lr: 2.2313e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1162 - auc: 0.9885 - accuracy: 0.9581 - precision: 0.9066 - recall: 0.8915 \n",
      "Epoch 47: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.1162 - auc: 0.9885 - accuracy: 0.9581 - precision: 0.9066 - recall: 0.8915 - val_loss: 0.5450 - val_auc: 0.9911 - val_accuracy: 0.7229 - val_precision: 0.3595 - val_recall: 0.9977 - lr: 2.0190e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1163 - auc: 0.9884 - accuracy: 0.9580 - precision: 0.9057 - recall: 0.8924\n",
      "Epoch 48: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1163 - auc: 0.9884 - accuracy: 0.9580 - precision: 0.9057 - recall: 0.8924 - val_loss: 0.3073 - val_auc: 0.9892 - val_accuracy: 0.8654 - val_precision: 0.5367 - val_recall: 0.9917 - lr: 2.0190e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1159 - auc: 0.9884 - accuracy: 0.9582 - precision: 0.9080 - recall: 0.8907 \n",
      "Epoch 49: val_loss did not improve from 0.16259\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1159 - auc: 0.9884 - accuracy: 0.9582 - precision: 0.9080 - recall: 0.8907 - val_loss: 0.2699 - val_auc: 0.9891 - val_accuracy: 0.8843 - val_precision: 0.5745 - val_recall: 0.9897 - lr: 1.8268e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1151 - auc: 0.9887 - accuracy: 0.9584 - precision: 0.9065 - recall: 0.8933\n",
      "Epoch 50: val_loss did not improve from 0.16259\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.1151 - auc: 0.9887 - accuracy: 0.9584 - precision: 0.9065 - recall: 0.8933 - val_loss: 0.2834 - val_auc: 0.9894 - val_accuracy: 0.8783 - val_precision: 0.5619 - val_recall: 0.9910 - lr: 1.8268e-04\n",
      "Epoch 50: early stopping\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2336 - auc: 0.9453 - accuracy: 0.9235 - precision: 0.7750 - recall: 0.7823\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6717 - auc: 0.8340 - accuracy: 0.6583 - precision: 0.3714 - recall: 0.9051 \n",
      "Epoch 1: val_loss improved from inf to 1.66193, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.6717 - auc: 0.8340 - accuracy: 0.6583 - precision: 0.3714 - recall: 0.9051 - val_loss: 1.6619 - val_auc: 0.5537 - val_accuracy: 0.1691 - val_precision: 0.1593 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4478 - auc: 0.9578 - accuracy: 0.8820 - precision: 0.6588 - recall: 0.9093 \n",
      "Epoch 2: val_loss did not improve from 1.66193\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.4478 - auc: 0.9578 - accuracy: 0.8820 - precision: 0.6588 - recall: 0.9093 - val_loss: 2.0784 - val_auc: 0.5947 - val_accuracy: 0.1691 - val_precision: 0.1593 - val_recall: 1.0000 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3751 - auc: 0.9675 - accuracy: 0.9330 - precision: 0.8104 - recall: 0.8892\n",
      "Epoch 3: val_loss improved from 1.66193 to 0.87568, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.3751 - auc: 0.9675 - accuracy: 0.9330 - precision: 0.8104 - recall: 0.8892 - val_loss: 0.8757 - val_auc: 0.6885 - val_accuracy: 0.1806 - val_precision: 0.1611 - val_recall: 0.9999 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3340 - auc: 0.9676 - accuracy: 0.9423 - precision: 0.8550 - recall: 0.8734\n",
      "Epoch 4: val_loss improved from 0.87568 to 0.49325, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.3340 - auc: 0.9676 - accuracy: 0.9423 - precision: 0.8550 - recall: 0.8734 - val_loss: 0.4932 - val_auc: 0.8648 - val_accuracy: 0.8413 - val_precision: 0.2580 - val_recall: 0.0043 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3025 - auc: 0.9690 - accuracy: 0.9434 - precision: 0.8587 - recall: 0.8744\n",
      "Epoch 5: val_loss improved from 0.49325 to 0.41724, saving model to pixel_core_fold_16.hdf5\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.3025 - auc: 0.9690 - accuracy: 0.9434 - precision: 0.8587 - recall: 0.8744 - val_loss: 0.4172 - val_auc: 0.8713 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2796 - auc: 0.9740 - accuracy: 0.9450 - precision: 0.8634 - recall: 0.8771 \n",
      "Epoch 6: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2796 - auc: 0.9740 - accuracy: 0.9450 - precision: 0.8634 - recall: 0.8771 - val_loss: 0.4235 - val_auc: 0.8848 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2618 - auc: 0.9767 - accuracy: 0.9475 - precision: 0.8766 - recall: 0.8731 \n",
      "Epoch 7: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.2618 - auc: 0.9767 - accuracy: 0.9475 - precision: 0.8766 - recall: 0.8731 - val_loss: 0.4253 - val_auc: 0.8839 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2467 - auc: 0.9781 - accuracy: 0.9489 - precision: 0.8793 - recall: 0.8769 \n",
      "Epoch 8: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.2467 - auc: 0.9781 - accuracy: 0.9489 - precision: 0.8793 - recall: 0.8769 - val_loss: 0.4324 - val_auc: 0.8357 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2347 - auc: 0.9785 - accuracy: 0.9496 - precision: 0.8819 - recall: 0.8777\n",
      "Epoch 9: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2347 - auc: 0.9785 - accuracy: 0.9496 - precision: 0.8819 - recall: 0.8777 - val_loss: 0.4431 - val_auc: 0.5032 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2240 - auc: 0.9798 - accuracy: 0.9499 - precision: 0.8787 - recall: 0.8836\n",
      "Epoch 10: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 98s 10s/step - loss: 0.2240 - auc: 0.9798 - accuracy: 0.9499 - precision: 0.8787 - recall: 0.8836 - val_loss: 0.4418 - val_auc: 0.5677 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2147 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8910 - recall: 0.8729 \n",
      "Epoch 11: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2147 - auc: 0.9805 - accuracy: 0.9509 - precision: 0.8910 - recall: 0.8729 - val_loss: 0.4428 - val_auc: 0.4384 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2084 - auc: 0.9785 - accuracy: 0.9505 - precision: 0.8902 - recall: 0.8721\n",
      "Epoch 12: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.2084 - auc: 0.9785 - accuracy: 0.9505 - precision: 0.8902 - recall: 0.8721 - val_loss: 0.4438 - val_auc: 0.4202 - val_accuracy: 0.8426 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2019 - auc: 0.9786 - accuracy: 0.9508 - precision: 0.8932 - recall: 0.8697\n",
      "Epoch 13: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.2019 - auc: 0.9786 - accuracy: 0.9508 - precision: 0.8932 - recall: 0.8697 - val_loss: 0.4502 - val_auc: 0.2990 - val_accuracy: 0.8428 - val_precision: 1.0000 - val_recall: 0.0013 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1939 - auc: 0.9824 - accuracy: 0.9515 - precision: 0.8819 - recall: 0.8881\n",
      "Epoch 14: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.1939 - auc: 0.9824 - accuracy: 0.9515 - precision: 0.8819 - recall: 0.8881 - val_loss: 0.4664 - val_auc: 0.1260 - val_accuracy: 0.8430 - val_precision: 1.0000 - val_recall: 0.0024 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1871 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8934 - recall: 0.8809\n",
      "Epoch 15: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1871 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8934 - recall: 0.8809 - val_loss: 0.4695 - val_auc: 0.1348 - val_accuracy: 0.8431 - val_precision: 1.0000 - val_recall: 0.0030 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1825 - auc: 0.9821 - accuracy: 0.9532 - precision: 0.8982 - recall: 0.8765 \n",
      "Epoch 16: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1825 - auc: 0.9821 - accuracy: 0.9532 - precision: 0.8982 - recall: 0.8765 - val_loss: 0.4728 - val_auc: 0.1536 - val_accuracy: 0.8431 - val_precision: 1.0000 - val_recall: 0.0034 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1772 - auc: 0.9826 - accuracy: 0.9535 - precision: 0.8925 - recall: 0.8853 \n",
      "Epoch 17: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.1772 - auc: 0.9826 - accuracy: 0.9535 - precision: 0.8925 - recall: 0.8853 - val_loss: 0.4788 - val_auc: 0.2955 - val_accuracy: 0.8432 - val_precision: 1.0000 - val_recall: 0.0037 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1727 - auc: 0.9832 - accuracy: 0.9539 - precision: 0.8920 - recall: 0.8881 \n",
      "Epoch 18: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1727 - auc: 0.9832 - accuracy: 0.9539 - precision: 0.8920 - recall: 0.8881 - val_loss: 0.4827 - val_auc: 0.2894 - val_accuracy: 0.8432 - val_precision: 1.0000 - val_recall: 0.0037 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1690 - auc: 0.9838 - accuracy: 0.9544 - precision: 0.9003 - recall: 0.8806\n",
      "Epoch 19: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1690 - auc: 0.9838 - accuracy: 0.9544 - precision: 0.9003 - recall: 0.8806 - val_loss: 0.4961 - val_auc: 0.4108 - val_accuracy: 0.8433 - val_precision: 1.0000 - val_recall: 0.0046 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1661 - auc: 0.9835 - accuracy: 0.9546 - precision: 0.9013 - recall: 0.8801\n",
      "Epoch 20: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.1661 - auc: 0.9835 - accuracy: 0.9546 - precision: 0.9013 - recall: 0.8801 - val_loss: 0.5013 - val_auc: 0.4187 - val_accuracy: 0.8436 - val_precision: 1.0000 - val_recall: 0.0067 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1669 - auc: 0.9827 - accuracy: 0.9526 - precision: 0.8930 - recall: 0.8796\n",
      "Epoch 21: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1669 - auc: 0.9827 - accuracy: 0.9526 - precision: 0.8930 - recall: 0.8796 - val_loss: 0.4694 - val_auc: 0.4426 - val_accuracy: 0.8461 - val_precision: 0.9979 - val_recall: 0.0226 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1628 - auc: 0.9832 - accuracy: 0.9537 - precision: 0.8901 - recall: 0.8894 \n",
      "Epoch 22: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1628 - auc: 0.9832 - accuracy: 0.9537 - precision: 0.8901 - recall: 0.8894 - val_loss: 0.5040 - val_auc: 0.6220 - val_accuracy: 0.8461 - val_precision: 0.9984 - val_recall: 0.0224 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1625 - auc: 0.9817 - accuracy: 0.9531 - precision: 0.8950 - recall: 0.8798 \n",
      "Epoch 23: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1625 - auc: 0.9817 - accuracy: 0.9531 - precision: 0.8950 - recall: 0.8798 - val_loss: 0.5064 - val_auc: 0.6787 - val_accuracy: 0.8483 - val_precision: 0.9987 - val_recall: 0.0362 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1569 - auc: 0.9842 - accuracy: 0.9551 - precision: 0.9100 - recall: 0.8724\n",
      "Epoch 24: val_loss did not improve from 0.41724\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1569 - auc: 0.9842 - accuracy: 0.9551 - precision: 0.9100 - recall: 0.8724 - val_loss: 0.4840 - val_auc: 0.6593 - val_accuracy: 0.8508 - val_precision: 0.9984 - val_recall: 0.0523 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1544 - auc: 0.9849 - accuracy: 0.9549 - precision: 0.8909 - recall: 0.8948\n",
      "Epoch 25: val_loss did not improve from 0.41724\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "10/10 [==============================] - 99s 10s/step - loss: 0.1544 - auc: 0.9849 - accuracy: 0.9549 - precision: 0.8909 - recall: 0.8948 - val_loss: 0.4589 - val_auc: 0.6660 - val_accuracy: 0.8544 - val_precision: 0.9954 - val_recall: 0.0753 - lr: 6.0653e-04\n",
      "Epoch 25: early stopping\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4149 - auc: 0.9003 - accuracy: 0.8443 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6732 - auc: 0.9111 - accuracy: 0.7020 - precision: 0.4159 - recall: 0.9517 \n",
      "Epoch 1: val_loss improved from inf to 0.63111, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.6732 - auc: 0.9111 - accuracy: 0.7020 - precision: 0.4159 - recall: 0.9517 - val_loss: 0.6311 - val_auc: 0.5520 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4576 - auc: 0.9634 - accuracy: 0.9284 - precision: 0.7972 - recall: 0.8951\n",
      "Epoch 2: val_loss improved from 0.63111 to 0.36963, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.4576 - auc: 0.9634 - accuracy: 0.9284 - precision: 0.7972 - recall: 0.8951 - val_loss: 0.3696 - val_auc: 0.8190 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4035 - auc: 0.9499 - accuracy: 0.9429 - precision: 0.8655 - recall: 0.8696\n",
      "Epoch 3: val_loss improved from 0.36963 to 0.34603, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.4035 - auc: 0.9499 - accuracy: 0.9429 - precision: 0.8655 - recall: 0.8696 - val_loss: 0.3460 - val_auc: 0.8540 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3665 - auc: 0.9555 - accuracy: 0.9449 - precision: 0.8679 - recall: 0.8778\n",
      "Epoch 4: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.3665 - auc: 0.9555 - accuracy: 0.9449 - precision: 0.8679 - recall: 0.8778 - val_loss: 0.3549 - val_auc: 0.8712 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3392 - auc: 0.9648 - accuracy: 0.9466 - precision: 0.8755 - recall: 0.8763\n",
      "Epoch 5: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.3392 - auc: 0.9648 - accuracy: 0.9466 - precision: 0.8755 - recall: 0.8763 - val_loss: 0.4200 - val_auc: 0.9038 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3188 - auc: 0.9721 - accuracy: 0.9478 - precision: 0.8794 - recall: 0.8778 \n",
      "Epoch 6: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.3188 - auc: 0.9721 - accuracy: 0.9478 - precision: 0.8794 - recall: 0.8778 - val_loss: 0.4597 - val_auc: 0.8750 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3012 - auc: 0.9738 - accuracy: 0.9491 - precision: 0.8857 - recall: 0.8766 \n",
      "Epoch 7: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.3012 - auc: 0.9738 - accuracy: 0.9491 - precision: 0.8857 - recall: 0.8766 - val_loss: 0.4671 - val_auc: 0.9178 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2866 - auc: 0.9752 - accuracy: 0.9490 - precision: 0.8795 - recall: 0.8839\n",
      "Epoch 8: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.2866 - auc: 0.9752 - accuracy: 0.9490 - precision: 0.8795 - recall: 0.8839 - val_loss: 0.4721 - val_auc: 0.7306 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2736 - auc: 0.9755 - accuracy: 0.9497 - precision: 0.8864 - recall: 0.8788\n",
      "Epoch 9: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 96s 10s/step - loss: 0.2736 - auc: 0.9755 - accuracy: 0.9497 - precision: 0.8864 - recall: 0.8788 - val_loss: 0.4672 - val_auc: 0.7147 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2610 - auc: 0.9762 - accuracy: 0.9501 - precision: 0.8851 - recall: 0.8827 \n",
      "Epoch 10: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.2610 - auc: 0.9762 - accuracy: 0.9501 - precision: 0.8851 - recall: 0.8827 - val_loss: 0.4632 - val_auc: 0.2572 - val_accuracy: 0.8848 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2488 - auc: 0.9753 - accuracy: 0.9500 - precision: 0.8877 - recall: 0.8787 \n",
      "Epoch 11: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.2488 - auc: 0.9753 - accuracy: 0.9500 - precision: 0.8877 - recall: 0.8787 - val_loss: 0.4358 - val_auc: 0.2790 - val_accuracy: 0.8850 - val_precision: 1.0000 - val_recall: 0.0015 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2359 - auc: 0.9743 - accuracy: 0.9511 - precision: 0.8905 - recall: 0.8810 \n",
      "Epoch 12: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 105s 11s/step - loss: 0.2359 - auc: 0.9743 - accuracy: 0.9511 - precision: 0.8905 - recall: 0.8810 - val_loss: 0.4214 - val_auc: 0.3628 - val_accuracy: 0.8852 - val_precision: 1.0000 - val_recall: 0.0032 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2267 - auc: 0.9751 - accuracy: 0.9509 - precision: 0.8875 - recall: 0.8837 \n",
      "Epoch 13: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.2267 - auc: 0.9751 - accuracy: 0.9509 - precision: 0.8875 - recall: 0.8837 - val_loss: 0.4109 - val_auc: 0.4793 - val_accuracy: 0.8853 - val_precision: 1.0000 - val_recall: 0.0043 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2177 - auc: 0.9771 - accuracy: 0.9512 - precision: 0.8856 - recall: 0.8880\n",
      "Epoch 14: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2177 - auc: 0.9771 - accuracy: 0.9512 - precision: 0.8856 - recall: 0.8880 - val_loss: 0.4050 - val_auc: 0.3444 - val_accuracy: 0.8854 - val_precision: 1.0000 - val_recall: 0.0049 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2098 - auc: 0.9763 - accuracy: 0.9512 - precision: 0.8859 - recall: 0.8877 \n",
      "Epoch 15: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.2098 - auc: 0.9763 - accuracy: 0.9512 - precision: 0.8859 - recall: 0.8877 - val_loss: 0.4047 - val_auc: 0.2959 - val_accuracy: 0.8864 - val_precision: 1.0000 - val_recall: 0.0137 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2014 - auc: 0.9792 - accuracy: 0.9519 - precision: 0.8874 - recall: 0.8896 \n",
      "Epoch 16: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 106s 10s/step - loss: 0.2014 - auc: 0.9792 - accuracy: 0.9519 - precision: 0.8874 - recall: 0.8896 - val_loss: 0.3961 - val_auc: 0.2338 - val_accuracy: 0.8874 - val_precision: 1.0000 - val_recall: 0.0222 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1956 - auc: 0.9781 - accuracy: 0.9516 - precision: 0.8861 - recall: 0.8897 \n",
      "Epoch 17: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1956 - auc: 0.9781 - accuracy: 0.9516 - precision: 0.8861 - recall: 0.8897 - val_loss: 0.3859 - val_auc: 0.2892 - val_accuracy: 0.8891 - val_precision: 1.0000 - val_recall: 0.0372 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1884 - auc: 0.9811 - accuracy: 0.9523 - precision: 0.8902 - recall: 0.8878 \n",
      "Epoch 18: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1884 - auc: 0.9811 - accuracy: 0.9523 - precision: 0.8902 - recall: 0.8878 - val_loss: 0.3765 - val_auc: 0.2607 - val_accuracy: 0.8924 - val_precision: 0.9987 - val_recall: 0.0655 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1831 - auc: 0.9819 - accuracy: 0.9520 - precision: 0.8840 - recall: 0.8945 \n",
      "Epoch 19: val_loss did not improve from 0.34603\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.1831 - auc: 0.9819 - accuracy: 0.9520 - precision: 0.8840 - recall: 0.8945 - val_loss: 0.3587 - val_auc: 0.3028 - val_accuracy: 0.8981 - val_precision: 0.9991 - val_recall: 0.1152 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1784 - auc: 0.9819 - accuracy: 0.9525 - precision: 0.8891 - recall: 0.8905 \n",
      "Epoch 20: val_loss improved from 0.34603 to 0.32794, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1784 - auc: 0.9819 - accuracy: 0.9525 - precision: 0.8891 - recall: 0.8905 - val_loss: 0.3279 - val_auc: 0.4088 - val_accuracy: 0.9092 - val_precision: 0.9960 - val_recall: 0.2124 - lr: 8.1873e-04\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1744 - auc: 0.9821 - accuracy: 0.9522 - precision: 0.8874 - recall: 0.8910 \n",
      "Epoch 21: val_loss improved from 0.32794 to 0.29865, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1744 - auc: 0.9821 - accuracy: 0.9522 - precision: 0.8874 - recall: 0.8910 - val_loss: 0.2986 - val_auc: 0.5481 - val_accuracy: 0.9191 - val_precision: 0.9940 - val_recall: 0.2995 - lr: 7.4082e-04\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1708 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8948 - recall: 0.8851\n",
      "Epoch 22: val_loss improved from 0.29865 to 0.26420, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1708 - auc: 0.9814 - accuracy: 0.9529 - precision: 0.8948 - recall: 0.8851 - val_loss: 0.2642 - val_auc: 0.7042 - val_accuracy: 0.9311 - val_precision: 0.9906 - val_recall: 0.4057 - lr: 7.4082e-04\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1678 - auc: 0.9815 - accuracy: 0.9528 - precision: 0.8928 - recall: 0.8874 \n",
      "Epoch 23: val_loss improved from 0.26420 to 0.22676, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1678 - auc: 0.9815 - accuracy: 0.9528 - precision: 0.8928 - recall: 0.8874 - val_loss: 0.2268 - val_auc: 0.8151 - val_accuracy: 0.9443 - val_precision: 0.9906 - val_recall: 0.5211 - lr: 6.7032e-04\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1643 - auc: 0.9827 - accuracy: 0.9527 - precision: 0.8866 - recall: 0.8946 \n",
      "Epoch 24: val_loss improved from 0.22676 to 0.20169, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1643 - auc: 0.9827 - accuracy: 0.9527 - precision: 0.8866 - recall: 0.8946 - val_loss: 0.2017 - val_auc: 0.8724 - val_accuracy: 0.9518 - val_precision: 0.9886 - val_recall: 0.5881 - lr: 6.7032e-04\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1619 - auc: 0.9819 - accuracy: 0.9535 - precision: 0.8961 - recall: 0.8866 \n",
      "Epoch 25: val_loss improved from 0.20169 to 0.19440, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1619 - auc: 0.9819 - accuracy: 0.9535 - precision: 0.8961 - recall: 0.8866 - val_loss: 0.1944 - val_auc: 0.8694 - val_accuracy: 0.9569 - val_precision: 0.9817 - val_recall: 0.6375 - lr: 6.0653e-04\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1589 - auc: 0.9827 - accuracy: 0.9537 - precision: 0.8920 - recall: 0.8928 \n",
      "Epoch 26: val_loss improved from 0.19440 to 0.14567, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1589 - auc: 0.9827 - accuracy: 0.9537 - precision: 0.8920 - recall: 0.8928 - val_loss: 0.1457 - val_auc: 0.9289 - val_accuracy: 0.9651 - val_precision: 0.9773 - val_recall: 0.7139 - lr: 6.0653e-04\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1565 - auc: 0.9830 - accuracy: 0.9541 - precision: 0.8984 - recall: 0.8868 \n",
      "Epoch 27: val_loss improved from 0.14567 to 0.11460, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1565 - auc: 0.9830 - accuracy: 0.9541 - precision: 0.8984 - recall: 0.8868 - val_loss: 0.1146 - val_auc: 0.9658 - val_accuracy: 0.9700 - val_precision: 0.9732 - val_recall: 0.7604 - lr: 5.4881e-04\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1553 - auc: 0.9833 - accuracy: 0.9538 - precision: 0.8948 - recall: 0.8898 \n",
      "Epoch 28: val_loss improved from 0.11460 to 0.09546, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1553 - auc: 0.9833 - accuracy: 0.9538 - precision: 0.8948 - recall: 0.8898 - val_loss: 0.0955 - val_auc: 0.9869 - val_accuracy: 0.9752 - val_precision: 0.9482 - val_recall: 0.8295 - lr: 5.4881e-04\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1540 - auc: 0.9833 - accuracy: 0.9537 - precision: 0.8934 - recall: 0.8913 \n",
      "Epoch 29: val_loss improved from 0.09546 to 0.09307, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 107s 10s/step - loss: 0.1540 - auc: 0.9833 - accuracy: 0.9537 - precision: 0.8934 - recall: 0.8913 - val_loss: 0.0931 - val_auc: 0.9916 - val_accuracy: 0.9777 - val_precision: 0.9218 - val_recall: 0.8813 - lr: 4.9659e-04\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1518 - auc: 0.9837 - accuracy: 0.9540 - precision: 0.8930 - recall: 0.8935 \n",
      "Epoch 30: val_loss improved from 0.09307 to 0.09272, saving model to pixel_core_fold_17.hdf5\n",
      "10/10 [==============================] - 107s 10s/step - loss: 0.1518 - auc: 0.9837 - accuracy: 0.9540 - precision: 0.8930 - recall: 0.8935 - val_loss: 0.0927 - val_auc: 0.9926 - val_accuracy: 0.9768 - val_precision: 0.8868 - val_recall: 0.9150 - lr: 4.9659e-04\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1504 - auc: 0.9832 - accuracy: 0.9546 - precision: 0.9013 - recall: 0.8858 \n",
      "Epoch 31: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1504 - auc: 0.9832 - accuracy: 0.9546 - precision: 0.9013 - recall: 0.8858 - val_loss: 0.1017 - val_auc: 0.9930 - val_accuracy: 0.9752 - val_precision: 0.8652 - val_recall: 0.9296 - lr: 4.4933e-04\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1491 - auc: 0.9845 - accuracy: 0.9540 - precision: 0.8902 - recall: 0.8967 \n",
      "Epoch 32: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1491 - auc: 0.9845 - accuracy: 0.9540 - precision: 0.8902 - recall: 0.8967 - val_loss: 0.1112 - val_auc: 0.9924 - val_accuracy: 0.9734 - val_precision: 0.8502 - val_recall: 0.9333 - lr: 4.4933e-04\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1480 - auc: 0.9838 - accuracy: 0.9547 - precision: 0.9029 - recall: 0.8844 \n",
      "Epoch 33: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1480 - auc: 0.9838 - accuracy: 0.9547 - precision: 0.9029 - recall: 0.8844 - val_loss: 0.1733 - val_auc: 0.9902 - val_accuracy: 0.9395 - val_precision: 0.6635 - val_recall: 0.9624 - lr: 4.0657e-04\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1463 - auc: 0.9842 - accuracy: 0.9545 - precision: 0.8939 - recall: 0.8950 \n",
      "Epoch 34: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.1463 - auc: 0.9842 - accuracy: 0.9545 - precision: 0.8939 - recall: 0.8950 - val_loss: 0.1736 - val_auc: 0.9898 - val_accuracy: 0.9428 - val_precision: 0.6778 - val_recall: 0.9594 - lr: 4.0657e-04\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1455 - auc: 0.9841 - accuracy: 0.9550 - precision: 0.9045 - recall: 0.8842 \n",
      "Epoch 35: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1455 - auc: 0.9841 - accuracy: 0.9550 - precision: 0.9045 - recall: 0.8842 - val_loss: 0.3442 - val_auc: 0.9860 - val_accuracy: 0.7945 - val_precision: 0.3569 - val_recall: 0.9785 - lr: 3.6788e-04\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1450 - auc: 0.9846 - accuracy: 0.9543 - precision: 0.8923 - recall: 0.8960 \n",
      "Epoch 36: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1450 - auc: 0.9846 - accuracy: 0.9543 - precision: 0.8923 - recall: 0.8960 - val_loss: 0.2696 - val_auc: 0.9877 - val_accuracy: 0.9000 - val_precision: 0.5362 - val_recall: 0.9722 - lr: 3.6788e-04\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1432 - auc: 0.9851 - accuracy: 0.9552 - precision: 0.9035 - recall: 0.8863 \n",
      "Epoch 37: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.1432 - auc: 0.9851 - accuracy: 0.9552 - precision: 0.9035 - recall: 0.8863 - val_loss: 0.4029 - val_auc: 0.9860 - val_accuracy: 0.7596 - val_precision: 0.3220 - val_recall: 0.9838 - lr: 3.3287e-04\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1436 - auc: 0.9844 - accuracy: 0.9543 - precision: 0.8944 - recall: 0.8929 \n",
      "Epoch 38: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 111s 11s/step - loss: 0.1436 - auc: 0.9844 - accuracy: 0.9543 - precision: 0.8944 - recall: 0.8929 - val_loss: 0.5045 - val_auc: 0.9827 - val_accuracy: 0.7105 - val_precision: 0.2830 - val_recall: 0.9865 - lr: 3.3287e-04\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1423 - auc: 0.9846 - accuracy: 0.9549 - precision: 0.9000 - recall: 0.8893 \n",
      "Epoch 39: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 106s 11s/step - loss: 0.1423 - auc: 0.9846 - accuracy: 0.9549 - precision: 0.9000 - recall: 0.8893 - val_loss: 0.5130 - val_auc: 0.9822 - val_accuracy: 0.7052 - val_precision: 0.2793 - val_recall: 0.9871 - lr: 3.0119e-04\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1416 - auc: 0.9846 - accuracy: 0.9551 - precision: 0.8991 - recall: 0.8911 \n",
      "Epoch 40: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.1416 - auc: 0.9846 - accuracy: 0.9551 - precision: 0.8991 - recall: 0.8911 - val_loss: 0.5308 - val_auc: 0.9813 - val_accuracy: 0.6973 - val_precision: 0.2740 - val_recall: 0.9868 - lr: 3.0119e-04\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1407 - auc: 0.9850 - accuracy: 0.9552 - precision: 0.9007 - recall: 0.8897 \n",
      "Epoch 41: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1407 - auc: 0.9850 - accuracy: 0.9552 - precision: 0.9007 - recall: 0.8897 - val_loss: 0.9805 - val_auc: 0.9717 - val_accuracy: 0.4095 - val_precision: 0.1631 - val_recall: 0.9989 - lr: 2.7253e-04\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1399 - auc: 0.9855 - accuracy: 0.9551 - precision: 0.9014 - recall: 0.8885 \n",
      "Epoch 42: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1399 - auc: 0.9855 - accuracy: 0.9551 - precision: 0.9014 - recall: 0.8885 - val_loss: 1.3081 - val_auc: 0.9632 - val_accuracy: 0.3423 - val_precision: 0.1490 - val_recall: 0.9998 - lr: 2.7253e-04\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1400 - auc: 0.9844 - accuracy: 0.9550 - precision: 0.9006 - recall: 0.8890\n",
      "Epoch 43: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 102s 10s/step - loss: 0.1400 - auc: 0.9844 - accuracy: 0.9550 - precision: 0.9006 - recall: 0.8890 - val_loss: 1.1568 - val_auc: 0.9635 - val_accuracy: 0.3736 - val_precision: 0.1552 - val_recall: 0.9993 - lr: 2.4660e-04\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1386 - auc: 0.9855 - accuracy: 0.9552 - precision: 0.8966 - recall: 0.8950 \n",
      "Epoch 44: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1386 - auc: 0.9855 - accuracy: 0.9552 - precision: 0.8966 - recall: 0.8950 - val_loss: 1.0433 - val_auc: 0.9697 - val_accuracy: 0.4015 - val_precision: 0.1613 - val_recall: 0.9991 - lr: 2.4660e-04\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1390 - auc: 0.9850 - accuracy: 0.9551 - precision: 0.9007 - recall: 0.8895 \n",
      "Epoch 45: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1390 - auc: 0.9850 - accuracy: 0.9551 - precision: 0.9007 - recall: 0.8895 - val_loss: 1.0127 - val_auc: 0.9705 - val_accuracy: 0.4142 - val_precision: 0.1642 - val_recall: 0.9988 - lr: 2.2313e-04\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1381 - auc: 0.9852 - accuracy: 0.9551 - precision: 0.8990 - recall: 0.8918 \n",
      "Epoch 46: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1381 - auc: 0.9852 - accuracy: 0.9551 - precision: 0.8990 - recall: 0.8918 - val_loss: 0.9459 - val_auc: 0.9662 - val_accuracy: 0.4467 - val_precision: 0.1719 - val_recall: 0.9971 - lr: 2.2313e-04\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1374 - auc: 0.9852 - accuracy: 0.9555 - precision: 0.9037 - recall: 0.8877\n",
      "Epoch 47: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1374 - auc: 0.9852 - accuracy: 0.9555 - precision: 0.9037 - recall: 0.8877 - val_loss: 0.8060 - val_auc: 0.9724 - val_accuracy: 0.4984 - val_precision: 0.1862 - val_recall: 0.9955 - lr: 2.0190e-04\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1369 - auc: 0.9857 - accuracy: 0.9553 - precision: 0.8988 - recall: 0.8931 \n",
      "Epoch 48: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 101s 10s/step - loss: 0.1369 - auc: 0.9857 - accuracy: 0.9553 - precision: 0.8988 - recall: 0.8931 - val_loss: 0.9351 - val_auc: 0.9668 - val_accuracy: 0.4506 - val_precision: 0.1730 - val_recall: 0.9972 - lr: 2.0190e-04\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1367 - auc: 0.9854 - accuracy: 0.9553 - precision: 0.9013 - recall: 0.8898 \n",
      "Epoch 49: val_loss did not improve from 0.09272\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.1367 - auc: 0.9854 - accuracy: 0.9553 - precision: 0.9013 - recall: 0.8898 - val_loss: 0.5783 - val_auc: 0.9771 - val_accuracy: 0.6597 - val_precision: 0.2512 - val_recall: 0.9866 - lr: 1.8268e-04\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1368 - auc: 0.9852 - accuracy: 0.9553 - precision: 0.9017 - recall: 0.8894 \n",
      "Epoch 50: val_loss did not improve from 0.09272\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "10/10 [==============================] - 103s 10s/step - loss: 0.1368 - auc: 0.9852 - accuracy: 0.9553 - precision: 0.9017 - recall: 0.8894 - val_loss: 0.9567 - val_auc: 0.9679 - val_accuracy: 0.4467 - val_precision: 0.1720 - val_recall: 0.9974 - lr: 1.8268e-04\n",
      "Epoch 50: early stopping\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1407 - auc: 0.9923 - accuracy: 0.9484 - precision: 0.7644 - recall: 0.9667\n",
      "No checkpoint found. Starting training from scratch.\n",
      "Epoch 1/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6385 - auc: 0.8717 - accuracy: 0.6579 - precision: 0.3667 - recall: 0.9171\n",
      "Epoch 1: val_loss improved from inf to 1.25575, saving model to pixel_core_fold_18.hdf5\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.6385 - auc: 0.8717 - accuracy: 0.6579 - precision: 0.3667 - recall: 0.9171 - val_loss: 1.2558 - val_auc: 0.4852 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4237 - auc: 0.9577 - accuracy: 0.9189 - precision: 0.7547 - recall: 0.8959 \n",
      "Epoch 2: val_loss improved from 1.25575 to 0.86130, saving model to pixel_core_fold_18.hdf5\n",
      "10/10 [==============================] - 105s 10s/step - loss: 0.4237 - auc: 0.9577 - accuracy: 0.9189 - precision: 0.7547 - recall: 0.8959 - val_loss: 0.8613 - val_auc: 0.7810 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3557 - auc: 0.9591 - accuracy: 0.9433 - precision: 0.8557 - recall: 0.8704\n",
      "Epoch 3: val_loss improved from 0.86130 to 0.51704, saving model to pixel_core_fold_18.hdf5\n",
      "10/10 [==============================] - 100s 10s/step - loss: 0.3557 - auc: 0.9591 - accuracy: 0.9433 - precision: 0.8557 - recall: 0.8704 - val_loss: 0.5170 - val_auc: 0.9371 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3090 - auc: 0.9572 - accuracy: 0.9441 - precision: 0.8577 - recall: 0.8724 \n",
      "Epoch 4: val_loss improved from 0.51704 to 0.46053, saving model to pixel_core_fold_18.hdf5\n",
      "10/10 [==============================] - 115s 12s/step - loss: 0.3090 - auc: 0.9572 - accuracy: 0.9441 - precision: 0.8577 - recall: 0.8724 - val_loss: 0.4605 - val_auc: 0.9368 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2732 - auc: 0.9653 - accuracy: 0.9472 - precision: 0.8712 - recall: 0.8715 \n",
      "Epoch 5: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 123s 12s/step - loss: 0.2732 - auc: 0.9653 - accuracy: 0.9472 - precision: 0.8712 - recall: 0.8715 - val_loss: 0.6400 - val_auc: 0.0451 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2499 - auc: 0.9707 - accuracy: 0.9484 - precision: 0.8798 - recall: 0.8672 \n",
      "Epoch 6: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 127s 13s/step - loss: 0.2499 - auc: 0.9707 - accuracy: 0.9484 - precision: 0.8798 - recall: 0.8672 - val_loss: 0.5712 - val_auc: 0.0506 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2354 - auc: 0.9756 - accuracy: 0.9490 - precision: 0.8753 - recall: 0.8763 \n",
      "Epoch 7: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 123s 12s/step - loss: 0.2354 - auc: 0.9756 - accuracy: 0.9490 - precision: 0.8753 - recall: 0.8763 - val_loss: 0.5496 - val_auc: 0.0675 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2272 - auc: 0.9757 - accuracy: 0.9493 - precision: 0.8831 - recall: 0.8677 \n",
      "Epoch 8: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 117s 12s/step - loss: 0.2272 - auc: 0.9757 - accuracy: 0.9493 - precision: 0.8831 - recall: 0.8677 - val_loss: 0.5270 - val_auc: 0.0613 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2171 - auc: 0.9751 - accuracy: 0.9507 - precision: 0.8877 - recall: 0.8699 \n",
      "Epoch 9: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 120s 12s/step - loss: 0.2171 - auc: 0.9751 - accuracy: 0.9507 - precision: 0.8877 - recall: 0.8699 - val_loss: 0.5125 - val_auc: 0.0872 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2100 - auc: 0.9771 - accuracy: 0.9501 - precision: 0.8849 - recall: 0.8700 \n",
      "Epoch 10: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 118s 12s/step - loss: 0.2100 - auc: 0.9771 - accuracy: 0.9501 - precision: 0.8849 - recall: 0.8700 - val_loss: 0.5057 - val_auc: 0.2051 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2008 - auc: 0.9779 - accuracy: 0.9517 - precision: 0.8912 - recall: 0.8712 \n",
      "Epoch 11: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 112s 11s/step - loss: 0.2008 - auc: 0.9779 - accuracy: 0.9517 - precision: 0.8912 - recall: 0.8712 - val_loss: 0.5001 - val_auc: 0.3301 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1946 - auc: 0.9785 - accuracy: 0.9517 - precision: 0.8871 - recall: 0.8764 \n",
      "Epoch 12: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 124s 12s/step - loss: 0.1946 - auc: 0.9785 - accuracy: 0.9517 - precision: 0.8871 - recall: 0.8764 - val_loss: 0.4982 - val_auc: 0.4000 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1885 - auc: 0.9797 - accuracy: 0.9519 - precision: 0.8827 - recall: 0.8829 \n",
      "Epoch 13: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 121s 12s/step - loss: 0.1885 - auc: 0.9797 - accuracy: 0.9519 - precision: 0.8827 - recall: 0.8829 - val_loss: 0.4964 - val_auc: 0.5761 - val_accuracy: 0.8017 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1825 - auc: 0.9804 - accuracy: 0.9527 - precision: 0.8910 - recall: 0.8770 \n",
      "Epoch 14: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 117s 12s/step - loss: 0.1825 - auc: 0.9804 - accuracy: 0.9527 - precision: 0.8910 - recall: 0.8770 - val_loss: 0.4948 - val_auc: 0.8070 - val_accuracy: 0.8020 - val_precision: 1.0000 - val_recall: 0.0011 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1779 - auc: 0.9804 - accuracy: 0.9527 - precision: 0.8896 - recall: 0.8783 \n",
      "Epoch 15: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 126s 13s/step - loss: 0.1779 - auc: 0.9804 - accuracy: 0.9527 - precision: 0.8896 - recall: 0.8783 - val_loss: 0.4993 - val_auc: 0.7469 - val_accuracy: 0.8024 - val_precision: 1.0000 - val_recall: 0.0030 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1735 - auc: 0.9807 - accuracy: 0.9529 - precision: 0.8914 - recall: 0.8777 \n",
      "Epoch 16: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 113s 11s/step - loss: 0.1735 - auc: 0.9807 - accuracy: 0.9529 - precision: 0.8914 - recall: 0.8777 - val_loss: 0.5004 - val_auc: 0.8234 - val_accuracy: 0.8027 - val_precision: 1.0000 - val_recall: 0.0049 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1704 - auc: 0.9794 - accuracy: 0.9527 - precision: 0.8910 - recall: 0.8767 \n",
      "Epoch 17: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 124s 12s/step - loss: 0.1704 - auc: 0.9794 - accuracy: 0.9527 - precision: 0.8910 - recall: 0.8767 - val_loss: 0.4997 - val_auc: 0.7836 - val_accuracy: 0.8031 - val_precision: 1.0000 - val_recall: 0.0070 - lr: 9.0484e-04\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1663 - auc: 0.9807 - accuracy: 0.9533 - precision: 0.8953 - recall: 0.8747 \n",
      "Epoch 18: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 115s 12s/step - loss: 0.1663 - auc: 0.9807 - accuracy: 0.9533 - precision: 0.8953 - recall: 0.8747 - val_loss: 0.4978 - val_auc: 0.8188 - val_accuracy: 0.8041 - val_precision: 0.9984 - val_recall: 0.0119 - lr: 9.0484e-04\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1630 - auc: 0.9814 - accuracy: 0.9533 - precision: 0.8922 - recall: 0.8787 \n",
      "Epoch 19: val_loss did not improve from 0.46053\n",
      "10/10 [==============================] - 104s 10s/step - loss: 0.1630 - auc: 0.9814 - accuracy: 0.9533 - precision: 0.8922 - recall: 0.8787 - val_loss: 0.4936 - val_auc: 0.8439 - val_accuracy: 0.8061 - val_precision: 0.9900 - val_recall: 0.0220 - lr: 8.1873e-04\n",
      "Epoch 20/150\n",
      " 4/10 [===========>..................] - ETA: 1:05 - loss: 0.1608 - auc: 0.9811 - accuracy: 0.9544 - precision: 0.9016 - recall: 0.8668"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluation metrics initialization\n",
    "auc_scores = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "new_size = (512, 512)\n",
    "\n",
    "# Open a CSV file to write the results\n",
    "with open('model_evaluation_results.csv', mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header\n",
    "    # Check if the file is empty by seeking to the end and getting the position\n",
    "    file.seek(0, os.SEEK_END)\n",
    "    if file.tell() == 0:\n",
    "        # File is empty, write the header\n",
    "        writer.writerow(['Fold', 'Loss', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "    file.flush() \n",
    "    i = 10\n",
    "    # Iterate over each fold\n",
    "    for fold in folds[i:]:\n",
    "        i += 1\n",
    "        augmented_train_images, test_image, validation_images = fold\n",
    "\n",
    "        # Load and preprocess images and labels\n",
    "        train_images, train_masks = load_images_and_labels(\n",
    "            augmented_train_images, augmented_label_dir, new_size)\n",
    "        test_images, test_masks = load_images_and_labels(\n",
    "            test_image, original_label_dir, new_size)\n",
    "        val_images, val_masks = load_images_and_labels(\n",
    "            validation_images, original_label_dir, new_size)\n",
    "\n",
    "        # Create a new instance of the model\n",
    "        model = unet()\n",
    "\n",
    "        # Train the model\n",
    "        trained_model = train_unet(model, train_images, train_masks, val_images, val_masks, 150, 32, \"pixel_core_fold_{i}.hdf5\".format(i=i))\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        loss, auc, accuracy, precision, recall = trained_model.evaluate(\n",
    "            test_images, test_masks)\n",
    "\n",
    "        # Store the evaluation metrics\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # Write the fold results to the CSV file\n",
    "        writer.writerow([i, loss, auc, accuracy, precision, recall])\n",
    "        file.flush() \n",
    "\n",
    "# Calculate average and standard deviation of metrics\n",
    "avg_auc = np.mean(auc_scores)\n",
    "std_auc = np.std(auc_scores)\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "avg_precision = np.mean(precision_scores)\n",
    "std_precision = np.std(precision_scores)\n",
    "avg_recall = np.mean(recall_scores)\n",
    "std_recall = np.std(recall_scores)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Average AUC: {avg_auc:.4f} +/- {std_auc:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f} +/- {std_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f} +/- {std_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f} +/- {std_recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aaron\\Documents\\GitHub\\RizzGPT\\Microarray-Dearraying\\UNetDetection.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aaron/Documents/GitHub/RizzGPT/Microarray-Dearraying/UNetDetection.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m plot_training_predictions(model, images, masks)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_predictions(model, training_images, training_masks, num_samples=3):\n",
    "    # Make sure there is enough data for the number of samples requested\n",
    "    if num_samples > len(training_images):\n",
    "        num_samples = len(training_images)\n",
    "        print(f\"Number of available samples is less than requested. Setting num_samples to {num_samples}.\")\n",
    "\n",
    "    # Randomly select some samples from the training images and masks\n",
    "    indices = np.random.choice(len(training_images), num_samples, replace=False)\n",
    "    sample_images = np.array([training_images[i] for i in indices])\n",
    "    sample_masks = np.array([training_masks[i] for i in indices])\n",
    "\n",
    "    # Generate predictions for the sample_images\n",
    "    predicted_masks = model.predict(sample_images)\n",
    "\n",
    "    # Convert predicted masks to binary\n",
    "    binary_predicted_masks = (predicted_masks > 0.114).astype(np.uint8)\n",
    "\n",
    "    # Set up the matplotlib figure and axes, based on the number of samples\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)  # If only one sample, make sure axes are iterable\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Display original image\n",
    "        axes[i, 0].imshow(np.squeeze(sample_images[i]), cmap='gray')\n",
    "        axes[i, 0].set_title(\"Original Image\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        # Display true mask for the image\n",
    "        axes[i, 1].imshow(np.squeeze(sample_masks[i]), cmap='gray')\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "        # Display predicted mask for the image\n",
    "        axes[i, 2].imshow(np.squeeze(binary_predicted_masks[i]), cmap='gray')\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "        axes[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_predictions(model, images, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Call the function after loading your images and masks\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gea2/Documents/medicaid/Microarray-Dearraying/SegmentationMobileNet.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m verify_masks(images, masks, num_samples\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mask_alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def verify_masks(images, masks, num_samples=3, mask_alpha=0.3):\n",
    "    \"\"\"\n",
    "    This function overlays the mask onto the image to verify position and size.\n",
    "    Parameters:\n",
    "    - images: numpy array of images.\n",
    "    - masks: numpy array of masks.\n",
    "    - num_samples: number of samples to display for verification.\n",
    "    - mask_alpha: transparency level of the mask overlay.\n",
    "    \"\"\"\n",
    "    # Set the number of images to display\n",
    "    num_samples = min(num_samples, len(images))\n",
    "\n",
    "    # Create figure to display images and masks\n",
    "    plt.figure(figsize=(20, num_samples * 10))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.imshow(masks[i].squeeze(), cmap='jet', alpha=mask_alpha)  # 'jet' colormap for the mask\n",
    "        plt.title(f'Image {i} with Mask Overlay')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function after loading your images and masks\n",
    "verify_masks(images, masks, num_samples=2, mask_alpha=0.3)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
