{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from skimage.draw import disk\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Activation, BatchNormalization, Input, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of cores we expect in any image\n",
    "MAX_CORES = 256  # Adjust this number based on your dataset\n",
    "\n",
    "def create_label_array(json_data):\n",
    "    labels = []\n",
    "    for item in json_data:\n",
    "        labels.append([item['x'], item['y'], item['radius']])\n",
    "    # If there are fewer cores than MAX_CORES, we pad the remaining values with -1\n",
    "    while len(labels) < MAX_CORES:\n",
    "        labels.append([-1, -1, -1])  # Padding\n",
    "    labels_flat = np.array(labels).flatten()\n",
    "    # Normalize and flatten the labels to be between 0 and 1, except for padding values which remain -1\n",
    "    for i in range(0, len(labels_flat), 3):\n",
    "        if labels_flat[i] != -1:\n",
    "            labels_flat[i] /= 1024\n",
    "            labels_flat[i+1] /= 1024\n",
    "            labels_flat[i+2] /= 1024\n",
    "    return labels_flat\n",
    "\n",
    "def load_images_and_labels(image_dir, label_dir):\n",
    "    image_files = [os.path.join(image_dir, file) for file in sorted(os.listdir(image_dir)) if file.endswith('.png')]\n",
    "    label_files = [os.path.join(label_dir, file) for file in sorted(os.listdir(label_dir)) if file.endswith('.json')]\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_file, label_file in zip(image_files, label_files):\n",
    "        # Load image\n",
    "        image = img_to_array(load_img(image_file, color_mode='rgb'))\n",
    "        images.append(image / 255.0)  # Normalize the image\n",
    "\n",
    "        # Load corresponding label\n",
    "        with open(label_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        label = create_label_array(json_data)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Usage\n",
    "image_dir = './TMA_WSI_Padded_PNGs'\n",
    "label_dir = './TMA_WSI_Labels_updated'\n",
    "images, labels = load_images_and_labels(image_dir, label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(input_tensor, num_filters, kernel_size=3, do_batch_norm=True):\n",
    "    # A conv block consists of two convolutions, each followed by a batch normalization and a relu activation.\n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    if do_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def unet_regression(input_size=(1024, 1024, 3), num_filters=64, depth=4, dropout=0.5, batch_norm=True, max_cores = 256):\n",
    "    # INPUT LAYER\n",
    "    inputs = Input(input_size)\n",
    "    # CONTRACTING PATH\n",
    "    conv_blocks = []\n",
    "    x = inputs\n",
    "    for i in range(depth):\n",
    "        x = conv_block(x, num_filters * (2**i), do_batch_norm=batch_norm)\n",
    "        conv_blocks.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "    # BOTTLENECK\n",
    "    x = conv_block(x, num_filters * (2**(depth)), do_batch_norm=batch_norm)\n",
    "    \n",
    "    # EXPANSIVE PATH\n",
    "    for i in reversed(range(depth)):\n",
    "        num_filters_exp = num_filters * (2**i)\n",
    "        x = UpSampling2D(size=(2, 2))(x)\n",
    "        x = concatenate([x, conv_blocks[i]], axis=3)\n",
    "        x = conv_block(x, num_filters_exp, do_batch_norm=batch_norm)\n",
    "\n",
    "\n",
    "    # OLD OUTPUT LAYER\n",
    "    # output = Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    # model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "    # NEW OUTPUT LAYER\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    # Adjust the number of outputs to be 3 * MAX_CORES\n",
    "    outputs = Dense(3 * max_cores, activation='linear')(x)  # 3 values for each core: x, y, and radius\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = unet_regression(input_size=(1024, 1024, 3), num_filters=64, depth=4, dropout=0.5, batch_norm=True, max_cores = 256)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "# Assuming 'images' and 'labels' are loaded and preprocessed correctly\n",
    "\n",
    "# Define a custom loss function that can handle the padding\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask = tf.cast(tf.not_equal(y_true, -1), tf.float32)  # Create a mask for the padding\n",
    "    loss = MeanSquaredError()(y_true * mask, y_pred * mask)  # Apply the mask\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)  # Normalize by the number of non-padded entries\n",
    "\n",
    "# Create the U-Net model (ensure this function is defined correctly)\n",
    "model = unet_regression(input_size=(1024, 1024, 3), num_filters=32, depth=4, dropout=0.5, batch_norm=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=custom_loss)\n",
    "\n",
    "# Set up callbacks for learning rate scheduling and checkpointing\n",
    "checkpoint = ModelCheckpoint('model_checkpoint.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='min', min_lr=1e-6)\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "# This is a simple split, consider using sklearn's train_test_split for a random split\n",
    "# val_split = 0.1  # Use 10% of data for validation\n",
    "# num_val_samples = int(val_split * len(images))\n",
    "# train_images, val_images = images[:-num_val_samples], images[-num_val_samples:]\n",
    "# train_labels, val_labels = labels[:-num_val_samples], labels[-num_val_samples:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     train_images, \n",
    "#     train_labels, \n",
    "#     validation_data=(val_images, val_labels),\n",
    "#     epochs=5,  # Set the number of epochs\n",
    "#     batch_size=3,  # Set the batch size\n",
    "#     callbacks=[checkpoint, reduce_lr]\n",
    "# )\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    images, \n",
    "    labels, \n",
    "    epochs=5,  # Set the number of epochs\n",
    "    batch_size=3,  # Set the batch size\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
